{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_WQJ7j5n3B",
        "outputId": "a98bafdd-e7e8-47af-9eb7-3e4272835f36"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-11 12:17:11.577337: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:11.577383: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-11 12:17:14.531776: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2022-01-11 12:17:14.576868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-01-11 12:17:14.578766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX130 computeCapability: 5.0\n",
            "coreClock: 1.189GHz coreCount: 3 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 37.33GiB/s\n",
            "2022-01-11 12:17:14.579133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579413: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579527: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579735: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2022-01-11 12:17:14.579970: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from mia.shadow_models import *\n",
        "from mia.attack_model import *\n",
        "from mia.utilities import *\n",
        "from mia.wrappers import *\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWI32aRtFJqm"
      },
      "source": [
        "## Data Preprocessing, D_in & D_out and Target Model Creation\n",
        "\n",
        "OK. Let's first load our dataset and take a peek at the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JehzAxjYHxAm",
        "outputId": "acfd2205-7fb2-401f-a89c-3449dc9b4a7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-01-11 12:17:14--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3974305 (3,8M) [application/x-httpd-php]\n",
            "Saving to: ‘adult.data.4’\n",
            "\n",
            "adult.data.4        100%[===================>]   3,79M  1,97MB/s    in 1,9s    \n",
            "\n",
            "2022-01-11 12:17:17 (1,97 MB/s) - ‘adult.data.4’ saved [3974305/3974305]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "# !wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oh1C7fT8FJVA"
      },
      "outputs": [],
      "source": [
        "cols = ['age', \n",
        "        'workclass', \n",
        "        'fnlwgt', \n",
        "        'education',\n",
        "        'education-num',\n",
        "        'marital-status',\n",
        "        'occupation', \n",
        "        'relationship', \n",
        "        'race',\n",
        "        'sex',\n",
        "        'capital-gain',\n",
        "        'capital-loss',\n",
        "        'hours-per-week', \n",
        "        'native-country',\n",
        "        'salary']\n",
        "cat_cols = [\n",
        "  'workclass', \n",
        "  'education',\n",
        "  'marital-status',\n",
        "  'occupation',\n",
        "  'relationship',\n",
        "  'race',\n",
        "  'sex',\n",
        "  'native-country'     \n",
        "]\n",
        "\n",
        "num_cols = list(set(cols) - set(cat_cols) - set({'salary'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p8Z5qWioEwtj"
      },
      "outputs": [],
      "source": [
        "dataset_path = 'adult.data' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TE3MYfV0FfvT"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv(dataset_path, index_col=False, names=cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RZAfWfc0ZGVR"
      },
      "outputs": [],
      "source": [
        "data_df.loc[data_df['salary'].str.contains('>50K'), 'salary'] = 1\n",
        "data_df.loc[data_df['salary'].str.contains('>50K') == False, 'salary'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pJL7rlGyH6Oy"
      },
      "outputs": [],
      "source": [
        "for col in cat_cols:\n",
        "  data_df = data_df[data_df[col].str.contains('\\?') == False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxiT8YB_b7AB"
      },
      "outputs": [],
      "source": [
        "data_df[cat_cols] = data_df[cat_cols].astype('category')\n",
        "for col in cat_cols:\n",
        "  data_df[col] = data_df[col].cat.codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FkWFWpHVcL8y"
      },
      "outputs": [],
      "source": [
        "y = data_df.pop('salary').to_numpy(dtype=np.int8)\n",
        "X = data_df.to_numpy(dtype=np.float64) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9nJHvjvid_mF"
      },
      "outputs": [],
      "source": [
        "# divide to target and attack dataset\n",
        "X_target, X_attacker, y_target, y_attacker = train_test_split(X, y, test_size=0.5, shuffle=True, random_state=0)\n",
        "\n",
        "# train-test split for the target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_target, y_target, test_size=0.33, shuffle=True, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C-423fz3dWD4"
      },
      "outputs": [],
      "source": [
        "target_model = DecisionTreeClassifier(random_state=0).fit(X_train, y_train.reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_APyi1ZqdrLJ",
        "outputId": "8f7ad9e9-cd51-40c5-e71b-cec326ddf0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Test Scores:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      7625\n",
            "           1       1.00      1.00      1.00      2479\n",
            "\n",
            "    accuracy                           1.00     10104\n",
            "   macro avg       1.00      1.00      1.00     10104\n",
            "weighted avg       1.00      1.00      1.00     10104\n",
            "\n",
            "Validation Test Scores:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87      3734\n",
            "           1       0.60      0.62      0.61      1243\n",
            "\n",
            "    accuracy                           0.80      4977\n",
            "   macro avg       0.74      0.74      0.74      4977\n",
            "weighted avg       0.80      0.80      0.80      4977\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Training Test Scores:', \n",
        "      classification_report(y_train, target_model.predict(X_train)), \n",
        "      'Validation Test Scores:', \n",
        "      classification_report(y_test, target_model.predict(X_test)), sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_model.predict = target_model.predict_proba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcbVJs-ig03r"
      },
      "source": [
        "So we clearly see that Decision tree is overfitted to the data. It is time to run our normal attack on some data that lack of certain features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M90y3DvEiIA0"
      },
      "source": [
        "## Attacker-Shadows Dataset separation\n",
        "\n",
        "We will divide the attacker dataset to\n",
        "- Attack Evaluation dataset of instances that we know they belong to $D_{out}$\n",
        "- Attack Evaluation dataset of instances that we know they belong to $D_{in}$\n",
        "- Instances from the dataset distribution we will use to train the shadow and attack models. These will also be used as a guide to fill out null values later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7I_QAYdeimk6"
      },
      "outputs": [],
      "source": [
        "# divide attacker dataset\n",
        "X_attacker_train, X_attacker_test_out, y_attacker_train, y_attacker_test_out = train_test_split(X_attacker, y_attacker, test_size=0.33, shuffle=True, random_state=0)\n",
        "\n",
        "# get a proportion of the D_in dataset for later testing of the model\n",
        "_, X_attacker_test_in, _, y_attacker_test_in = train_test_split(X_train, y_train, test_size=0.33, shuffle=True, random_state=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv5vtMZMhFMq"
      },
      "source": [
        "## Filling null features from the dataset distribution.\n",
        "\n",
        "For research purposes we will cross out some categorical and numerical datapoints with probability of 10\\%$ and fill them using the following methods:\n",
        "\n",
        "- for numerical features use the mean of the collumn\n",
        "- for categorical features, find the label, group by it, find the most common value, accross same-labeled instances and assign it to the null case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "44rHSRrohBZ7"
      },
      "outputs": [],
      "source": [
        "# return a df of nullified features\n",
        "def nullify_features_randomly(_df, prob_of_null=0.1):\n",
        "  global cols\n",
        "  df = pd.DataFrame(_df, columns=cols).copy()\n",
        "  for col in cols:\n",
        "    df[col] = df[col].apply(lambda x: x if np.random.random() - prob_of_null >= 0.0 else None)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eKrgVjVSlb1g"
      },
      "outputs": [],
      "source": [
        "nulled_df = nullify_features_randomly(np.concatenate((X_attacker_test_out, y_attacker_test_out.reshape(-1, 1)), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk-Xfnc-lhq9",
        "outputId": "760cf590-68d4-4287-8b47-c5ec361e90d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age               508\n",
              "workclass         517\n",
              "fnlwgt            501\n",
              "education         479\n",
              "education-num     498\n",
              "marital-status    463\n",
              "occupation        489\n",
              "relationship      479\n",
              "race              530\n",
              "sex               552\n",
              "capital-gain      482\n",
              "capital-loss      477\n",
              "hours-per-week    501\n",
              "native-country    524\n",
              "salary            485\n",
              "dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nulled_df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U00a_MTObTSk"
      },
      "outputs": [],
      "source": [
        "N_SHADOWS=5\n",
        "SHADOW_EPOCHS=50\n",
        "SHADOW_DATASET_SIZE=10000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5TxieABsaaKV"
      },
      "outputs": [],
      "source": [
        "def f_shadow():\n",
        "  model = DecisionTreeClassifier(random_state=0) \n",
        "  model.predict = model.predict_proba\n",
        "  return  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_auZzR-omVDy"
      },
      "outputs": [],
      "source": [
        "shadow_models = ShadowModelBatch(N_SHADOWS, f_shadow, model_type='sklearn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Z0P48OqXbuLY"
      },
      "outputs": [],
      "source": [
        "D_shadows = generate_shadow_dataset(target_model, N_SHADOWS, SHADOW_DATASET_SIZE, 2, attacker_X=X_attacker_train, attacker_y=y_attacker_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbX6IX4bbRZp",
        "outputId": "c501c442-27e6-4419-ab08-2595d808ac1e"
      },
      "outputs": [],
      "source": [
        "ShadowModelBatch.VERBOSE=True\n",
        "shadow_models.fit_all(D_shadows, SHADOW_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mNtemr5ab_DI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-11 12:17:20.049640: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-01-11 12:17:20.050362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-01-11 12:17:20.050391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n"
          ]
        }
      ],
      "source": [
        "attack_model = DefaultAttackModel(shadow_models, 2, (3,), 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Wwym01becsw_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-11 12:17:20.610023: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2022-01-11 12:17:20.630652: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2899885000 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "722/722 [==============================] - 3s 3ms/step - loss: 0.6977 - accuracy: 0.5296 - val_loss: 0.6959 - val_accuracy: 0.4957\n",
            "Epoch 2/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6950 - accuracy: 0.5056 - val_loss: 0.6955 - val_accuracy: 0.5422\n",
            "Epoch 3/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6944 - accuracy: 0.5146 - val_loss: 0.6947 - val_accuracy: 0.5422\n",
            "Epoch 4/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6940 - accuracy: 0.5135 - val_loss: 0.6946 - val_accuracy: 0.5422\n",
            "Epoch 5/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6938 - accuracy: 0.5180 - val_loss: 0.6939 - val_accuracy: 0.4960\n",
            "Epoch 6/50\n",
            "722/722 [==============================] - 2s 3ms/step - loss: 0.6937 - accuracy: 0.5239 - val_loss: 0.6937 - val_accuracy: 0.4960\n",
            "Epoch 7/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6936 - accuracy: 0.5022 - val_loss: 0.6937 - val_accuracy: 0.4960\n",
            "Epoch 8/50\n",
            "722/722 [==============================] - 2s 3ms/step - loss: 0.6935 - accuracy: 0.5116 - val_loss: 0.6934 - val_accuracy: 0.4960\n",
            "Epoch 9/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6934 - accuracy: 0.5022 - val_loss: 0.6934 - val_accuracy: 0.4960\n",
            "Epoch 10/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4871 - val_loss: 0.6935 - val_accuracy: 0.4952\n",
            "Epoch 11/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.4955 - val_loss: 0.6936 - val_accuracy: 0.4952\n",
            "Epoch 12/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.4948 - val_loss: 0.6932 - val_accuracy: 0.5043\n",
            "Epoch 13/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6932 - accuracy: 0.4823 - val_loss: 0.6931 - val_accuracy: 0.5043\n",
            "Epoch 14/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5032 - val_loss: 0.6932 - val_accuracy: 0.5043\n",
            "Epoch 15/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5094 - val_loss: 0.6931 - val_accuracy: 0.5043\n",
            "Epoch 16/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6932 - accuracy: 0.5172 - val_loss: 0.6935 - val_accuracy: 0.4952\n",
            "Epoch 17/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5246 - val_loss: 0.6934 - val_accuracy: 0.5506\n",
            "Epoch 18/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5127 - val_loss: 0.6938 - val_accuracy: 0.4952\n",
            "Epoch 19/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5438 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 20/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5330 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 21/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5235 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 22/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5188 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 23/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5190 - val_loss: 0.6932 - val_accuracy: 0.5506\n",
            "Epoch 24/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5223 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 25/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5249 - val_loss: 0.6930 - val_accuracy: 0.5506\n",
            "Epoch 26/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5184 - val_loss: 0.6931 - val_accuracy: 0.5506\n",
            "Epoch 27/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5175 - val_loss: 0.6933 - val_accuracy: 0.5506\n",
            "Epoch 28/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5327 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 29/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5213 - val_loss: 0.6930 - val_accuracy: 0.5506\n",
            "Epoch 30/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5126 - val_loss: 0.6931 - val_accuracy: 0.5506\n",
            "Epoch 31/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5178 - val_loss: 0.6935 - val_accuracy: 0.5506\n",
            "Epoch 32/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5325 - val_loss: 0.6929 - val_accuracy: 0.4578\n",
            "Epoch 33/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5187 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 34/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6935 - val_accuracy: 0.5506\n",
            "Epoch 35/50\n",
            "722/722 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.5310 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 36/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5246 - val_loss: 0.6930 - val_accuracy: 0.5506\n",
            "Epoch 37/50\n",
            "722/722 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.5220 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 38/50\n",
            "722/722 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.5219 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 39/50\n",
            "722/722 [==============================] - 2s 3ms/step - loss: 0.6931 - accuracy: 0.5232 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 40/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5247 - val_loss: 0.6931 - val_accuracy: 0.5506\n",
            "Epoch 41/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5324 - val_loss: 0.6929 - val_accuracy: 0.4578\n",
            "Epoch 42/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5132 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 43/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5164 - val_loss: 0.6930 - val_accuracy: 0.5043\n",
            "Epoch 44/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5184 - val_loss: 0.6931 - val_accuracy: 0.5506\n",
            "Epoch 45/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6930 - accuracy: 0.5247 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 46/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5226 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 47/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5213 - val_loss: 0.6930 - val_accuracy: 0.5506\n",
            "Epoch 48/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6931 - accuracy: 0.5240 - val_loss: 0.6929 - val_accuracy: 0.5043\n",
            "Epoch 49/50\n",
            "722/722 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5280 - val_loss: 0.6928 - val_accuracy: 0.5043\n",
            "Epoch 50/50\n",
            "722/722 [==============================] - 2s 2ms/step - loss: 0.6931 - accuracy: 0.5180 - val_loss: 0.6932 - val_accuracy: 0.5506\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f171f49a400>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DefaultAttackModel.VERBOSE = True\n",
        "attack_model.fit(epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NtcnmIZ-c0sa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, 14) (0,)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_11661/2608808012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_attacker_test_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_attacker_test_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattack_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/Documents/DIT/Thesis/Code/mia/attack_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, X, y, verbose)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_class_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/DIT/Thesis/Code/mia/attack_model.py\u001b[0m in \u001b[0;36mper_class_acc\u001b[0;34m(self, X_attack, y_attack, n_classes)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mclass_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m \u001b[0;31m# get same class samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_instances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_instances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_attack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_instances\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"class-{c+1} acc: {test_acc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
          ]
        }
      ],
      "source": [
        "D_in = attack_model.prepare_batch(target_model, X_attacker_test_in, y_attacker_test_in, True)\n",
        "D_out = attack_model.prepare_batch(target_model, X_attacker_test_out, y_attacker_test_out, False)\n",
        "D_all = np.concatenate((D_in, D_out))\n",
        "attack_model.evaluate(D_all[:, :-1], D_all[:, -1], verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ADULT_mia_v1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
