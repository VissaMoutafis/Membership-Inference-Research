{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_MIA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7JmQQa44ci2"
      },
      "source": [
        "# MIA against a Simple Logistic Regression Algorithm\n",
        "\n",
        "We will perform a Membership Inference Attacks against a self-made LR model, trained on well known iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YgMWUN94ZSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a9b702-8031-4c7c-cf73-945744456833"
      },
      "source": [
        "# import basic libraries\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import sys\n",
        "\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine, fetch_olivetti_faces, fetch_lfw_pairs, load_diabetes\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install mia\n",
        "from mia.estimators import ShadowModelBundle, AttackModelBundle, prepare_attack_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mia\n",
            "  Downloading mia-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mia) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mia) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mia) (0.22.2.post1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from mia) (1.9.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mia) (4.62.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mia) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->mia) (3.7.4.3)\n",
            "Building wheels for collected packages: mia\n",
            "  Building wheel for mia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mia: filename=mia-0.1.2-py3-none-any.whl size=11106 sha256=671f35bc7e319981f4ff3c82e17da43798ca7a8e090c258ab714dd49fc35475d\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/cb/28/c0c2be5bebacd827e384b58ccfe4833ca3bffc1aa0086766d7\n",
            "Successfully built mia\n",
            "Installing collected packages: mia\n",
            "Successfully installed mia-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTvm6Y6j7Trm"
      },
      "source": [
        "#load the data set\n",
        "X, y = load_wine(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, shuffle=True, random_state=0)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgkeN6pX7WUF"
      },
      "source": [
        "# create the mode\n",
        "model = DecisionTreeClassifier()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS2wsuR49S0C",
        "outputId": "ac7c9af2-a507-45d4-aa5a-ce3cd8dea2c1"
      },
      "source": [
        "# fit the model and check accuracy scores\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred)}\") "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.9101123595505618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOrFHHwVDifr",
        "outputId": "beee9f77-e6fc-4a3e-f6f0-9e55355c7445"
      },
      "source": [
        "NUM_CLASSES = 2\n",
        "SHADOW_DATASET_SIZE = 35\n",
        "ATTACK_TEST_DATASET_SIZE = 4000\n",
        "\n",
        "def target_model_fn():\n",
        "  return DecisionTreeClassifier()\n",
        "\n",
        "def attack_model_fn():\n",
        "  return RandomForestClassifier()\n",
        "\n",
        "smb = ShadowModelBundle(\n",
        "        target_model_fn,\n",
        "        shadow_dataset_size=SHADOW_DATASET_SIZE,\n",
        "        num_models=50,\n",
        "\n",
        "    )\n",
        "\n",
        "X_shadow, y_shadow = smb.fit_transform(\n",
        "        X_test,\n",
        "        y_test,\n",
        "        \n",
        "    )\n",
        "\n",
        "print(X_shadow.shape)\n",
        "\n",
        " # ShadowModelBundle returns data in the format suitable for the AttackModelBundle.\n",
        "amb = AttackModelBundle(attack_model_fn, num_classes=NUM_CLASSES)\n",
        "\n",
        "# Fit the attack models.\n",
        "print(\"Training the attack models...\")\n",
        "amb.fit(X_shadow, y_shadow)\n",
        "\n",
        "    # Test the success of the attack.\n",
        "\n",
        "    # Prepare examples that were in the training, and out of the training.\n",
        "data_in = X_train, y_train\n",
        "data_out = X_test, y_test\n",
        "\n",
        "    # Compile them into the expected format for the AttackModelBundle.\n",
        "attack_test_data, real_membership_labels = prepare_attack_data(\n",
        "        model, data_in, data_out\n",
        "    )\n",
        "\n",
        "    # Compute the attack accuracy.\n",
        "attack_guesses = amb.predict(attack_test_data)\n",
        "attack_accuracy = np.mean(attack_guesses == real_membership_labels)\n",
        "\n",
        "print(attack_accuracy)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3500, 4)\n",
            "Training the attack models...\n",
            "0.5449438202247191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl_7FO2q-NuN"
      },
      "source": [
        "## Membership Inference Attack\n",
        "\n",
        "### Assumptions\n",
        "- Each and every Shadow dataset is disjoint with target dataset\n",
        "\n",
        "### Planning\n",
        "- Create $n$ shadow models\n",
        "- Create $n$ shadow datasets\n",
        "- Train the shadow models\n",
        "- Query each one of them and get a attack training-dataset\n",
        "- Create and Train Attack Model\n",
        "- Perform an attack in the victim model\n",
        "- Evaluate the attack\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDijtMAQENjX"
      },
      "source": [
        "N_SHADOW_MODELS = 50\n",
        "SHADOW_DATASET_SIZE = X_train.shape[0]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9XQXHZrFx66"
      },
      "source": [
        "## TODO IMPLEMENT SYNTESIS OF SHADOW DATA\n",
        "\n",
        "# produce a random record\n",
        "def rand_record(size, mean, std):\n",
        "  v = np.random.normal(mean, std, size)\n",
        "  return np.reshape(v, (1, -1))\n",
        "#\n",
        "def rand_record2(x, k_features):\n",
        "  changed_features = set()\n",
        "  for k in range(k_features):\n",
        "    # pick a random index\n",
        "    i = random.randint(0, x.size-1) \n",
        "    # don't change the same feature twice\n",
        "    while i in changed_features:\n",
        "      i = random.randint(0, x.size-1)\n",
        "\n",
        "    # note the feature as changed\n",
        "    changed_features.add(i)\n",
        "\n",
        "    # change the feature by a random value\n",
        "    x[0][i] = x[0][i] + np.random.randn() * np.random.normal(0, 4) \n",
        "\n",
        "\n",
        "def synthesize(model, dim, data_mean, data_std, c, k_max, k_min, iter_max, conf_min, rej_max):\n",
        "  x = rand_record(dim, data_mean, data_std)\n",
        "  y_conf_star = 0.0\n",
        "  rej = 0;\n",
        "  k = k_max\n",
        "\n",
        "  for iter in range(iter_max):\n",
        "    # predict outcome\n",
        "    y = model.predict_proba(x)\n",
        "    y_conf = y[0][c] # the confidence of class 'c' is the probability the classifier predicts\n",
        "    \n",
        "    # if the prediction confidence is high and the classifier predicts that x is of class 'c' \n",
        "    # then we flip a coin to decide if we gonna add this datapoint in our shadow training data  \n",
        "    if y_conf > y_conf_star and c == np.argmax(y):\n",
        "      # flip a coin in {0, 1} and sample\n",
        "      if np.random.randint(2) > 0:\n",
        "        # add the datapoint into synthetic dataset\n",
        "        return x.copy()\n",
        "\n",
        "      # update metrics\n",
        "      y_conf_star = y_conf\n",
        "      rej = 0\n",
        "\n",
        "    else:\n",
        "      #reject the datapoint\n",
        "      rej += 1\n",
        "      \n",
        "      # too many rejections => decrease the features to modify and renew the counter\n",
        "      if rej > rej_max:\n",
        "        k = max(k_min, (k+1)//2)\n",
        "        rej = 0\n",
        "\n",
        "    x = rand_record2(x, k)\n",
        "\n",
        "    return None"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0SkT_rcrKd5",
        "outputId": "8b2f8237-9805-4c9e-fc4a-bd1467cd616d"
      },
      "source": [
        "# create the shadow train and test datasets\n",
        "shadow_training_sets = []\n",
        "shadow_test_sets = []\n",
        "values = range(SHADOW_DATASET_SIZE)\n",
        "for i in range(N_SHADOW_MODELS):\n",
        "  dataset = None\n",
        "  with tqdm(total=len(values), file=sys.stdout) as pbar:\n",
        "    pbar.set_description(\"Creating shadow-dataset: %d\" %(1+i))\n",
        "    c = 0\n",
        "    for j in range(SHADOW_DATASET_SIZE):\n",
        "      c = (c + 1)%(y.max() + 1)\n",
        "\n",
        "      conf = 0.9\n",
        "      x = synthesize(model, int(X.shape[1]), X.mean(), X.std(), c, int(X.shape[1]), 1, 100, conf, 25)\n",
        "      while x is None:\n",
        "        x = synthesize(model, int(X.shape[1]), X.mean(), X.std(), c, int(X.shape[1]), 1, 200, conf, 25)\n",
        "\n",
        "      if x is not None:\n",
        "        # if x is not none then add it in the dataset\n",
        "        x = np.concatenate((x, [[c]]), axis=1)\n",
        "        dataset = np.concatenate((dataset, x.copy())) if dataset is not None else x.copy()\n",
        "    \n",
        "      pbar.update(1)\n",
        "    \n",
        "  train, test = train_test_split(dataset.copy(), test_size=0.1, random_state=0, shuffle=True)\n",
        "  train_x, train_y = train[:, :-1], train[:, -1]\n",
        "  test_x, test_y = test[:, :-1], test[:, -1]\n",
        "  shadow_training_sets.append((train_x,train_y))\n",
        "  shadow_test_sets.append((test_x, test_y))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating shadow-dataset: 1: 100%|██████████| 89/89 [00:40<00:00,  2.19it/s]\n",
            "Creating shadow-dataset: 2: 100%|██████████| 89/89 [00:35<00:00,  2.53it/s]\n",
            "Creating shadow-dataset: 3: 100%|██████████| 89/89 [00:52<00:00,  1.70it/s]\n",
            "Creating shadow-dataset: 4: 100%|██████████| 89/89 [00:34<00:00,  2.60it/s]\n",
            "Creating shadow-dataset: 5: 100%|██████████| 89/89 [00:37<00:00,  2.38it/s]\n",
            "Creating shadow-dataset: 6: 100%|██████████| 89/89 [00:37<00:00,  2.35it/s]\n",
            "Creating shadow-dataset: 7: 100%|██████████| 89/89 [00:47<00:00,  1.87it/s]\n",
            "Creating shadow-dataset: 8: 100%|██████████| 89/89 [00:30<00:00,  2.88it/s]\n",
            "Creating shadow-dataset: 9: 100%|██████████| 89/89 [00:46<00:00,  1.91it/s]\n",
            "Creating shadow-dataset: 10: 100%|██████████| 89/89 [00:30<00:00,  2.92it/s]\n",
            "Creating shadow-dataset: 11: 100%|██████████| 89/89 [00:53<00:00,  1.67it/s]\n",
            "Creating shadow-dataset: 12: 100%|██████████| 89/89 [00:34<00:00,  2.57it/s]\n",
            "Creating shadow-dataset: 13: 100%|██████████| 89/89 [00:39<00:00,  2.28it/s]\n",
            "Creating shadow-dataset: 14: 100%|██████████| 89/89 [00:43<00:00,  2.04it/s]\n",
            "Creating shadow-dataset: 15: 100%|██████████| 89/89 [00:25<00:00,  3.50it/s]\n",
            "Creating shadow-dataset: 16: 100%|██████████| 89/89 [00:31<00:00,  2.80it/s]\n",
            "Creating shadow-dataset: 17: 100%|██████████| 89/89 [00:40<00:00,  2.19it/s]\n",
            "Creating shadow-dataset: 18: 100%|██████████| 89/89 [00:33<00:00,  2.65it/s]\n",
            "Creating shadow-dataset: 19: 100%|██████████| 89/89 [00:40<00:00,  2.22it/s]\n",
            "Creating shadow-dataset: 20: 100%|██████████| 89/89 [00:46<00:00,  1.91it/s]\n",
            "Creating shadow-dataset: 21: 100%|██████████| 89/89 [00:41<00:00,  2.14it/s]\n",
            "Creating shadow-dataset: 22: 100%|██████████| 89/89 [00:29<00:00,  3.00it/s]\n",
            "Creating shadow-dataset: 23: 100%|██████████| 89/89 [00:33<00:00,  2.62it/s]\n",
            "Creating shadow-dataset: 24: 100%|██████████| 89/89 [00:47<00:00,  1.89it/s]\n",
            "Creating shadow-dataset: 25: 100%|██████████| 89/89 [00:46<00:00,  1.93it/s]\n",
            "Creating shadow-dataset: 26: 100%|██████████| 89/89 [00:32<00:00,  2.71it/s]\n",
            "Creating shadow-dataset: 27: 100%|██████████| 89/89 [00:33<00:00,  2.65it/s]\n",
            "Creating shadow-dataset: 28: 100%|██████████| 89/89 [00:32<00:00,  2.77it/s]\n",
            "Creating shadow-dataset: 29: 100%|██████████| 89/89 [00:38<00:00,  2.34it/s]\n",
            "Creating shadow-dataset: 30: 100%|██████████| 89/89 [00:34<00:00,  2.55it/s]\n",
            "Creating shadow-dataset: 31: 100%|██████████| 89/89 [00:36<00:00,  2.44it/s]\n",
            "Creating shadow-dataset: 32: 100%|██████████| 89/89 [00:32<00:00,  2.75it/s]\n",
            "Creating shadow-dataset: 33: 100%|██████████| 89/89 [00:37<00:00,  2.40it/s]\n",
            "Creating shadow-dataset: 34: 100%|██████████| 89/89 [00:36<00:00,  2.43it/s]\n",
            "Creating shadow-dataset: 35: 100%|██████████| 89/89 [00:49<00:00,  1.78it/s]\n",
            "Creating shadow-dataset: 36: 100%|██████████| 89/89 [00:47<00:00,  1.87it/s]\n",
            "Creating shadow-dataset: 37: 100%|██████████| 89/89 [00:33<00:00,  2.65it/s]\n",
            "Creating shadow-dataset: 38: 100%|██████████| 89/89 [00:37<00:00,  2.37it/s]\n",
            "Creating shadow-dataset: 39: 100%|██████████| 89/89 [00:44<00:00,  1.99it/s]\n",
            "Creating shadow-dataset: 40: 100%|██████████| 89/89 [00:41<00:00,  2.13it/s]\n",
            "Creating shadow-dataset: 41: 100%|██████████| 89/89 [00:29<00:00,  3.02it/s]\n",
            "Creating shadow-dataset: 42: 100%|██████████| 89/89 [00:43<00:00,  2.03it/s]\n",
            "Creating shadow-dataset: 43: 100%|██████████| 89/89 [00:34<00:00,  2.55it/s]\n",
            "Creating shadow-dataset: 44: 100%|██████████| 89/89 [00:41<00:00,  2.12it/s]\n",
            "Creating shadow-dataset: 45: 100%|██████████| 89/89 [00:40<00:00,  2.19it/s]\n",
            "Creating shadow-dataset: 46: 100%|██████████| 89/89 [00:31<00:00,  2.80it/s]\n",
            "Creating shadow-dataset: 47: 100%|██████████| 89/89 [00:43<00:00,  2.04it/s]\n",
            "Creating shadow-dataset: 48: 100%|██████████| 89/89 [00:30<00:00,  2.91it/s]\n",
            "Creating shadow-dataset: 49: 100%|██████████| 89/89 [00:35<00:00,  2.50it/s]\n",
            "Creating shadow-dataset: 50: 100%|██████████| 89/89 [00:39<00:00,  2.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_syQfhwH20V8"
      },
      "source": [
        "#Now we will train all the shadow models\n",
        "\n",
        "# init the shadow models\n",
        "shadow_models = []\n",
        "\n",
        "for i in range(N_SHADOW_MODELS):\n",
        "  shadow_X_train, shadow_y_train = shadow_training_sets[i]\n",
        "  shadow_model = DecisionTreeClassifier(random_state=0).fit(shadow_X_train, shadow_y_train)\n",
        "  shadow_models.append(shadow_model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDaFk3Wk222H",
        "outputId": "4e99fa58-b812-463a-a9bf-d3c6a07493d5"
      },
      "source": [
        "# Evaluate the shadow models accuracy\n",
        "for i in range(N_SHADOW_MODELS):\n",
        "  shadow_X_test, shadow_y_test = shadow_test_sets[i]\n",
        "  y_pred = shadow_models[i].predict(shadow_X_test)\n",
        "  \n",
        "  print(f\"Shadow-Model-{i} Accuracy: {accuracy_score(shadow_y_test, y_pred)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shadow-Model-0 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-1 Accuracy: 1.0\n",
            "Shadow-Model-2 Accuracy: 1.0\n",
            "Shadow-Model-3 Accuracy: 1.0\n",
            "Shadow-Model-4 Accuracy: 0.5555555555555556\n",
            "Shadow-Model-5 Accuracy: 1.0\n",
            "Shadow-Model-6 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-7 Accuracy: 0.7777777777777778\n",
            "Shadow-Model-8 Accuracy: 1.0\n",
            "Shadow-Model-9 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-10 Accuracy: 0.7777777777777778\n",
            "Shadow-Model-11 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-12 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-13 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-14 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-15 Accuracy: 1.0\n",
            "Shadow-Model-16 Accuracy: 1.0\n",
            "Shadow-Model-17 Accuracy: 1.0\n",
            "Shadow-Model-18 Accuracy: 0.6666666666666666\n",
            "Shadow-Model-19 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-20 Accuracy: 0.5555555555555556\n",
            "Shadow-Model-21 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-22 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-23 Accuracy: 1.0\n",
            "Shadow-Model-24 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-25 Accuracy: 1.0\n",
            "Shadow-Model-26 Accuracy: 1.0\n",
            "Shadow-Model-27 Accuracy: 1.0\n",
            "Shadow-Model-28 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-29 Accuracy: 1.0\n",
            "Shadow-Model-30 Accuracy: 0.7777777777777778\n",
            "Shadow-Model-31 Accuracy: 1.0\n",
            "Shadow-Model-32 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-33 Accuracy: 1.0\n",
            "Shadow-Model-34 Accuracy: 1.0\n",
            "Shadow-Model-35 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-36 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-37 Accuracy: 0.6666666666666666\n",
            "Shadow-Model-38 Accuracy: 1.0\n",
            "Shadow-Model-39 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-40 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-41 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-42 Accuracy: 0.7777777777777778\n",
            "Shadow-Model-43 Accuracy: 0.6666666666666666\n",
            "Shadow-Model-44 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-45 Accuracy: 1.0\n",
            "Shadow-Model-46 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-47 Accuracy: 0.7777777777777778\n",
            "Shadow-Model-48 Accuracy: 0.8888888888888888\n",
            "Shadow-Model-49 Accuracy: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMCfEW6SByhS"
      },
      "source": [
        "# Construct the attack dataset\n",
        "# Labeling 'in' with 1 and 'out' with 0\n",
        "\n",
        "D_attack = None \n",
        "\n",
        "for i in range(N_SHADOW_MODELS):\n",
        "  # 'in' labeled data\n",
        "  shadow_X_train, y_in = shadow_training_sets[i]\n",
        "  y_prob_in = shadow_models[i].predict_proba(shadow_X_train)\n",
        "\n",
        "  # 'out' labeled data\n",
        "  shadow_X_test, y_out = shadow_test_sets[i]\n",
        "  y_prob_out = shadow_models[i].predict_proba(shadow_X_test)\n",
        "\n",
        "  in_labeled = np.concatenate((y_in.reshape(-1, 1), y_prob_in, model.predict(shadow_X_train).reshape(-1, 1), np.ones(shape=(y_in.shape[0], 1))), axis=1)\n",
        "  out_labeled = np.concatenate((y_out.reshape(-1, 1), y_prob_out, model.predict(shadow_X_test).reshape(-1, 1), np.zeros(shape=(y_out.shape[0], 1))), axis=1)\n",
        "  # create a attack dataset batch\n",
        "  D_attack_i = np.concatenate((in_labeled, out_labeled)) \n",
        "\n",
        "  # append to the rest of the batches\n",
        "  D_attack = np.concatenate((D_attack, D_attack_i), axis=0) if D_attack is not None else D_attack_i\n",
        "\n",
        "np.random.shuffle(D_attack)\n",
        "\n",
        "#D_attack instance format <c, proba_vec from shadow model_i, predicted class, 'in'/'out'>"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4qtyGYeDrRr"
      },
      "source": [
        "attack_models = []\n",
        "for c in range(y.max()+1):\n",
        "  D = D_attack[D_attack[:, 0] == c]\n",
        "  m = RandomForestClassifier().fit(D[:, 1:-1], D[:, -1])\n",
        "  attack_models.append(m)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahtcv-heEyuz",
        "outputId": "b8db22d9-cf65-483c-9ca5-f5b8b681f51a"
      },
      "source": [
        "# Actual attack eval\n",
        "# X format : <class, prob_vec from target, accuracy_score>\n",
        "# all data are 'in' the target training set\n",
        "in_labeled = np.concatenate((y_train.reshape(-1, 1), model.predict_proba(X_train), model.predict(X_train).reshape(-1, 1)), axis=1)\n",
        "out_labeled = np.concatenate((y_test.reshape(-1, 1), model.predict_proba(X_test), model.predict(X_test).reshape(-1, 1)), axis=1)\n",
        "X_attack_real = np.concatenate((in_labeled, out_labeled))\n",
        "\n",
        "y_true = np.concatenate((np.ones((X_train.shape[0], 1)), np.zeros((X_test.shape[0], 1))))\n",
        "\n",
        "\n",
        "for c in range(y.max()+1):\n",
        "  X_targets = X_attack_real[X_attack_real[:, 0] == c, 1:] # get all the <prob-vecs> of predictions for class c\n",
        "  y_attack_pred_real = attack_models[c].predict(X_targets)\n",
        "  acc = accuracy_score(y_true[X_attack_real[:, 0] == c], y_attack_pred_real)\n",
        "  print(f\"({c})Real Attack accuracy: {acc}\")\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0)Real Attack accuracy: 0.576271186440678\n",
            "(1)Real Attack accuracy: 0.5211267605633803\n",
            "(2)Real Attack accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td8dYV0pEKbc",
        "outputId": "ee63936c-ce6b-4973-fc21-bd3465508e68"
      },
      "source": [
        "in_labeled[in_labeled[:, -1] == 1].shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RIspgLxF9y5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c785df8-9569-4252-8dfa-e57c8b9baa12"
      },
      "source": [
        "print(in_labeled[in_labeled[:, -1] == 0].shape)\n",
        "print(in_labeled[in_labeled[:, -1] == 1].shape)\n",
        "print(out_labeled[out_labeled[:, -1] == 0].shape)\n",
        "print(out_labeled[out_labeled[:, -1] == 1].shape)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34, 5)\n",
            "(31, 5)\n",
            "(26, 5)\n",
            "(36, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmz-7Npn3Nxq"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}