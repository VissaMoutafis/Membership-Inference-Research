{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vzAuc5Xo3j2"
      },
      "source": [
        "# Label Only Membership Inference (Revisited on points)\n",
        "\n",
        "### Threat Model:\n",
        "\n",
        "- **Black Box** access to an overfitted classifier with no access to actual $D_{train}$\n",
        "- Predict API returns **only labels instead of confidence vectors**\n",
        "- We have some insight on the training data distribution, $D_{out}$ , **but** $D_{train} \\cap D_{out} = \\varnothing$\n",
        "\n",
        "\n",
        "### Attack Target: \n",
        "- Use a shadow model to attack local shadow models and extract membership leakage features\n",
        "- Use data perturbations in order to exploit test/training data approximation relevancies to the classification boundaries.\n",
        "- Perfom the boundary-based attack on the actual model\n",
        "\n",
        "### Evaluation Target\n",
        "- Score over $50\\%$ accuracy\n",
        "- Train attack model based on this assumption and compare with conf-vector attack\n",
        "\n",
        "Implemented based on [this paper](https://arxiv.org/abs/2007.14321)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_WQJ7j5n3B",
        "outputId": "3dfc3a9e-0590-4a68-dad5-42cb42eb2636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# for image interpolation\n",
        "import scipy.ndimage.interpolation as interpolation\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from mia_v1.attack_model import *\n",
        "from mia_v1.label_only import *\n",
        "from mia_v1.shadow_models import *\n",
        "from mia_v1.utilities import *\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kv7Qon0qRTk"
      },
      "source": [
        "## Target Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zacp4ArauIET"
      },
      "outputs": [],
      "source": [
        "D_TARGET_SIZE = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qg7LkXX0zOF"
      },
      "outputs": [],
      "source": [
        "def f_target(X_train, y_train, X_test=None, y_test=None, epochs=100):\n",
        "  \"\"\"\n",
        "  Returns a trained target model, if test data are specified we will evaluate the model and print its accuracy\n",
        "  \"\"\"\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  if X_test is None or y_test is None:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_split=0.2)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_data=(X_test, y_test))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy2NLipP75sX",
        "outputId": "ebd06c33-64d8-4060-92f0-be82fecdde5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "#shuffle the datasets\n",
        "sample_i = np.random.choice(range(train_images.shape[0]), train_images.shape[0], replace=False)\n",
        "train_images = train_images[sample_i]\n",
        "train_labels = train_labels[sample_i]\n",
        "sample_i = np.random.choice(range(test_images.shape[0]), test_images.shape[0], replace=False)\n",
        "test_images = test_images[sample_i]\n",
        "test_labels = test_labels[sample_i] \n",
        "\n",
        "# use the rest as testing - 'out' records\n",
        "attacker_labels = np.concatenate((train_labels[D_TARGET_SIZE:], test_labels))\n",
        "attacker_images = np.concatenate((train_images[D_TARGET_SIZE:], test_images))\n",
        "target_images = train_images[:D_TARGET_SIZE]\n",
        "target_labels = train_labels[:D_TARGET_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap02yKRT76RJ",
        "outputId": "dd1e57e7-174f-4d22-db06-b4d8f5cf54de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "125/125 [==============================] - 3s 13ms/step - loss: 2.4335 - accuracy: 0.1800 - val_loss: 1.9295 - val_accuracy: 0.2840\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 1.8829 - accuracy: 0.3142 - val_loss: 2.3912 - val_accuracy: 0.1900\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 1.8078 - accuracy: 0.3228 - val_loss: 1.7220 - val_accuracy: 0.3620\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 1s 11ms/step - loss: 1.6355 - accuracy: 0.3935 - val_loss: 1.7445 - val_accuracy: 0.3780\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 1.5424 - accuracy: 0.4345 - val_loss: 1.6306 - val_accuracy: 0.3880\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 1s 12ms/step - loss: 1.4416 - accuracy: 0.4660 - val_loss: 1.6614 - val_accuracy: 0.3740\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 1.3042 - accuracy: 0.5160 - val_loss: 1.7449 - val_accuracy: 0.3650\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 1.1501 - accuracy: 0.5765 - val_loss: 1.6543 - val_accuracy: 0.4250\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 1.0085 - accuracy: 0.6332 - val_loss: 1.9584 - val_accuracy: 0.3730\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.8780 - accuracy: 0.6787 - val_loss: 1.9440 - val_accuracy: 0.4290\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.7255 - accuracy: 0.7445 - val_loss: 2.1508 - val_accuracy: 0.4430\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.6233 - accuracy: 0.7793 - val_loss: 2.1634 - val_accuracy: 0.4170\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.5232 - accuracy: 0.8148 - val_loss: 2.4997 - val_accuracy: 0.3930\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.4741 - accuracy: 0.8345 - val_loss: 2.3332 - val_accuracy: 0.4270\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 0.3755 - accuracy: 0.8712 - val_loss: 2.7361 - val_accuracy: 0.4370\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.3598 - accuracy: 0.8820 - val_loss: 2.9176 - val_accuracy: 0.4270\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 0.2993 - accuracy: 0.8978 - val_loss: 2.6465 - val_accuracy: 0.4280\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2734 - accuracy: 0.9100 - val_loss: 3.0769 - val_accuracy: 0.4190\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1996 - accuracy: 0.9337 - val_loss: 3.8518 - val_accuracy: 0.3800\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.3527 - accuracy: 0.8892 - val_loss: 3.0474 - val_accuracy: 0.4210\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1749 - accuracy: 0.9450 - val_loss: 3.5331 - val_accuracy: 0.4090\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.2207 - accuracy: 0.9325 - val_loss: 3.2247 - val_accuracy: 0.4370\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1917 - accuracy: 0.9373 - val_loss: 3.4264 - val_accuracy: 0.4060\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.1773 - accuracy: 0.9485 - val_loss: 3.3423 - val_accuracy: 0.4430\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 2s 12ms/step - loss: 0.0914 - accuracy: 0.9718 - val_loss: 3.7038 - val_accuracy: 0.4420\n"
          ]
        }
      ],
      "source": [
        "train_images, eval_images, train_labels, eval_labels = train_test_split(target_images, target_labels, test_size=0.2, shuffle=True)\n",
        "target_model = f_target(train_images, train_labels, eval_images, eval_labels, epochs=25) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l--0MCg-elRq"
      },
      "source": [
        "### Perturbed Instance Behaviour\n",
        "\n",
        "Following we will apply some perturbations to data instances from in and out of $D_{target}$ and we will count how the predicted label change in respect to this perturbations, according to each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H0PYHLFrWJ1"
      },
      "source": [
        "\n",
        "\n",
        "## Shadow Models\n",
        "Following we define our own shadow models\n",
        "\n",
        "### Shadow Model Architecture\n",
        "- 3 CNN layers of $32, 64, 128$ filters of size $3 \\times 3$ with MaxPooling and ReLU activation\n",
        "- Dense Layer of 512 nodes\n",
        "- Dense Layer of 10 nodes as Output layer\n",
        "\n",
        "All output logits pass through Softmax Unit as in the target model to acquire probability vectors\n",
        "\n",
        "\n",
        "\n",
        "### Shadow Dataset Composition\n",
        "\n",
        "We just divide the CIFAR-10 dataset to $D_{out}$ and $D_{train}$ such as $D_{train} \\cap D_{out} = \\varnothing$ and use $D_{out}$ in order to train/test shadow models and attack model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GWyCXmmwIiJ"
      },
      "outputs": [],
      "source": [
        "N_SHADOWS = 5\n",
        "D_SHADOW_SIZE = 2500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rwhySHfVQjV"
      },
      "outputs": [],
      "source": [
        "def f_shadow():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='tanh', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='tanh'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='tanh'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='tanh'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sliyw7xO2PTg"
      },
      "outputs": [],
      "source": [
        "# returns list of (trained shadow_model, D_shadow)\n",
        "def create_shadows(D_shadows):\n",
        "  shadow_models_bundle = ShadowModelBatch(len(D_shadows), f_shadow) # shadow model list\n",
        "  shadow_models_bundle.fit_all(D_shadows, epochs=25)\n",
        "  return shadow_models_bundle # return a list where every item is (model, acc), train-data, test-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3ziH9LP3CY5"
      },
      "outputs": [],
      "source": [
        "# generate shadow datasets\n",
        "D_shadows = generate_shadow_dataset(target_model, N_SHADOWS, D_SHADOW_SIZE, 10, attacker_images, attacker_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc8morl-NRP",
        "outputId": "5b350459-58ae-4a0a-c580-7a6b04531cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "53/53 [==============================] - 2s 16ms/step - loss: 2.1427 - accuracy: 0.2501 - val_loss: 1.8442 - val_accuracy: 0.3345\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.6387 - accuracy: 0.4018 - val_loss: 1.8400 - val_accuracy: 0.3333\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1.4746 - accuracy: 0.4693 - val_loss: 1.8617 - val_accuracy: 0.3636\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.2911 - accuracy: 0.5361 - val_loss: 1.7726 - val_accuracy: 0.4048\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1.0336 - accuracy: 0.6388 - val_loss: 1.8089 - val_accuracy: 0.3842\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.8334 - accuracy: 0.7164 - val_loss: 1.9800 - val_accuracy: 0.3733\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.6415 - accuracy: 0.7869 - val_loss: 1.9277 - val_accuracy: 0.4109\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5073 - accuracy: 0.8454 - val_loss: 2.0249 - val_accuracy: 0.3964\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.2934 - accuracy: 0.9176 - val_loss: 2.0304 - val_accuracy: 0.4279\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.1469 - accuracy: 0.9737 - val_loss: 2.1356 - val_accuracy: 0.4473\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0840 - accuracy: 0.9869 - val_loss: 2.2191 - val_accuracy: 0.4315\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0384 - accuracy: 0.9976 - val_loss: 2.3036 - val_accuracy: 0.4521\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.2964 - val_accuracy: 0.4497\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.2992 - val_accuracy: 0.4436\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.3176 - val_accuracy: 0.4448\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.3442 - val_accuracy: 0.4424\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3679 - val_accuracy: 0.4436\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3749 - val_accuracy: 0.4424\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.3934 - val_accuracy: 0.4461\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4084 - val_accuracy: 0.4436\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4236 - val_accuracy: 0.4436\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.4319 - val_accuracy: 0.4424\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4541 - val_accuracy: 0.4461\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.4577 - val_accuracy: 0.4412\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4797 - val_accuracy: 0.4461\n",
            "Epoch 1/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 2.1181 - accuracy: 0.2543 - val_loss: 1.8896 - val_accuracy: 0.2788\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.7593 - accuracy: 0.3600 - val_loss: 1.7897 - val_accuracy: 0.3382\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.5079 - accuracy: 0.4549 - val_loss: 1.7337 - val_accuracy: 0.3830\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1.2719 - accuracy: 0.5546 - val_loss: 1.8893 - val_accuracy: 0.3648\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1.0726 - accuracy: 0.6322 - val_loss: 1.7381 - val_accuracy: 0.4182\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.8853 - accuracy: 0.6848 - val_loss: 1.8632 - val_accuracy: 0.4230\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.5945 - accuracy: 0.8048 - val_loss: 1.8046 - val_accuracy: 0.4255\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.3802 - accuracy: 0.8925 - val_loss: 1.9813 - val_accuracy: 0.4206\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.2049 - accuracy: 0.9558 - val_loss: 2.0703 - val_accuracy: 0.4255\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.1166 - accuracy: 0.9815 - val_loss: 2.1576 - val_accuracy: 0.4291\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0590 - accuracy: 0.9952 - val_loss: 2.2242 - val_accuracy: 0.4364\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0363 - accuracy: 0.9976 - val_loss: 2.2476 - val_accuracy: 0.4461\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 2.3049 - val_accuracy: 0.4497\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.3221 - val_accuracy: 0.4497\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.3472 - val_accuracy: 0.4497\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.3743 - val_accuracy: 0.4497\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3964 - val_accuracy: 0.4497\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.4129 - val_accuracy: 0.4570\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.4295 - val_accuracy: 0.4485\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4607 - val_accuracy: 0.4497\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4704 - val_accuracy: 0.4485\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.4828 - val_accuracy: 0.4461\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5019 - val_accuracy: 0.4570\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5133 - val_accuracy: 0.4545\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.5256 - val_accuracy: 0.4582\n",
            "Epoch 1/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 2.1627 - accuracy: 0.2424 - val_loss: 1.7830 - val_accuracy: 0.3297\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.7585 - accuracy: 0.3666 - val_loss: 1.7680 - val_accuracy: 0.3273\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1.6341 - accuracy: 0.4096 - val_loss: 1.7989 - val_accuracy: 0.3782\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 1.5311 - accuracy: 0.4507 - val_loss: 1.6809 - val_accuracy: 0.3903\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.3410 - accuracy: 0.5325 - val_loss: 1.7361 - val_accuracy: 0.4097\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 1.2154 - accuracy: 0.5719 - val_loss: 1.7129 - val_accuracy: 0.4012\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.9990 - accuracy: 0.6591 - val_loss: 1.7728 - val_accuracy: 0.4024\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.8007 - accuracy: 0.7296 - val_loss: 1.8023 - val_accuracy: 0.4061\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.7481 - accuracy: 0.7552 - val_loss: 1.9091 - val_accuracy: 0.3867\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.5918 - accuracy: 0.7970 - val_loss: 2.0349 - val_accuracy: 0.4048\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.4137 - accuracy: 0.8657 - val_loss: 2.0199 - val_accuracy: 0.4097\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.3099 - accuracy: 0.9027 - val_loss: 2.0753 - val_accuracy: 0.4218\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.1336 - accuracy: 0.9707 - val_loss: 2.2563 - val_accuracy: 0.3988\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0908 - accuracy: 0.9857 - val_loss: 2.2939 - val_accuracy: 0.4145\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0556 - accuracy: 0.9928 - val_loss: 2.2934 - val_accuracy: 0.4291\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0220 - accuracy: 0.9994 - val_loss: 2.2989 - val_accuracy: 0.4436\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.3045 - val_accuracy: 0.4388\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.3246 - val_accuracy: 0.4436\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.3436 - val_accuracy: 0.4412\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3542 - val_accuracy: 0.4436\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.3733 - val_accuracy: 0.4400\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.3903 - val_accuracy: 0.4436\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4024 - val_accuracy: 0.4436\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 11ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4173 - val_accuracy: 0.4436\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.4235 - val_accuracy: 0.4473\n",
            "Epoch 1/25\n",
            "53/53 [==============================] - 2s 17ms/step - loss: 2.1527 - accuracy: 0.2531 - val_loss: 1.8770 - val_accuracy: 0.3127\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1.6771 - accuracy: 0.3970 - val_loss: 1.8388 - val_accuracy: 0.3685\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1.4929 - accuracy: 0.4597 - val_loss: 1.7351 - val_accuracy: 0.3636\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1.2811 - accuracy: 0.5427 - val_loss: 1.8643 - val_accuracy: 0.3939\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1.1448 - accuracy: 0.5988 - val_loss: 1.7550 - val_accuracy: 0.4000\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 18ms/step - loss: 0.9646 - accuracy: 0.6693 - val_loss: 1.8913 - val_accuracy: 0.3745\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 17ms/step - loss: 0.7189 - accuracy: 0.7600 - val_loss: 1.9416 - val_accuracy: 0.3745\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.6270 - accuracy: 0.7809 - val_loss: 1.8352 - val_accuracy: 0.4145\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.3595 - accuracy: 0.9009 - val_loss: 2.0044 - val_accuracy: 0.4206\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.2879 - accuracy: 0.9212 - val_loss: 2.0363 - val_accuracy: 0.4097\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.1582 - accuracy: 0.9630 - val_loss: 2.1272 - val_accuracy: 0.4376\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.1164 - accuracy: 0.9767 - val_loss: 2.1841 - val_accuracy: 0.4194\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0871 - accuracy: 0.9869 - val_loss: 2.2854 - val_accuracy: 0.4376\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.2873 - val_accuracy: 0.4315\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.3009 - val_accuracy: 0.4521\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.2937 - val_accuracy: 0.4521\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3099 - val_accuracy: 0.4461\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.3343 - val_accuracy: 0.4461\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.3401 - val_accuracy: 0.4521\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.3502 - val_accuracy: 0.4533\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.3771 - val_accuracy: 0.4497\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3832 - val_accuracy: 0.4558\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.4017 - val_accuracy: 0.4533\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.4161 - val_accuracy: 0.4545\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.4228 - val_accuracy: 0.4582\n",
            "Epoch 1/25\n",
            "53/53 [==============================] - 4s 56ms/step - loss: 2.1584 - accuracy: 0.2394 - val_loss: 1.8890 - val_accuracy: 0.3297\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1.7231 - accuracy: 0.3785 - val_loss: 1.6993 - val_accuracy: 0.3830\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1.5258 - accuracy: 0.4496 - val_loss: 1.7037 - val_accuracy: 0.3867\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 1.3583 - accuracy: 0.5206 - val_loss: 1.6466 - val_accuracy: 0.4121\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 1.0812 - accuracy: 0.6263 - val_loss: 1.7563 - val_accuracy: 0.3988\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.9335 - accuracy: 0.6704 - val_loss: 1.6555 - val_accuracy: 0.4436\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.6502 - accuracy: 0.7982 - val_loss: 1.8184 - val_accuracy: 0.4097\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.4498 - accuracy: 0.8693 - val_loss: 1.9029 - val_accuracy: 0.4400\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.2596 - accuracy: 0.9272 - val_loss: 1.9608 - val_accuracy: 0.4327\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.1814 - accuracy: 0.9642 - val_loss: 2.0129 - val_accuracy: 0.4194\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0728 - accuracy: 0.9916 - val_loss: 2.0754 - val_accuracy: 0.4315\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 2.0879 - val_accuracy: 0.4448\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.1286 - val_accuracy: 0.4364\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.1448 - val_accuracy: 0.4364\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 12ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1631 - val_accuracy: 0.4485\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.1909 - val_accuracy: 0.4436\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.2123 - val_accuracy: 0.4485\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2386 - val_accuracy: 0.4424\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 15ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2437 - val_accuracy: 0.4436\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.2728 - val_accuracy: 0.4424\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.2886 - val_accuracy: 0.4436\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.2926 - val_accuracy: 0.4473\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.3192 - val_accuracy: 0.4400\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 13ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3298 - val_accuracy: 0.4376\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 14ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.3464 - val_accuracy: 0.4424\n"
          ]
        }
      ],
      "source": [
        "# train the shadow models\n",
        "shadow_models = create_shadows(D_shadows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJQxvjrfrfnW"
      },
      "source": [
        "## Attack Model\n",
        "\n",
        "### Attack Model Architecture\n",
        "The attack model is consisted of 1 swallow layer of 10 neurons just as proposed in Shokri et al. and in the relative label only attack paper.\n",
        "\n",
        "\n",
        "### Attack Dataset\n",
        "The attack dataset will be consisted of vectors $x_i$, s.t. $x_i$ contains:\n",
        "- real label\n",
        "- predicted label\n",
        "- bitstring of length $n'$, where $x_{ij+2}, \\; j \\in \\{1, ..., n'\\} $ will be 1 if perturbed label is same as predicted, otherwise it'll be zero.\n",
        "\n",
        "\n",
        "### Perturbed Queries for feature extraction and Attack Dataset\n",
        "\n",
        "In order to construct the actual attack dataset we have 2 perturbation functions:\n",
        "- Translate\n",
        "- Rotate\n",
        "\n",
        "that can apply the necessary augmentations in order to acquire the feature vector for a query.\n",
        "\n",
        "This works by applying all augmentations to the input X and querying the target model in order to return a binary vector $x_{attack}$ where $$x_{attack_p} = 1 \\; if \\;y_p == y_{true} \\; else \\; 0, \\forall p \\in Perturbations(X)$$\n",
        "\n",
        "where $y_p$ is the label for pertubation $p$ of input $X$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrhUttNV1jR6"
      },
      "outputs": [],
      "source": [
        "r = 2 # rotate range => creating 2*r+1 rotations \n",
        "d = 1 # translate range =? creating 4*d + 1 translates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnhE29HBBYGy"
      },
      "outputs": [],
      "source": [
        "def f_attack():\n",
        "  global r\n",
        "  global d\n",
        "  \n",
        "  model = models.Sequential(name='label-only attack_model')\n",
        "  # input dims = 2*r(# of rotates - neutral)  + 4*d(# of translates - neutral) + 2 (y_pred, y_true)\n",
        "  model.add(layers.Dense(10, input_shape=(2*r+4*d+2, )))\n",
        "  model.add(layers.LeakyReLU(0.3))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "        \n",
        "  model.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "  \n",
        "  print(model.summary())\n",
        "  return model \n",
        "\n",
        "attack_model = LabelOnlyAttackModel(shadow_models, 10, f_attack_builder=f_attack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bdgsVbiFk3B",
        "outputId": "d4c118da-4c3d-4b65-ea2c-eeba4974806e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing shadow batch of size 1650\n",
            "Done!\n",
            "Preparing shadow batch of size 1650\n",
            "Done!\n",
            "Preparing shadow batch of size 1650\n",
            "Done!\n",
            "Preparing shadow batch of size 1650\n",
            "Done!\n",
            "Preparing shadow batch of size 1650\n",
            "Done!\n",
            "Epoch 1/50\n",
            "181/181 [==============================] - 2s 6ms/step - loss: 0.6833 - accuracy: 0.5758 - val_loss: 0.6582 - val_accuracy: 0.6210\n",
            "Epoch 2/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.6512 - accuracy: 0.6118 - val_loss: 0.6376 - val_accuracy: 0.6453\n",
            "Epoch 3/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.6235 - accuracy: 0.6620 - val_loss: 0.6059 - val_accuracy: 0.7002\n",
            "Epoch 4/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.6940 - val_loss: 0.5897 - val_accuracy: 0.7139\n",
            "Epoch 5/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7202 - val_loss: 0.5729 - val_accuracy: 0.7301\n",
            "Epoch 6/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5611 - accuracy: 0.7351 - val_loss: 0.5519 - val_accuracy: 0.7495\n",
            "Epoch 7/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5457 - accuracy: 0.7513 - val_loss: 0.5380 - val_accuracy: 0.7543\n",
            "Epoch 8/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.7605 - val_loss: 0.5261 - val_accuracy: 0.7592\n",
            "Epoch 9/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.7707 - val_loss: 0.5131 - val_accuracy: 0.7758\n",
            "Epoch 10/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.5079 - accuracy: 0.7778 - val_loss: 0.5024 - val_accuracy: 0.7778\n",
            "Epoch 11/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4992 - accuracy: 0.7861 - val_loss: 0.4943 - val_accuracy: 0.7859\n",
            "Epoch 12/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4913 - accuracy: 0.7915 - val_loss: 0.4869 - val_accuracy: 0.7952\n",
            "Epoch 13/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.7995 - val_loss: 0.4809 - val_accuracy: 0.7984\n",
            "Epoch 14/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.8012 - val_loss: 0.4758 - val_accuracy: 0.8032\n",
            "Epoch 15/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.8045 - val_loss: 0.4706 - val_accuracy: 0.8020\n",
            "Epoch 16/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4669 - accuracy: 0.8047 - val_loss: 0.4674 - val_accuracy: 0.8069\n",
            "Epoch 17/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.8081 - val_loss: 0.4617 - val_accuracy: 0.8028\n",
            "Epoch 18/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.8087 - val_loss: 0.4577 - val_accuracy: 0.8061\n",
            "Epoch 19/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4557 - accuracy: 0.8087 - val_loss: 0.4549 - val_accuracy: 0.8113\n",
            "Epoch 20/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4522 - accuracy: 0.8104 - val_loss: 0.4588 - val_accuracy: 0.7972\n",
            "Epoch 21/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4485 - accuracy: 0.8111 - val_loss: 0.4493 - val_accuracy: 0.8012\n",
            "Epoch 22/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4464 - accuracy: 0.8118 - val_loss: 0.4460 - val_accuracy: 0.8093\n",
            "Epoch 23/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4429 - accuracy: 0.8133 - val_loss: 0.4449 - val_accuracy: 0.8012\n",
            "Epoch 24/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4424 - accuracy: 0.8137 - val_loss: 0.4406 - val_accuracy: 0.8113\n",
            "Epoch 25/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4392 - accuracy: 0.8154 - val_loss: 0.4378 - val_accuracy: 0.8149\n",
            "Epoch 26/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4349 - accuracy: 0.8173 - val_loss: 0.4355 - val_accuracy: 0.8154\n",
            "Epoch 27/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4357 - accuracy: 0.8142 - val_loss: 0.4337 - val_accuracy: 0.8158\n",
            "Epoch 28/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4319 - accuracy: 0.8185 - val_loss: 0.4330 - val_accuracy: 0.8137\n",
            "Epoch 29/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4300 - accuracy: 0.8194 - val_loss: 0.4300 - val_accuracy: 0.8182\n",
            "Epoch 30/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4288 - accuracy: 0.8190 - val_loss: 0.4406 - val_accuracy: 0.8012\n",
            "Epoch 31/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4269 - accuracy: 0.8201 - val_loss: 0.4270 - val_accuracy: 0.8166\n",
            "Epoch 32/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4247 - accuracy: 0.8187 - val_loss: 0.4278 - val_accuracy: 0.8214\n",
            "Epoch 33/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8206 - val_loss: 0.4235 - val_accuracy: 0.8210\n",
            "Epoch 34/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4224 - accuracy: 0.8225 - val_loss: 0.4280 - val_accuracy: 0.8214\n",
            "Epoch 35/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4219 - accuracy: 0.8227 - val_loss: 0.4225 - val_accuracy: 0.8178\n",
            "Epoch 36/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4211 - accuracy: 0.8223 - val_loss: 0.4229 - val_accuracy: 0.8178\n",
            "Epoch 37/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4180 - accuracy: 0.8248 - val_loss: 0.4215 - val_accuracy: 0.8190\n",
            "Epoch 38/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4185 - accuracy: 0.8225 - val_loss: 0.4181 - val_accuracy: 0.8210\n",
            "Epoch 39/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4162 - accuracy: 0.8242 - val_loss: 0.4203 - val_accuracy: 0.8214\n",
            "Epoch 40/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4150 - accuracy: 0.8246 - val_loss: 0.4157 - val_accuracy: 0.8214\n",
            "Epoch 41/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4148 - accuracy: 0.8255 - val_loss: 0.4151 - val_accuracy: 0.8214\n",
            "Epoch 42/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4135 - accuracy: 0.8249 - val_loss: 0.4150 - val_accuracy: 0.8214\n",
            "Epoch 43/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8246 - val_loss: 0.4174 - val_accuracy: 0.8214\n",
            "Epoch 44/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4124 - accuracy: 0.8253 - val_loss: 0.4127 - val_accuracy: 0.8214\n",
            "Epoch 45/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4117 - accuracy: 0.8253 - val_loss: 0.4165 - val_accuracy: 0.8210\n",
            "Epoch 46/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8255 - val_loss: 0.4137 - val_accuracy: 0.8214\n",
            "Epoch 47/50\n",
            "181/181 [==============================] - 1s 6ms/step - loss: 0.4105 - accuracy: 0.8255 - val_loss: 0.4162 - val_accuracy: 0.8210\n",
            "Epoch 48/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4081 - accuracy: 0.8256 - val_loss: 0.4223 - val_accuracy: 0.8214\n",
            "Epoch 49/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4092 - accuracy: 0.8255 - val_loss: 0.4090 - val_accuracy: 0.8214\n",
            "Epoch 50/50\n",
            "181/181 [==============================] - 1s 5ms/step - loss: 0.4064 - accuracy: 0.8255 - val_loss: 0.4079 - val_accuracy: 0.8214\n"
          ]
        }
      ],
      "source": [
        "# provide the model with the perturbation parameters and use @prepare_batch to apply them and \n",
        "# return attack input instance from a picture that the model will recognise\n",
        "attack_model.fit(r, d, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAveNFNrvrX"
      },
      "source": [
        "## Attack Evaluation\n",
        "\n",
        "Use prepare batch to transform the evaluation dataset and give it to the model.\n",
        "\n",
        "If previously fitted prepare batch will already have a value for $r$ and $d$ of pertubations, otherwise the user might set them with the following snippet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHeNGGZ8yzpi"
      },
      "outputs": [],
      "source": [
        "attack_model.r = 2\n",
        "attack_model.d = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9GxZE5Yntpw"
      },
      "outputs": [],
      "source": [
        "D_in = attack_model.prepare_batch(target_model, train_images[:500], train_labels[:500], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCPLb3aXIu2V"
      },
      "outputs": [],
      "source": [
        "D_out = attack_model.prepare_batch(target_model, attacker_images[:500], attacker_labels[:500], False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "8wDNdLqnnyVp",
        "outputId": "508ff424-a343-4b09-ae3b-5eab3d7b37fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class-1 acc: 0.8037382960319519\n",
            "class-2 acc: 0.7765957713127136\n",
            "class-3 acc: 0.8666666746139526\n",
            "class-4 acc: 0.8865979313850403\n",
            "class-5 acc: 0.8584905862808228\n",
            "class-6 acc: 0.8928571343421936\n",
            "class-7 acc: 0.8429751992225647\n",
            "class-8 acc: 0.8351648449897766\n",
            "class-9 acc: 0.6907216310501099\n",
            "class-10 acc: 0.8265306353569031\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.69      0.80       500\n",
            "         1.0       0.76      0.96      0.85       500\n",
            "\n",
            "    accuracy                           0.83      1000\n",
            "   macro avg       0.85      0.83      0.82      1000\n",
            "weighted avg       0.85      0.83      0.82      1000\n",
            "\n",
            "AUC: 0.847054\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "attack_model.evaluate(np.concatenate((D_out[:, :-1], D_in[:, :-1])),  np.concatenate((D_out[:, -1], D_in[:, -1])), 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grjprA4PmE7"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9g2jus3rP1j"
      },
      "source": [
        "## Check target model's behaviour in perturbed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD5YbfusfCob"
      },
      "outputs": [],
      "source": [
        "def study_perturbations(model, X, y, rs, ts):\n",
        "  diffs = []\n",
        "  y_pred = target_predict(model, X)    \n",
        "  for c in range(10):\n",
        "    #  given class acquire the changes in perturbed input instances given the model\n",
        "    idx = y_pred[:, 0] == c\n",
        "    X_c = X[idx]\n",
        "    y_pred_c = y_pred[idx]\n",
        "    perturbed_labels = augmented_queries(model, X_c, y_pred_c, rs, ts)\n",
        "    # Now we have to count how many labels diverge from the predicted label\n",
        "    diff = len(perturbed_labels.reshape(-1)) - sum(perturbed_labels.reshape(-1)) # the labels are binary where 1 == y_pred = y_perturbed, otherwise 0\n",
        "    diffs.append(int(100 * diff/len(perturbed_labels.reshape(-1)))) # append the percentage of changes in the class sample\n",
        "    \n",
        "  return diffs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-0sJVhfbfQ3"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 100\n",
        "train_idx = np.random.choice(range(train_images.shape[0]), N_SAMPLES, replace=False)\n",
        "test_idx = np.random.choice(range(attacker_images.shape[0]), N_SAMPLES, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dpYCPdS0EA-p",
        "outputId": "23c1ae63-e9ec-4a77-db9d-8003e7696182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7fd540457690>,\n",
              " <matplotlib.axis.XTick at 0x7fd53ff9fad0>,\n",
              " <matplotlib.axis.XTick at 0x7fd53ff9f250>,\n",
              " <matplotlib.axis.XTick at 0x7fd541126a90>,\n",
              " <matplotlib.axis.XTick at 0x7fd540ff2910>,\n",
              " <matplotlib.axis.XTick at 0x7fd540d2f3d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd540f71f10>,\n",
              " <matplotlib.axis.XTick at 0x7fd540f71290>,\n",
              " <matplotlib.axis.XTick at 0x7fd5410ed390>,\n",
              " <matplotlib.axis.XTick at 0x7fd54108b310>,\n",
              " <matplotlib.axis.XTick at 0x7fd54108b350>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7fd5497ec490>,\n",
              " <matplotlib.axis.XTick at 0x7fd5497ec3d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd5497ec7d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd540d209d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd540d200d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54108b710>,\n",
              " <matplotlib.axis.XTick at 0x7fd541126f10>,\n",
              " <matplotlib.axis.XTick at 0x7fd540d94e90>,\n",
              " <matplotlib.axis.XTick at 0x7fd540d94f90>,\n",
              " <matplotlib.axis.XTick at 0x7fd540d941d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd540e85090>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7fd541372c50>,\n",
              " <matplotlib.axis.XTick at 0x7fd5413725d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd541372150>,\n",
              " <matplotlib.axis.XTick at 0x7fd54119a290>,\n",
              " <matplotlib.axis.XTick at 0x7fd54119ad90>,\n",
              " <matplotlib.axis.XTick at 0x7fd540e85e90>,\n",
              " <matplotlib.axis.XTick at 0x7fd54108bb10>,\n",
              " <matplotlib.axis.XTick at 0x7fd54119a3d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54119a310>,\n",
              " <matplotlib.axis.XTick at 0x7fd540ec1510>,\n",
              " <matplotlib.axis.XTick at 0x7fd540ec1310>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%')]"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# tests in D_in\n",
        "diffs_per_class_D_in = study_perturbations(target_model, train_images[train_idx], train_labels[train_idx], r, d) \n",
        "total_diffs_in = sum(diffs_per_class_D_in)/10\n",
        "axes[0].set_title('D_in predicted label divergence');\n",
        "axes[0].barh(list(range(10)), diffs_per_class_D_in, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "# tests in D_out  \n",
        "diffs_per_class_D_out= study_perturbations(target_model,attacker_images[test_idx],attacker_labels[test_idx], r, d)\n",
        "total_diffs_out = sum(diffs_per_class_D_out)/10\n",
        "axes[1].set_title('D_out predicted label divergence');\n",
        "axes[1].barh(list(range(10)), diffs_per_class_D_out, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "axes[2].set_title('Total predicted label divergence percentage');\n",
        "axes[2].barh([1, 0], [total_diffs_in, total_diffs_out], tick_label=['In', 'Out'])\n",
        "\n",
        "plt.setp(axes, xticks=range(0, 101, 10), xticklabels=[f'{i}%' for i in range(0, 101, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZOpEdcmCMXX"
      },
      "source": [
        "## Attack a perturbation trained model\n",
        "\n",
        "- We will apply augmentations to the dataset and re-train the target model.\n",
        "- The attacker **does not** know our augmentation settings, so he will train with a normal dataset of zero augmentations\n",
        "- We want to measure the quality of the attack when the target tries to defend MIAs by adding perturbed images of data samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cl0sR-1I_sG"
      },
      "outputs": [],
      "source": [
        "# We will defend against the same rotations and translations that the attack models uses (worst case for the attacker)\n",
        "rotates = create_rotates(r)\n",
        "translates = create_translates(d)\n",
        "\n",
        "X_train_aug = train_images\n",
        "X_eval_aug = eval_images\n",
        "y_train_aug = np.concatenate(tuple([train_labels] + [train_labels for rot in rotates] + [train_labels for tra in translates]))\n",
        "y_eval_aug = np.concatenate(tuple([eval_labels] + [eval_labels for rot in rotates] + [eval_labels for tra in translates]))\n",
        "\n",
        "\n",
        "\n",
        "for rot in rotates:\n",
        "  aug_x = apply_augment(train_images, rot, 'r')\n",
        "  X_train_aug = np.concatenate((X_train_aug,aug_x))\n",
        "  aug_x = apply_augment(eval_images, rot, 'r')\n",
        "  X_eval_aug = np.concatenate((X_eval_aug,aug_x))\n",
        "\n",
        "for tra in translates:\n",
        "  aug_x = apply_augment(train_images, tra, 'd')\n",
        "  X_train_aug = np.concatenate((X_train_aug,aug_x))\n",
        "  aug_x = apply_augment(eval_images, tra, 'd')\n",
        "  X_eval_aug = np.concatenate((X_eval_aug ,aug_x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaNvyxztuwED",
        "outputId": "c18b8543-2c2f-46e9-a61e-b05d8afeaf8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1375/1375 [==============================] - 19s 13ms/step - loss: 1.4369 - accuracy: 0.4849 - val_loss: 1.7567 - val_accuracy: 0.4453\n",
            "Epoch 2/10\n",
            "1375/1375 [==============================] - 18s 13ms/step - loss: 0.6120 - accuracy: 0.7916 - val_loss: 2.3232 - val_accuracy: 0.4479\n",
            "Epoch 3/10\n",
            "1375/1375 [==============================] - 18s 13ms/step - loss: 0.3004 - accuracy: 0.9025 - val_loss: 2.7799 - val_accuracy: 0.4576\n",
            "Epoch 4/10\n",
            "1375/1375 [==============================] - 18s 13ms/step - loss: 0.2099 - accuracy: 0.9358 - val_loss: 2.8301 - val_accuracy: 0.4597\n",
            "Epoch 5/10\n",
            "1375/1375 [==============================] - 17s 12ms/step - loss: 0.1913 - accuracy: 0.9427 - val_loss: 2.9066 - val_accuracy: 0.4625\n",
            "Epoch 6/10\n",
            "1375/1375 [==============================] - 18s 13ms/step - loss: 0.1556 - accuracy: 0.9532 - val_loss: 3.1514 - val_accuracy: 0.4544\n",
            "Epoch 7/10\n",
            "1375/1375 [==============================] - 17s 12ms/step - loss: 0.1516 - accuracy: 0.9562 - val_loss: 3.7347 - val_accuracy: 0.4517\n",
            "Epoch 8/10\n",
            "1375/1375 [==============================] - 17s 12ms/step - loss: 0.1487 - accuracy: 0.9572 - val_loss: 3.4636 - val_accuracy: 0.4518\n",
            "Epoch 9/10\n",
            "1375/1375 [==============================] - 18s 13ms/step - loss: 0.1311 - accuracy: 0.9639 - val_loss: 4.0093 - val_accuracy: 0.4675\n",
            "Epoch 10/10\n",
            "1375/1375 [==============================] - 18s 13ms/step - loss: 0.1283 - accuracy: 0.9642 - val_loss: 3.5604 - val_accuracy: 0.4278\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  X_train_aug = tf.convert_to_tensor(X_train_aug)\n",
        "  y_train_aug = tf.convert_to_tensor(y_train_aug)\n",
        "  X_eval_aug = tf.convert_to_tensor(X_eval_aug)\n",
        "  y_eval_aug = tf.convert_to_tensor(y_eval_aug)\n",
        "  target_model = f_target(X_train_aug, y_train_aug, X_eval_aug, y_eval_aug, epochs=10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsRYuPrCUBWl"
      },
      "source": [
        "The model is quite overfitted so now all that is left is to evaluate the attack model we created before on the newly trained and \"defended\" target model with perturbations in the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "zyt1sD06SBFa",
        "outputId": "9343bfbd-deb3-449a-cc4f-9eec022fcd39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "class-1 acc: 0.738095223903656\n",
            "class-2 acc: 0.7446808218955994\n",
            "class-3 acc: 0.8965517282485962\n",
            "class-4 acc: 0.9019607901573181\n",
            "class-5 acc: 0.8356807231903076\n",
            "class-6 acc: 0.816216230392456\n",
            "class-7 acc: 0.7710280418395996\n",
            "class-8 acc: 0.7864583134651184\n",
            "class-9 acc: 0.7464115023612976\n",
            "class-10 acc: 0.7802197933197021\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.64      0.76      1000\n",
            "         1.0       0.73      0.97      0.83      1000\n",
            "\n",
            "    accuracy                           0.80      2000\n",
            "   macro avg       0.84      0.80      0.80      2000\n",
            "weighted avg       0.84      0.80      0.80      2000\n",
            "\n",
            "AUC: 0.8526244999999999\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "D_in = attack_model.prepare_batch(target_model, train_images[:1000], train_labels[:1000], True)\n",
        "\n",
        "D_out = attack_model.prepare_batch(target_model, attacker_images[:1000], attacker_labels[:1000], False)\n",
        "\n",
        "attack_model.evaluate(np.concatenate((D_out[:, :-1], D_in[:, :-1])),  np.concatenate((D_out[:, -1], D_in[:, -1])), 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW_JINmBUgd_"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "To conclude if the model is more vulnerable, we must meassure the label divergence percentage in the adjusted-to-augmentations model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OWDU6N1uSCnA",
        "outputId": "7d1b5ebf-a3dd-4b4e-ce4d-8590948c712f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7fd54961edd0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54961e750>,\n",
              " <matplotlib.axis.XTick at 0x7fd547ee7f90>,\n",
              " <matplotlib.axis.XTick at 0x7fd5c0cdddd0>,\n",
              " <matplotlib.axis.XTick at 0x7fd5c12a4d50>,\n",
              " <matplotlib.axis.XTick at 0x7fd53feeb7d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd53feeb910>,\n",
              " <matplotlib.axis.XTick at 0x7fd53feeb9d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54144df50>,\n",
              " <matplotlib.axis.XTick at 0x7fd53feeb6d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54547a050>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7fd63007ae10>,\n",
              " <matplotlib.axis.XTick at 0x7fd63007ae90>,\n",
              " <matplotlib.axis.XTick at 0x7fd63007a690>,\n",
              " <matplotlib.axis.XTick at 0x7fd547ed3310>,\n",
              " <matplotlib.axis.XTick at 0x7fd547ed3850>,\n",
              " <matplotlib.axis.XTick at 0x7fd54966d1d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54966de50>,\n",
              " <matplotlib.axis.XTick at 0x7fd53acebd10>,\n",
              " <matplotlib.axis.XTick at 0x7fd54039d6d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54039d910>,\n",
              " <matplotlib.axis.XTick at 0x7fd54039ded0>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7fd5c1030490>,\n",
              " <matplotlib.axis.XTick at 0x7fd5c1030950>,\n",
              " <matplotlib.axis.XTick at 0x7fd5c10301d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54144d8d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd53b4787d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd5400453d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd540045fd0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54bd1f850>,\n",
              " <matplotlib.axis.XTick at 0x7fd54bd1f4d0>,\n",
              " <matplotlib.axis.XTick at 0x7fd54bd1f890>,\n",
              " <matplotlib.axis.XTick at 0x7fd54bd1f6d0>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%')]"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# test it onthe same data as we tested the non-adjusted to augmentation model\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# tests in D_in\n",
        "diffs_per_class_D_in = study_perturbations(target_model, train_images[train_idx], train_labels[train_idx], r, d) \n",
        "total_diffs_in = sum(diffs_per_class_D_in)/10\n",
        "axes[0].set_title('D_in predicted label divergence');\n",
        "axes[0].barh(list(range(10)), diffs_per_class_D_in, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "# tests in D_out  \n",
        "diffs_per_class_D_out= study_perturbations(target_model,attacker_images[test_idx],attacker_labels[test_idx], r, d)\n",
        "total_diffs_out = sum(diffs_per_class_D_out)/10\n",
        "axes[1].set_title('D_out predicted label divergence');\n",
        "axes[1].barh(list(range(10)), diffs_per_class_D_out, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "axes[2].set_title('Total predicted label divergence percentage');\n",
        "axes[2].barh([1, 0], [total_diffs_in, total_diffs_out], tick_label=['In', 'Out'])\n",
        "\n",
        "plt.setp(axes, xticks=range(0, 101, 10), xticklabels=[f'{i}%' for i in range(0, 101, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVyVo6yukPGH"
      },
      "source": [
        "We can see that the general percentage of predicted label divergence has fallen, **but** the confidence of the ML algorithm in predicting the label of perturbed instances of instances in $D_{in}$ is better that before and that is realized by the increase of the AUC value (~0.852 when before ~0.847). This means that the adjusted model is even more vulnerable and our attack predicts membership with high sensitivity to the predicted label changes."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cifar_10_labels_only_mia-v2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
