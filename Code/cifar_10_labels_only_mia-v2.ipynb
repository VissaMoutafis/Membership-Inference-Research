{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vzAuc5Xo3j2"
      },
      "source": [
        "# Label Only Membership Inference (Revisited on points)\n",
        "\n",
        "### Threat Model:\n",
        "\n",
        "- **Black Box** access to an overfitted classifier with no access to actual $D_{train}$\n",
        "- Predict API returns **only labels instead of confidence vectors**\n",
        "- We have some insight on the training data distribution, $D_{out}$ , **but** $D_{train} \\cap D_{out} = \\varnothing$\n",
        "\n",
        "\n",
        "### Attack Target: \n",
        "- Use a shadow model to attack local shadow models and extract membership leakage features\n",
        "- Use data perturbations in order to exploit test/training data approximation relevancies to the classification boundaries.\n",
        "- Perfom the boundary-based attack on the actual model\n",
        "\n",
        "### Evaluation Target\n",
        "- Score over $50\\%$ accuracy\n",
        "- Train attack model based on this assumption and compare with conf-vector attack\n",
        "\n",
        "Implemented based on [this paper](https://arxiv.org/abs/2007.14321)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_WQJ7j5n3B",
        "outputId": "c4c7fdd0-1953-4c08-dde5-3856e1500add"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# for image interpolation\n",
        "import scipy.ndimage.interpolation as interpolation\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from mia.attack_model import *\n",
        "from mia.label_only import *\n",
        "from mia.shadow_models import *\n",
        "from mia.utilities import *\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kv7Qon0qRTk"
      },
      "source": [
        "## Target Model\n",
        "\n",
        "### Model Architecture\n",
        "- 2 layers of 32 $3\\times 3$ Conv2D filters with Max Pooling\n",
        "- 2 layers of 64 $3\\times 3$ Conv2D filters with MaxPooling\n",
        "- Dense Layer of 512 neurons\n",
        "- Dense Output layer of 10 neurons\n",
        "- Each layer has ReLU activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zacp4ArauIET"
      },
      "outputs": [],
      "source": [
        "D_TARGET_SIZE = 7500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1qg7LkXX0zOF"
      },
      "outputs": [],
      "source": [
        "def f_target(X_train, y_train, X_test=None, y_test=None, epochs=100):\n",
        "  \"\"\"\n",
        "  Returns a trained target model, if test data are specified we will evaluate the model and print its accuracy\n",
        "  \"\"\"\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  if X_test is None or y_test is None:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_split=0.2)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_data=(X_test, y_test))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oy2NLipP75sX"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "# use the rest as testing - 'out' records\n",
        "attacker_labels = np.concatenate((train_labels[D_TARGET_SIZE:], test_labels))\n",
        "attacker_images = np.concatenate((train_images[D_TARGET_SIZE:], test_images))\n",
        "target_images = train_images[:D_TARGET_SIZE]\n",
        "target_labels = train_labels[:D_TARGET_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap02yKRT76RJ",
        "outputId": "8561f84f-585e-4d98-f5d3-fac642cfe05d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 6s 32ms/step - loss: 3.0323 - accuracy: 0.1070 - val_loss: 2.2735 - val_accuracy: 0.1400\n"
          ]
        }
      ],
      "source": [
        "train_images, eval_images, train_labels, eval_labels = train_test_split(target_images, target_labels, test_size=0.2, shuffle=True)\n",
        "target_model = f_target(train_images, train_labels, eval_images, eval_labels, epochs=100) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l--0MCg-elRq"
      },
      "source": [
        "### Perturbed Instance Behaviour\n",
        "\n",
        "Following we will apply some perturbations to data instances from in and out of $D_{target}$ and we will count how the predicted label change in respect to this perturbations, according to each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H0PYHLFrWJ1"
      },
      "source": [
        "\n",
        "\n",
        "## Shadow Models\n",
        "Following we define our own shadow models\n",
        "\n",
        "### Shadow Model Architecture\n",
        "- 3 CNN layers of $32, 64, 128$ filters of size $3 \\times 3$ with MaxPooling and ReLU activation\n",
        "- Dense Layer of 128 nodes\n",
        "- Dense Layer of 10 nodes as Output layer\n",
        "\n",
        "All output logits pass through Softmax Unit as in the target model to acquire probability vectors\n",
        "\n",
        "\n",
        "\n",
        "### Shadow Dataset Composition\n",
        "\n",
        "We just divide the CIFAR-10 dataset to $D_{out}$ and $D_{train}$ such as $D_{train} \\cap D_{out} = \\varnothing$ and use $D_{out}$ in order to train/test shadow models and attack model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2GWyCXmmwIiJ"
      },
      "outputs": [],
      "source": [
        "N_SHADOWS = 1\n",
        "D_SHADOW_SIZE = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2rwhySHfVQjV"
      },
      "outputs": [],
      "source": [
        "def f_shadow():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sliyw7xO2PTg"
      },
      "outputs": [],
      "source": [
        "# returns list of (trained shadow_model, D_shadow)\n",
        "def create_shadows(D_shadows):\n",
        "  shadow_models_bundle = ShadowModelBatch(len(D_shadows), f_shadow) # shadow model list\n",
        "  shadow_models_bundle.fit_all(D_shadows, epochs=50)\n",
        "  return shadow_models_bundle # return a list where every item is (model, acc), train-data, test-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q3ziH9LP3CY5"
      },
      "outputs": [],
      "source": [
        "# generate shadow datasets\n",
        "D_shadows = generate_shadow_dataset(target_model, N_SHADOWS, D_SHADOW_SIZE, 10, attacker_images, attacker_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc8morl-NRP",
        "outputId": "c803ef26-91a8-4ec0-fb7c-1107b08d945c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 268ms/step - loss: 13.5905 - accuracy: 0.1194 - val_loss: 10.7825 - val_accuracy: 0.0606\n"
          ]
        }
      ],
      "source": [
        "# train the shadow models\n",
        "shadow_models = create_shadows(D_shadows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJQxvjrfrfnW"
      },
      "source": [
        "## Attack Model\n",
        "\n",
        "### Attack Model Architecture\n",
        "The attack model is consisted of 1 swallow layer of 10 neurons just as proposed in Shokri et al. and in the relative label only attack paper.\n",
        "\n",
        "\n",
        "### Attack Dataset\n",
        "The attack dataset will be consisted of vectors $x_i$, s.t. $x_i$ contains:\n",
        "- real label\n",
        "- predicted label\n",
        "- bitstring of length $n'$, where $x_{ij+2}, \\; j \\in \\{1, ..., n'\\} $ will be 1 if perturbed label is same as predicted, otherwise it'll be zero.\n",
        "\n",
        "\n",
        "### Perturbed Queries for feature extraction and Attack Dataset\n",
        "\n",
        "In order to construct the actual attack dataset we have 2 perturbation functions:\n",
        "- Translate\n",
        "- Rotate\n",
        "\n",
        "that can apply the necessary augmentations in order to acquire the feature vector for a query.\n",
        "\n",
        "This works by applying all augmentations to the input X and querying the target model in order to return a binary vector $x_{attack}$ where $$x_{attack_p} = 1 \\; if \\;y_p == y_{true} \\; else \\; 0, \\forall p \\in Perturbations(X)$$\n",
        "\n",
        "where $y_p$ is the label for pertubation $p$ of input $X$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SrhUttNV1jR6"
      },
      "outputs": [],
      "source": [
        "r = 3 # rotate range => creating 2*r+1 rotations \n",
        "d = 1 # translate range =? creating 4*d + 1 translates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gnhE29HBBYGy"
      },
      "outputs": [],
      "source": [
        "# input dims = 2*r(# of rotates - neutral)  + 4*d(# of translates - neutral) + 2 (y_pred, y_true)\n",
        "attack_model = LabelOnlyAttackModel(shadow_models, 10, (2*r+4*d+2,), 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_model.fit(r, d, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bdgsVbiFk3B",
        "outputId": "d02f9a95-f657-4dee-90f9-c6baae3f8b7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing shadow batch of size 66\n",
            "Done!\n",
            "2/2 [==============================] - 2s 367ms/step - loss: 0.9531 - accuracy: 0.4783 - val_loss: 0.8621 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAveNFNrvrX"
      },
      "source": [
        "## Attack Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "g9GxZE5Yntpw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "68fdd1e4-bb02-4030-f543-7e0d59bcc8e8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b1cede7abce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/mia/label_only.py\u001b[0m in \u001b[0;36mprepare_batch\u001b[0;34m(self, model, X, y, in_D)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mperturbed_queries_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmented_queries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# return an instance <actual class, predicted class, perturbed_queries_res from shadow models, 'in'/'out' D_target membership>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mia/label_only.py\u001b[0m in \u001b[0;36maugmented_queries\u001b[0;34m(model, X, y_pred, r, d)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# skip the no translation augment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtra\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mX_perturbed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;31m# return query line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my_perturbed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_perturbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/mia/utilities.py\u001b[0m in \u001b[0;36mapply_augment\u001b[0;34m(d, augment, type_)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36mshift\u001b[0;34m(input, shift, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m     \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzoom_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "D_in = attack_model.prepare_batch(target_model, train_images[:500], train_labels[:500], True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_out = attack_model.prepare_batch(target_model, attacker_images[:500], attacker_labels[:500], False)"
      ],
      "metadata": {
        "id": "GCPLb3aXIu2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wDNdLqnnyVp"
      },
      "outputs": [],
      "source": [
        "y_pred = (attack_model.predict(np.concatenate((D_out[:, :-1], D_in[:, :-1]))) > 0.5).astype(np.int8)\n",
        "y_true = np.concatenate((D_out[:, -1], D_in[:, -1]))\n",
        "print(classification_report(y_true.reshape(-1), y_pred.reshape(-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8aQH6Nqp3Ah"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred = attack_model.predict(np.concatenate((D_out[:, :-1], D_in[:, :-1])))\n",
        "y_true = np.concatenate((D_out[:, -1], D_in[:, -1]))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "\n",
        "print(f\"AUC = {roc_auc_score(y_true, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grjprA4PmE7"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9g2jus3rP1j"
      },
      "source": [
        "## Check target model's behaviour in perturbed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sD5YbfusfCob"
      },
      "outputs": [],
      "source": [
        "def study_perturbations(model, X, y, rs, ts):\n",
        "  diffs = []\n",
        "  y_pred = target_predict(model, X)    \n",
        "  for c in range(10):\n",
        "    #  given class acquire the changes in perturbed input instances given the model\n",
        "    idx = y_pred[:, 0] == c\n",
        "    X_c = X[idx]\n",
        "    y_pred_c = y_pred[idx]\n",
        "    perturbed_labels = (augmented_queries(model, X_c, y_pred_c, rs, ts) == y_pred_c).astype(np.int8)\n",
        "    # Now we have to count how many labels diverge from the predicted label\n",
        "    diff = len(perturbed_labels.reshape(-1)) - sum(perturbed_labels.reshape(-1)) # the labels are binary where 1 == y_pred = y_perturbed, otherwise 0\n",
        "    diffs.append(int(100 * diff/len(perturbed_labels.reshape(-1)))) # append the percentage of changes in the class sample\n",
        "    \n",
        "  return diffs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-0sJVhfbfQ3"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 100\n",
        "train_idx = np.random.choice(range(train_images.shape[0]), N_SAMPLES, replace=False)\n",
        "test_idx = np.random.choice(range(attacker_images.shape[0]), N_SAMPLES, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpYCPdS0EA-p"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# tests in D_in\n",
        "diffs_per_class_D_in = study_perturbations(target_model, train_images[train_idx], train_labels[train_idx], r, d) \n",
        "total_diffs_in = sum(diffs_per_class_D_in)/10\n",
        "axes[0].set_title('D_in predicted label divergence');\n",
        "axes[0].barh(list(range(10)), diffs_per_class_D_in, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "# tests in D_out  \n",
        "diffs_per_class_D_out= study_perturbations(target_model,attacker_images[test_idx],attacker_labels[test_idx], r, d)\n",
        "total_diffs_out = sum(diffs_per_class_D_out)/10\n",
        "axes[1].set_title('D_out predicted label divergence');\n",
        "axes[1].barh(list(range(10)), diffs_per_class_D_out, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "axes[2].set_title('Total predicted label divergence percentage');\n",
        "axes[2].barh([1, 0], [total_diffs_in, total_diffs_out], tick_label=['In', 'Out'])\n",
        "\n",
        "plt.setp(axes, xticks=range(0, 101, 10), xticklabels=[f'{i}%' for i in range(0, 101, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZOpEdcmCMXX"
      },
      "source": [
        "## Attack a perturbation trained model\n",
        "\n",
        "- We will apply augmentations to the dataset and re-train the target model.\n",
        "- The attacker **does not** know our augmentation settings, so he will train with a normal dataset of zero augmentations\n",
        "- We want to measure the quality of the attack when the target tries to defend MIAs by adding perturbed images of data samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cl0sR-1I_sG"
      },
      "outputs": [],
      "source": [
        "# We will defend against the same rotations and translations that the attack models uses (worst case for the attacker)\n",
        "rotates = create_rotates(r)\n",
        "translates = create_translates(d)\n",
        "\n",
        "X_train_aug = train_images\n",
        "X_eval_aug = eval_images\n",
        "y_train_aug = np.concatenate(tuple([train_labels] + [train_labels for rot in rotates] + [train_labels for tra in translates]))\n",
        "y_eval_aug = np.concatenate(tuple([eval_labels] + [eval_labels for rot in rotates] + [eval_labels for tra in translates]))\n",
        "\n",
        "\n",
        "\n",
        "for rot in rotates:\n",
        "  aug_x = apply_augment(train_images, rot, 'r')\n",
        "  X_train_aug = np.concatenate((X_train_aug,aug_x))\n",
        "  aug_x = apply_augment(eval_images, rot, 'r')\n",
        "  X_eval_aug = np.concatenate((X_eval_aug,aug_x))\n",
        "\n",
        "for tra in translates:\n",
        "  aug_x = apply_augment(train_images, tra, 'd')\n",
        "  X_train_aug = np.concatenate((X_train_aug,aug_x))\n",
        "  aug_x = apply_augment(eval_images, tra, 'd')\n",
        "  X_eval_aug = np.concatenate((X_eval_aug ,aug_x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaNvyxztuwED"
      },
      "outputs": [],
      "source": [
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  X_train_aug = tf.convert_to_tensor(X_train_aug)\n",
        "  y_train_aug = tf.convert_to_tensor(y_train_aug)\n",
        "  X_eval_aug = tf.convert_to_tensor(X_eval_aug)\n",
        "  y_eval_aug = tf.convert_to_tensor(y_eval_aug)\n",
        "  target_model = f_target(X_train_aug, y_train_aug, X_eval_aug, y_eval_aug, epochs=10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsRYuPrCUBWl"
      },
      "source": [
        "The model is quite overfitted so now all that is left is to evaluate the attack model we created before on the newly trained and \"defended\" target model with perturbations in the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyt1sD06SBFa"
      },
      "outputs": [],
      "source": [
        "D_in = prepare_batch(target_model, train_images[:1000], train_labels[:1000], True)\n",
        "print(\"Testing with 'in' data only:\")\n",
        "res_in = evaluate_attack(attack_model_bundle, D_in[:, :-1], D_in[:, -1], 10)\n",
        "\n",
        "D_out = prepare_batch(target_model, attacker_images[:1000], attacker_labels[:1000], False)\n",
        "print(\"\\nTesting with 'out' data only:\")\n",
        "res_out = evaluate_attack(attack_model_bundle, D_out[:, :-1], D_out[:, -1], 10)\n",
        "\n",
        "print(\"\\nTesting with all prev data: \")\n",
        "res_all = evaluate_attack(attack_model_bundle, np.concatenate((D_out[:, :-1], D_in[:, :-1])), np.concatenate((D_out[:, -1], D_in[:, -1])), 10)\n",
        "\n",
        "print(f\"\\nTotal attack accuracy: {np.mean(res_all)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW_JINmBUgd_"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "To conclude if the model is more vulnerable, we must meassure the label divergence percentage in the adjusted-to-augmentations model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWDU6N1uSCnA"
      },
      "outputs": [],
      "source": [
        "# test it onthe same data as we tested the non-adjusted to augmentation model\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# tests in D_in\n",
        "diffs_per_class_D_in = study_perturbations(target_model, train_images[train_idx], train_labels[train_idx], r, d) \n",
        "total_diffs_in = sum(diffs_per_class_D_in)/10\n",
        "axes[0].set_title('D_in predicted label divergence');\n",
        "axes[0].barh(list(range(10)), diffs_per_class_D_in, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "# tests in D_out  \n",
        "diffs_per_class_D_out= study_perturbations(target_model,attacker_images[test_idx],attacker_labels[test_idx], r, d)\n",
        "total_diffs_out = sum(diffs_per_class_D_out)/10\n",
        "axes[1].set_title('D_out predicted label divergence');\n",
        "axes[1].barh(list(range(10)), diffs_per_class_D_out, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "axes[2].set_title('Total predicted label divergence percentage');\n",
        "axes[2].barh([1, 0], [total_diffs_in, total_diffs_out], tick_label=['In', 'Out'])\n",
        "\n",
        "plt.setp(axes, xticks=range(0, 101, 10), xticklabels=[f'{i}%' for i in range(0, 101, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVyVo6yukPGH"
      },
      "source": [
        "We can see that the general percentage of predicted label divergence has fallen, **but** the confidence of the ML algorithm in predicting the label of perturbed instances of instances in $D_{in}$ is even higher that before. This means that the adjusted model is even more vulnerable. Next step is to run all that with a well-generalized model and tune the attack model to get max accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXk2DEHBc9i9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cifar_10_labels_only_mia.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}