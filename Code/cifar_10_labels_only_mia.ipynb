{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_10_labels_only_mia.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vzAuc5Xo3j2"
      },
      "source": [
        "# Label Only Membership Inference\n",
        "\n",
        "### Attack Scenario:\n",
        "\n",
        "- **Black Box** access to an overfitted classifier with no access to actual $D_{train}$\n",
        "- Predict API returns **only labels instead of confidence vectors**\n",
        "- We have some samples over the training data distribution, $D_{out}$, such that $D_{train} \\cap D_{out} = \\varnothing$\n",
        "\n",
        "\n",
        "### Attack Target: \n",
        "- Use a shadow model to attack locally and extract membership leakage features\n",
        "- Use data perturbations in order to exploit test/training data approximation relevancies to the classification boundaries.\n",
        "- Train attack model based on this assumption and compare with original attack\n",
        "\n",
        "Implemented based on [this paper](https://arxiv.org/abs/2007.14321)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_WQJ7j5n3B",
        "outputId": "2807eb05-5f22-4ad8-bc16-de9da25592cc"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# for image interpolation\n",
        "import scipy.ndimage.interpolation as interpolation\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kv7Qon0qRTk"
      },
      "source": [
        "## Target Model\n",
        "\n",
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zacp4ArauIET"
      },
      "source": [
        "D_TARGET_SIZE = 5000"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qg7LkXX0zOF"
      },
      "source": [
        "def f_target(X_train, y_train, X_test=None, y_test=None, epochs=100):\n",
        "  \"\"\"\n",
        "  Returns a trained target model, if test data are specified we will evaluate the model and print its accuracy\n",
        "  \"\"\"\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  if X_test is None or y_test is None:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_split=0.2)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_data=(X_test, y_test))\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy2NLipP75sX"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "  # use the rest as testing - 'out' records\n",
        "  attacker_labels = np.concatenate((train_labels[D_TARGET_SIZE:], test_labels))\n",
        "  attacker_images = np.concatenate((train_images[D_TARGET_SIZE:], test_images))\n",
        "\n",
        "  target_images = train_images[:D_TARGET_SIZE] # as the paper attack train wiht only 200 records\n",
        "  target_labels = train_labels[:D_TARGET_SIZE]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap02yKRT76RJ",
        "outputId": "2ed2be90-a3af-4a76-9a86-97b607bcf370"
      },
      "source": [
        "with tf.device('/gpu:0'):\n",
        "  train_images, eval_images, train_labels, eval_labels = train_test_split(target_images, target_labels, test_size=0.2, shuffle=True)\n",
        "  target_model = f_target(train_images, train_labels, eval_images, eval_labels, epochs=50) "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 2s 14ms/step - loss: 2.7939 - accuracy: 0.2607 - val_loss: 1.7532 - val_accuracy: 0.3500\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.6711 - accuracy: 0.3950 - val_loss: 1.6645 - val_accuracy: 0.3940\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.3869 - accuracy: 0.5030 - val_loss: 1.6758 - val_accuracy: 0.4360\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1.1940 - accuracy: 0.5738 - val_loss: 1.6875 - val_accuracy: 0.4420\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.9532 - accuracy: 0.6643 - val_loss: 1.7678 - val_accuracy: 0.4170\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.7063 - accuracy: 0.7550 - val_loss: 1.8221 - val_accuracy: 0.4730\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.4779 - accuracy: 0.8322 - val_loss: 2.0317 - val_accuracy: 0.4760\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.3453 - accuracy: 0.8830 - val_loss: 2.2546 - val_accuracy: 0.4430\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2219 - accuracy: 0.9240 - val_loss: 2.7407 - val_accuracy: 0.4400\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1752 - accuracy: 0.9427 - val_loss: 3.4043 - val_accuracy: 0.4380\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1738 - accuracy: 0.9465 - val_loss: 3.0610 - val_accuracy: 0.4480\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1994 - accuracy: 0.9325 - val_loss: 3.2853 - val_accuracy: 0.4310\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1030 - accuracy: 0.9657 - val_loss: 3.1772 - val_accuracy: 0.4670\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1284 - accuracy: 0.9597 - val_loss: 3.7464 - val_accuracy: 0.4230\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1423 - accuracy: 0.9592 - val_loss: 3.7429 - val_accuracy: 0.4430\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1229 - accuracy: 0.9645 - val_loss: 3.7214 - val_accuracy: 0.4560\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1243 - accuracy: 0.9620 - val_loss: 3.9778 - val_accuracy: 0.4460\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1356 - accuracy: 0.9575 - val_loss: 3.6999 - val_accuracy: 0.4300\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0855 - accuracy: 0.9753 - val_loss: 3.9016 - val_accuracy: 0.4220\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0906 - accuracy: 0.9712 - val_loss: 4.1342 - val_accuracy: 0.4410\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0866 - accuracy: 0.9750 - val_loss: 4.1673 - val_accuracy: 0.4450\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0677 - accuracy: 0.9787 - val_loss: 4.8731 - val_accuracy: 0.4570\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1535 - accuracy: 0.9545 - val_loss: 4.5696 - val_accuracy: 0.4260\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0725 - accuracy: 0.9758 - val_loss: 5.1385 - val_accuracy: 0.4390\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1412 - accuracy: 0.9595 - val_loss: 4.3040 - val_accuracy: 0.4230\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0808 - accuracy: 0.9760 - val_loss: 4.6975 - val_accuracy: 0.4170\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0638 - accuracy: 0.9795 - val_loss: 4.3668 - val_accuracy: 0.4620\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0479 - accuracy: 0.9865 - val_loss: 4.5549 - val_accuracy: 0.4390\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0712 - accuracy: 0.9780 - val_loss: 4.7646 - val_accuracy: 0.4230\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0833 - accuracy: 0.9775 - val_loss: 5.3131 - val_accuracy: 0.4190\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.2115 - accuracy: 0.9442 - val_loss: 4.6947 - val_accuracy: 0.4190\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1407 - accuracy: 0.9590 - val_loss: 4.6052 - val_accuracy: 0.4310\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0670 - accuracy: 0.9795 - val_loss: 4.6733 - val_accuracy: 0.4460\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 5.3397 - val_accuracy: 0.4560\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.1350 - accuracy: 0.9592 - val_loss: 4.2978 - val_accuracy: 0.4220\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0615 - accuracy: 0.9812 - val_loss: 4.7589 - val_accuracy: 0.4320\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 5.1714 - val_accuracy: 0.4490\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 0.9962 - val_loss: 4.9033 - val_accuracy: 0.4540\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0120 - accuracy: 0.9970 - val_loss: 5.1638 - val_accuracy: 0.4660\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0503 - accuracy: 0.9850 - val_loss: 5.4326 - val_accuracy: 0.4570\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.2302 - accuracy: 0.9345 - val_loss: 4.3891 - val_accuracy: 0.4370\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0812 - accuracy: 0.9755 - val_loss: 4.8364 - val_accuracy: 0.4370\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.1046 - accuracy: 0.9720 - val_loss: 5.5609 - val_accuracy: 0.4270\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0819 - accuracy: 0.9783 - val_loss: 5.4111 - val_accuracy: 0.4320\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0934 - accuracy: 0.9747 - val_loss: 5.2118 - val_accuracy: 0.4310\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 5.4086 - val_accuracy: 0.4420\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0336 - accuracy: 0.9912 - val_loss: 5.8604 - val_accuracy: 0.4340\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 5.7568 - val_accuracy: 0.4250\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0473 - accuracy: 0.9868 - val_loss: 5.9272 - val_accuracy: 0.4310\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 0.0924 - accuracy: 0.9745 - val_loss: 5.7188 - val_accuracy: 0.4220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9I5lKSrSsU"
      },
      "source": [
        "### Target Model prediction API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvocFuQeVLsM"
      },
      "source": [
        "# API of model to get predictions : returns labels only\n",
        "def target_predict(X):\n",
        "  prob = layers.Softmax()\n",
        "  ret = prob(target_model.predict(X)).numpy()\n",
        "  return np.apply_along_axis(np.argmax, 1, ret).reshape((-1, 1))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H0PYHLFrWJ1"
      },
      "source": [
        "## Shadow Models\n",
        "\n",
        "### Shadow Model Architecture\n",
        "\n",
        "### Shadow Dataset Composition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GWyCXmmwIiJ"
      },
      "source": [
        "N_SHADOWS = 5\n",
        "D_SHADOW_SIZE = D_TARGET_SIZE"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rwhySHfVQjV"
      },
      "source": [
        "def f_shadow(X_train, y_train, X_test=None, y_test=None, epochs=25):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10)   )\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  if X_test is None or y_test is None:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_split=0.2)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_data=(X_test, y_test))\n",
        "  return model"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sliyw7xO2PTg"
      },
      "source": [
        "\n",
        "def divide_dataset(n_shadows, shadow_dataset_size, X, y):\n",
        "  D_shadows = []\n",
        "  rng = np.random.default_rng()\n",
        "  for i in range(n_shadows):\n",
        "    sample_i = np.random.choice(range(X.shape[0]), shadow_dataset_size, replace=False)\n",
        "    assert np.unique(sample_i).shape[0] == shadow_dataset_size # sanity check\n",
        "    D_shadows.append((X[sample_i, :], y[sample_i, :]))\n",
        "  return D_shadows\n",
        "\n",
        "# returns a list of 'n_shadows' datasets\n",
        "def generate_shadow_dataset(target_model, n_shadows, shadow_dataset_size, n_classes, attacker_X=None, attacker_y=None):\n",
        "  # param target model is not used yet\n",
        "\n",
        "\n",
        "  # in case we give test data we will just divide those to train the shadow models\n",
        "  if attacker_X is not None and attacker_y is not None:\n",
        "    return divide_dataset(n_shadows, shadow_dataset_size, attacker_X, attacker_y)\n",
        "  else:\n",
        "    raise ValueError(\"X and y provided are None.\")\n",
        "\n",
        "\n",
        "def create_shadows(D_shadows):\n",
        "  shadow_models = [] # shadow model list\n",
        "\n",
        "  for D_shadow in D_shadows:\n",
        "    # sample data to feed/evaluate the model\n",
        "    X_shadow, y_shadow = D_shadow\n",
        "    shadow_X_train, shadow_X_test, shadow_y_train, shadow_y_test = train_test_split(X_shadow, y_shadow, shuffle=True, test_size=0.33)\n",
        "\n",
        "    # generate the shadow model\n",
        "    shadow_model = f_shadow(shadow_X_train, shadow_y_train, shadow_X_test, shadow_y_test)\n",
        "\n",
        "    D_shadow = (shadow_X_train, shadow_y_train), (shadow_X_test, shadow_y_test)\n",
        "    shadow_models.append((shadow_model, D_shadow))\n",
        "\n",
        "  return shadow_models # return a list where every item is (model, acc), train-data, test-data"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ziH9LP3CY5"
      },
      "source": [
        "# generate shadow datasets\n",
        "D_shadows = generate_shadow_dataset(target_model, N_SHADOWS, D_SHADOW_SIZE, 10, attacker_images, attacker_labels)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dc8morl-NRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a80525-c241-4d9e-e3ee-0cd38694c776"
      },
      "source": [
        "# train the shadow models\n",
        "shadow_models = create_shadows(D_shadows)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "105/105 [==============================] - 2s 12ms/step - loss: 3.8200 - accuracy: 0.2063 - val_loss: 1.9782 - val_accuracy: 0.2830\n",
            "Epoch 2/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.7742 - accuracy: 0.3681 - val_loss: 1.7709 - val_accuracy: 0.3667\n",
            "Epoch 3/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.5488 - accuracy: 0.4439 - val_loss: 1.7136 - val_accuracy: 0.4055\n",
            "Epoch 4/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.3893 - accuracy: 0.5015 - val_loss: 1.7024 - val_accuracy: 0.4121\n",
            "Epoch 5/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.2463 - accuracy: 0.5588 - val_loss: 1.6513 - val_accuracy: 0.4424\n",
            "Epoch 6/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.0952 - accuracy: 0.6176 - val_loss: 1.7492 - val_accuracy: 0.4236\n",
            "Epoch 7/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.9299 - accuracy: 0.6740 - val_loss: 1.7580 - val_accuracy: 0.4461\n",
            "Epoch 8/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.8034 - accuracy: 0.7099 - val_loss: 1.8646 - val_accuracy: 0.4400\n",
            "Epoch 9/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.6409 - accuracy: 0.7830 - val_loss: 2.0537 - val_accuracy: 0.4315\n",
            "Epoch 10/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.5170 - accuracy: 0.8182 - val_loss: 2.3200 - val_accuracy: 0.4467\n",
            "Epoch 11/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.4278 - accuracy: 0.8490 - val_loss: 2.2959 - val_accuracy: 0.4533\n",
            "Epoch 12/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.4071 - accuracy: 0.8594 - val_loss: 2.4449 - val_accuracy: 0.4352\n",
            "Epoch 13/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2872 - accuracy: 0.9051 - val_loss: 2.6206 - val_accuracy: 0.4491\n",
            "Epoch 14/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2463 - accuracy: 0.9179 - val_loss: 2.9183 - val_accuracy: 0.4455\n",
            "Epoch 15/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1864 - accuracy: 0.9379 - val_loss: 3.3130 - val_accuracy: 0.4345\n",
            "Epoch 16/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1400 - accuracy: 0.9546 - val_loss: 3.4836 - val_accuracy: 0.4376\n",
            "Epoch 17/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2464 - accuracy: 0.9107 - val_loss: 3.3379 - val_accuracy: 0.4279\n",
            "Epoch 18/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2916 - accuracy: 0.8985 - val_loss: 3.1287 - val_accuracy: 0.4352\n",
            "Epoch 19/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1576 - accuracy: 0.9493 - val_loss: 3.8539 - val_accuracy: 0.4248\n",
            "Epoch 20/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1933 - accuracy: 0.9337 - val_loss: 3.6858 - val_accuracy: 0.4121\n",
            "Epoch 21/25\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 0.1764 - accuracy: 0.9442 - val_loss: 3.6479 - val_accuracy: 0.4406\n",
            "Epoch 22/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1665 - accuracy: 0.9421 - val_loss: 4.1344 - val_accuracy: 0.4030\n",
            "Epoch 23/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1309 - accuracy: 0.9564 - val_loss: 4.2438 - val_accuracy: 0.4303\n",
            "Epoch 24/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9534 - val_loss: 4.4228 - val_accuracy: 0.4212\n",
            "Epoch 25/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9382 - val_loss: 4.3535 - val_accuracy: 0.4285\n",
            "Epoch 1/25\n",
            "105/105 [==============================] - 2s 13ms/step - loss: 5.1067 - accuracy: 0.1851 - val_loss: 2.0073 - val_accuracy: 0.2697\n",
            "Epoch 2/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.8573 - accuracy: 0.3239 - val_loss: 1.8852 - val_accuracy: 0.3309\n",
            "Epoch 3/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.6900 - accuracy: 0.3755 - val_loss: 1.7316 - val_accuracy: 0.3703\n",
            "Epoch 4/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.4478 - accuracy: 0.4782 - val_loss: 1.7584 - val_accuracy: 0.3921\n",
            "Epoch 5/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.2923 - accuracy: 0.5304 - val_loss: 1.7223 - val_accuracy: 0.3958\n",
            "Epoch 6/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.1538 - accuracy: 0.5851 - val_loss: 1.7520 - val_accuracy: 0.4261\n",
            "Epoch 7/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.0117 - accuracy: 0.6436 - val_loss: 1.8420 - val_accuracy: 0.4200\n",
            "Epoch 8/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.8992 - accuracy: 0.6887 - val_loss: 1.8923 - val_accuracy: 0.4352\n",
            "Epoch 9/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.7356 - accuracy: 0.7430 - val_loss: 1.9863 - val_accuracy: 0.4370\n",
            "Epoch 10/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.6256 - accuracy: 0.7836 - val_loss: 2.3799 - val_accuracy: 0.4091\n",
            "Epoch 11/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.5787 - accuracy: 0.8060 - val_loss: 2.2820 - val_accuracy: 0.4212\n",
            "Epoch 12/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.4834 - accuracy: 0.8260 - val_loss: 2.5530 - val_accuracy: 0.4224\n",
            "Epoch 13/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3853 - accuracy: 0.8627 - val_loss: 2.6414 - val_accuracy: 0.4248\n",
            "Epoch 14/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3399 - accuracy: 0.8830 - val_loss: 2.7833 - val_accuracy: 0.4206\n",
            "Epoch 15/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2847 - accuracy: 0.8967 - val_loss: 2.9607 - val_accuracy: 0.4273\n",
            "Epoch 16/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2569 - accuracy: 0.9122 - val_loss: 3.0129 - val_accuracy: 0.4521\n",
            "Epoch 17/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9293 - val_loss: 3.2888 - val_accuracy: 0.4333\n",
            "Epoch 18/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2756 - accuracy: 0.9110 - val_loss: 3.2482 - val_accuracy: 0.4364\n",
            "Epoch 19/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3475 - accuracy: 0.8788 - val_loss: 3.4556 - val_accuracy: 0.4176\n",
            "Epoch 20/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2478 - accuracy: 0.9191 - val_loss: 3.3464 - val_accuracy: 0.4321\n",
            "Epoch 21/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1800 - accuracy: 0.9466 - val_loss: 3.5754 - val_accuracy: 0.4236\n",
            "Epoch 22/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2260 - accuracy: 0.9269 - val_loss: 3.5213 - val_accuracy: 0.4352\n",
            "Epoch 23/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1791 - accuracy: 0.9442 - val_loss: 4.1941 - val_accuracy: 0.4018\n",
            "Epoch 24/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2474 - accuracy: 0.9137 - val_loss: 3.9724 - val_accuracy: 0.4152\n",
            "Epoch 25/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1469 - accuracy: 0.9537 - val_loss: 4.0393 - val_accuracy: 0.4406\n",
            "Epoch 1/25\n",
            "105/105 [==============================] - 2s 13ms/step - loss: 4.2520 - accuracy: 0.2096 - val_loss: 2.0398 - val_accuracy: 0.2479\n",
            "Epoch 2/25\n",
            "105/105 [==============================] - 1s 9ms/step - loss: 1.8578 - accuracy: 0.3287 - val_loss: 1.8963 - val_accuracy: 0.2988\n",
            "Epoch 3/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.6708 - accuracy: 0.3896 - val_loss: 1.7262 - val_accuracy: 0.3655\n",
            "Epoch 4/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.5629 - accuracy: 0.4424 - val_loss: 1.6585 - val_accuracy: 0.3952\n",
            "Epoch 5/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.3964 - accuracy: 0.5054 - val_loss: 1.6837 - val_accuracy: 0.4091\n",
            "Epoch 6/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.2625 - accuracy: 0.5522 - val_loss: 1.6296 - val_accuracy: 0.4485\n",
            "Epoch 7/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.1554 - accuracy: 0.5922 - val_loss: 1.6898 - val_accuracy: 0.4352\n",
            "Epoch 8/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.0055 - accuracy: 0.6385 - val_loss: 1.8541 - val_accuracy: 0.4121\n",
            "Epoch 9/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.8950 - accuracy: 0.6782 - val_loss: 1.9443 - val_accuracy: 0.4345\n",
            "Epoch 10/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.7918 - accuracy: 0.7203 - val_loss: 1.9034 - val_accuracy: 0.4436\n",
            "Epoch 11/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.7121 - accuracy: 0.7475 - val_loss: 2.0517 - val_accuracy: 0.4570\n",
            "Epoch 12/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.5743 - accuracy: 0.8009 - val_loss: 2.2735 - val_accuracy: 0.4194\n",
            "Epoch 13/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.5031 - accuracy: 0.8263 - val_loss: 2.3856 - val_accuracy: 0.4370\n",
            "Epoch 14/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.4670 - accuracy: 0.8400 - val_loss: 2.3518 - val_accuracy: 0.4485\n",
            "Epoch 15/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3664 - accuracy: 0.8776 - val_loss: 2.8733 - val_accuracy: 0.4358\n",
            "Epoch 16/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2599 - accuracy: 0.9078 - val_loss: 2.9764 - val_accuracy: 0.4418\n",
            "Epoch 17/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2355 - accuracy: 0.9140 - val_loss: 3.1225 - val_accuracy: 0.4206\n",
            "Epoch 18/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3642 - accuracy: 0.8797 - val_loss: 3.0041 - val_accuracy: 0.4261\n",
            "Epoch 19/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2432 - accuracy: 0.9191 - val_loss: 3.1035 - val_accuracy: 0.4273\n",
            "Epoch 20/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1764 - accuracy: 0.9427 - val_loss: 3.3360 - val_accuracy: 0.4327\n",
            "Epoch 21/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2855 - accuracy: 0.8985 - val_loss: 3.5011 - val_accuracy: 0.4303\n",
            "Epoch 22/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1922 - accuracy: 0.9340 - val_loss: 3.7255 - val_accuracy: 0.4327\n",
            "Epoch 23/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1496 - accuracy: 0.9522 - val_loss: 3.9365 - val_accuracy: 0.4558\n",
            "Epoch 24/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1237 - accuracy: 0.9600 - val_loss: 4.0653 - val_accuracy: 0.4236\n",
            "Epoch 25/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1154 - accuracy: 0.9618 - val_loss: 4.1695 - val_accuracy: 0.4303\n",
            "Epoch 1/25\n",
            "105/105 [==============================] - 2s 12ms/step - loss: 3.8869 - accuracy: 0.1991 - val_loss: 1.8889 - val_accuracy: 0.3006\n",
            "Epoch 2/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.8205 - accuracy: 0.3385 - val_loss: 1.8440 - val_accuracy: 0.3127\n",
            "Epoch 3/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.6123 - accuracy: 0.4161 - val_loss: 1.7361 - val_accuracy: 0.3697\n",
            "Epoch 4/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.4065 - accuracy: 0.4979 - val_loss: 1.7312 - val_accuracy: 0.3933\n",
            "Epoch 5/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.2469 - accuracy: 0.5546 - val_loss: 1.6347 - val_accuracy: 0.4333\n",
            "Epoch 6/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.0874 - accuracy: 0.6155 - val_loss: 1.6896 - val_accuracy: 0.4273\n",
            "Epoch 7/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.8977 - accuracy: 0.6919 - val_loss: 1.7546 - val_accuracy: 0.4309\n",
            "Epoch 8/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.7602 - accuracy: 0.7293 - val_loss: 1.9059 - val_accuracy: 0.4103\n",
            "Epoch 9/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.6324 - accuracy: 0.7872 - val_loss: 2.0583 - val_accuracy: 0.4164\n",
            "Epoch 10/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.5333 - accuracy: 0.8230 - val_loss: 2.1819 - val_accuracy: 0.4406\n",
            "Epoch 11/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.4317 - accuracy: 0.8525 - val_loss: 2.2375 - val_accuracy: 0.4564\n",
            "Epoch 12/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3377 - accuracy: 0.8901 - val_loss: 2.4239 - val_accuracy: 0.4473\n",
            "Epoch 13/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2865 - accuracy: 0.9006 - val_loss: 2.6145 - val_accuracy: 0.4388\n",
            "Epoch 14/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2430 - accuracy: 0.9197 - val_loss: 2.8795 - val_accuracy: 0.4352\n",
            "Epoch 15/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2048 - accuracy: 0.9343 - val_loss: 3.0696 - val_accuracy: 0.4261\n",
            "Epoch 16/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2104 - accuracy: 0.9263 - val_loss: 3.2919 - val_accuracy: 0.4327\n",
            "Epoch 17/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.3143 - accuracy: 0.8976 - val_loss: 2.8567 - val_accuracy: 0.4242\n",
            "Epoch 18/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2262 - accuracy: 0.9236 - val_loss: 3.5040 - val_accuracy: 0.4261\n",
            "Epoch 19/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2332 - accuracy: 0.9203 - val_loss: 3.1991 - val_accuracy: 0.4485\n",
            "Epoch 20/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.1037 - accuracy: 0.9684 - val_loss: 3.5413 - val_accuracy: 0.4509\n",
            "Epoch 21/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.0891 - accuracy: 0.9710 - val_loss: 3.8183 - val_accuracy: 0.4515\n",
            "Epoch 22/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1585 - accuracy: 0.9513 - val_loss: 4.0300 - val_accuracy: 0.4285\n",
            "Epoch 23/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3087 - accuracy: 0.8949 - val_loss: 3.5084 - val_accuracy: 0.4279\n",
            "Epoch 24/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2382 - accuracy: 0.9224 - val_loss: 3.7222 - val_accuracy: 0.4309\n",
            "Epoch 25/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2247 - accuracy: 0.9278 - val_loss: 3.9028 - val_accuracy: 0.4242\n",
            "Epoch 1/25\n",
            "105/105 [==============================] - 2s 13ms/step - loss: 3.4498 - accuracy: 0.2084 - val_loss: 1.9018 - val_accuracy: 0.3055\n",
            "Epoch 2/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.7872 - accuracy: 0.3546 - val_loss: 1.7248 - val_accuracy: 0.3527\n",
            "Epoch 3/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.5650 - accuracy: 0.4400 - val_loss: 1.6479 - val_accuracy: 0.4018\n",
            "Epoch 4/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 1.3333 - accuracy: 0.5242 - val_loss: 1.6547 - val_accuracy: 0.4200\n",
            "Epoch 5/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.2314 - accuracy: 0.5693 - val_loss: 1.7036 - val_accuracy: 0.4145\n",
            "Epoch 6/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 1.0482 - accuracy: 0.6319 - val_loss: 1.7008 - val_accuracy: 0.4406\n",
            "Epoch 7/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.8902 - accuracy: 0.6952 - val_loss: 1.6595 - val_accuracy: 0.4448\n",
            "Epoch 8/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.7448 - accuracy: 0.7451 - val_loss: 1.8018 - val_accuracy: 0.4564\n",
            "Epoch 9/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.5910 - accuracy: 0.8057 - val_loss: 1.9433 - val_accuracy: 0.4697\n",
            "Epoch 10/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.4627 - accuracy: 0.8439 - val_loss: 2.0469 - val_accuracy: 0.4752\n",
            "Epoch 11/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.4004 - accuracy: 0.8642 - val_loss: 2.3133 - val_accuracy: 0.4473\n",
            "Epoch 12/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.3789 - accuracy: 0.8713 - val_loss: 2.2645 - val_accuracy: 0.4897\n",
            "Epoch 13/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2225 - accuracy: 0.9307 - val_loss: 2.5506 - val_accuracy: 0.4782\n",
            "Epoch 14/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1278 - accuracy: 0.9660 - val_loss: 3.0299 - val_accuracy: 0.4473\n",
            "Epoch 15/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2791 - accuracy: 0.9048 - val_loss: 2.6481 - val_accuracy: 0.4473\n",
            "Epoch 16/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2199 - accuracy: 0.9307 - val_loss: 2.9413 - val_accuracy: 0.4491\n",
            "Epoch 17/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1639 - accuracy: 0.9484 - val_loss: 3.0196 - val_accuracy: 0.4497\n",
            "Epoch 18/25\n",
            "105/105 [==============================] - 1s 10ms/step - loss: 0.2505 - accuracy: 0.9137 - val_loss: 3.0042 - val_accuracy: 0.4630\n",
            "Epoch 19/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1130 - accuracy: 0.9654 - val_loss: 3.2476 - val_accuracy: 0.4570\n",
            "Epoch 20/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1029 - accuracy: 0.9669 - val_loss: 3.5456 - val_accuracy: 0.4758\n",
            "Epoch 21/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.2652 - accuracy: 0.9131 - val_loss: 3.4276 - val_accuracy: 0.4206\n",
            "Epoch 22/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1892 - accuracy: 0.9409 - val_loss: 3.8207 - val_accuracy: 0.4279\n",
            "Epoch 23/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1734 - accuracy: 0.9436 - val_loss: 3.5172 - val_accuracy: 0.4418\n",
            "Epoch 24/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1713 - accuracy: 0.9415 - val_loss: 3.7691 - val_accuracy: 0.4576\n",
            "Epoch 25/25\n",
            "105/105 [==============================] - 1s 11ms/step - loss: 0.1075 - accuracy: 0.9660 - val_loss: 3.8142 - val_accuracy: 0.4624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJQxvjrfrfnW"
      },
      "source": [
        "## Attack Model\n",
        "\n",
        "### Attack Model Architecture\n",
        "The attack model is consisted of 1 swallow layer of 10 neurons just as proposed in Shokri et al. and in the relative label only attack paper.\n",
        "\n",
        "### Perturbed Queries for feature extraction and Attack Dataset\n",
        "\n",
        "In order to construct the actual attack dataset we have 2 perturbation functions:\n",
        "- Translate\n",
        "- Rotate\n",
        "\n",
        "that can apply the necessary augmentations in order to acquire the feature vector for a query.\n",
        "\n",
        "This works by applying all augmentations to the input X and querying the target model in order to return a binary vector $x_{attack}$ where $$x_{attack_p} = 1 \\; if \\;y_p == y_{true} \\; else \\; 0, \\forall p \\in Perturbations(X)$$\n",
        "\n",
        "where $y_p$ is the label for pertubation $p$ of input $X$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrhUttNV1jR6"
      },
      "source": [
        "r = 3 # rotate range => creating 2*r+1 rotations \n",
        "d = 1 # translate range =? creating 4*d + 1 translates"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh5MsDOgVT4V"
      },
      "source": [
        "def __f_attack(X_train, y_train, X_test, y_test, epochs=50):\n",
        "  print(X_train.shape, X_test.shape)\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(10, input_shape=(X_train.shape[1],)))\n",
        "  model.add(layers.LeakyReLU(alpha=0.3))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  history = model.fit(X_train, y_train, epochs=epochs,\n",
        "                    validation_data=(X_test, y_test), verbose=True)\n",
        "  \n",
        "  return model\n",
        "\n",
        "def f_attack(X, y):\n",
        "  # X_i = (class, probability vector, )\n",
        "  classes = np.unique(train_labels) # all class labels\n",
        "  with tf.device('/gpu:0'):\n",
        "  # split to train and test datasets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3)\n",
        "    attack_model = __f_attack(X_train, y_train, X_test, y_test)\n",
        "\n",
        "  return attack_model"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYRgNm8sqkY7"
      },
      "source": [
        "# create all relative rotates for interpolation (returns 2*r + 1 translates)\n",
        "def create_rotates(r):\n",
        "  if r is None:\n",
        "    return None\n",
        "  if r == 1:\n",
        "    return [0.0]\n",
        "  rotates = np.linspace(-r, r, (r * 2 + 1))\n",
        "  return rotates\n",
        "\n",
        "# create all possible translates (returns 4*d+1 translates)\n",
        "def create_translates(d):\n",
        "  if d is None:\n",
        "    return None\n",
        "\n",
        "  def all_shifts(mshift):\n",
        "    if mshift == 0:\n",
        "      return [(0, 0, 0, 0)]\n",
        "    \n",
        "    all_pairs = []\n",
        "    start = (0, mshift, 0, 0)\n",
        "    end = (0, mshift, 0, 0)\n",
        "    vdir = -1\n",
        "    hdir = -1\n",
        "    first_time = True\n",
        "    while (start[1] != end[1] or start[2] != end[2]) or first_time:\n",
        "      all_pairs.append(start)\n",
        "      start = (0, start[1] + vdir, start[2] + hdir, 0)\n",
        "      if abs(start[1]) == mshift:\n",
        "        vdir *= -1\n",
        "      if abs(start[2]) == mshift:\n",
        "        hdir *= -1\n",
        "      first_time = False\n",
        "    all_pairs = [(0, 0, 0, 0)] + all_pairs  # add no shift\n",
        "    return all_pairs\n",
        "\n",
        "  translates = all_shifts(d)\n",
        "  return translates\n",
        "\n",
        "\n",
        "def apply_augment(d, augment, type_):\n",
        "  if type_ == 'd':\n",
        "    d = interpolation.shift(d, augment, mode='constant')\n",
        "  elif type_ == 'r':\n",
        "    d = interpolation.rotate(d, augment, (1, 2), reshape=False)\n",
        "  else:\n",
        "    raise ValueError(f'Augmentation Type: \\'{type_}\\' doesn\\'t exist. Try \\'r\\' or \\'d\\'')\n",
        "  return d\n",
        "\n",
        "# param model the model to query\n",
        "# param X the input to perurb\n",
        "# param y_pred is the predictions of the model for given input\n",
        "def augmented_queries(model, X, y_pred):\n",
        "  #create perturbations\n",
        "  rotates = create_rotates(r)\n",
        "  translates = create_translates(d)\n",
        "\n",
        "  X_attack = None\n",
        "  print(f\"Applying {len(rotates)} Rotation\")\n",
        "  for rot in rotates:\n",
        "    #  create perturbed image\n",
        "    X_perturbed = apply_augment(X, rot, 'r')\n",
        "    # return query line\n",
        "    y_perturbed = target_predict(X_perturbed)\n",
        "    X_attack_col = (y_pred == y_perturbed).astype(int) # transform the prediction column into a binary collumn where x_i = 1 when y_true == y_pred else 0\n",
        "    \n",
        "    if X_attack is None:\n",
        "      X_attack = X_attack_col\n",
        "    else:\n",
        "      X_attack = np.concatenate((X_attack, X_attack_col), axis=1)\n",
        "  print(\"OK\")\n",
        "\n",
        "  print(f\"Applying {len(translates)} Translates\")\n",
        "  for tra in translates:\n",
        "    X_perturbed = apply_augment(X, tra, 'd')\n",
        "    # return query line\n",
        "    y_perturbed = target_predict(X_perturbed)\n",
        "    X_attack_col = (y_pred == y_perturbed).astype(int) # transform the prediction column into a binary collumn where x_i = 1 when y_true == y_pred else 0\n",
        "    # concate the col to the rest of x_attack feature vector\n",
        "    if X_attack is None:\n",
        "      X_attack = X_attack_col\n",
        "    else:\n",
        "      X_attack = np.concatenate((X_attack, X_attack_col), axis=1)\n",
        "  print(\"OK\")\n",
        "  return X_attack"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc2udr_m5PSm"
      },
      "source": [
        "# lol = train_images[:2]\n",
        "# print(\"labels: \", train_labels[:2, 0])\n",
        "# m = shadow_models[0][0]\n",
        "# # get the y_pred \n",
        "# prob = layers.Softmax()\n",
        "# ret = prob(m.predict(X)).numpy()\n",
        "# y_pred = np.apply_along_axis(np.argmax, 1, ret).reshape((-1, 1))\n",
        "# print('pred:', y_pred)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6lVDDuD2DA5"
      },
      "source": [
        "# helper function to prepare each shadow dataset batch\n",
        "def prepare_batch(model, X, y, in_D):\n",
        "  #decide membership\n",
        "  y_member = np.ones(shape=(y.shape[0], 1)) if in_D else np.zeros(shape=(y.shape[0], 1))\n",
        "\n",
        "  # get the y_pred \n",
        "  prob = layers.Softmax()\n",
        "  ret = prob(model.predict(X)).numpy()\n",
        "  y_pred = np.apply_along_axis(np.argmax, 1, ret).reshape((-1, 1))\n",
        "  perturbed_queries_res = augmented_queries(model, X, y_pred)\n",
        "  \n",
        "  # return an instance <actual class, predicted class, perturbed_queries_res from shadow models, 'in'/'out' D_target membership> \n",
        "  return np.concatenate((y.reshape(-1, 1), y_pred, perturbed_queries_res, y_member), axis=1)\n",
        "\n",
        "def generate_attack_dataset(shadow_models, n_classes):\n",
        "  # input is a list where items are model, (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "  D_attack = None\n",
        "  # D_attack_i format = <class, prob_vec, membership label (1 or 0)> \n",
        "  for shadow_model, ((X_train, y_train), (X_test, y_test)) in shadow_models:\n",
        "    s = min(X_train.shape[0], X_test.shape[0])\n",
        "    print(f\"Preparing shadow batch of size {2*s}\")\n",
        "    batch = np.concatenate((\n",
        "        prepare_batch(shadow_model, X_train[:s], y_train[:s], True), # members of shadow dataset \n",
        "        prepare_batch(shadow_model, X_test[:s], y_test[:s], False)   # non members of shadow dataset\n",
        "    ))   \n",
        "\n",
        "    D_attack = np.concatenate((D_attack, batch)) if D_attack is not None else batch  \n",
        "    print(\"Done!\")\n",
        "  return D_attack "
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_yfm1hK-Sg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221a1400-f133-46db-c495-82f9d7ce7250"
      },
      "source": [
        "D_attack = generate_attack_dataset(shadow_models, 10)\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing shadow batch of size 3300\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Done!\n",
            "Preparing shadow batch of size 3300\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Done!\n",
            "Preparing shadow batch of size 3300\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Done!\n",
            "Preparing shadow batch of size 3300\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Done!\n",
            "Preparing shadow batch of size 3300\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnhE29HBBYGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb89abac-5e43-42db-eeeb-ae989ac76dbd"
      },
      "source": [
        "attack_model_bundle = f_attack(D_attack[:, :-1], D_attack[:, -1])"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11550, 14) (4950, 14)\n",
            "Epoch 1/50\n",
            "361/361 [==============================] - 3s 7ms/step - loss: 0.8352 - accuracy: 0.4866 - val_loss: 0.7169 - val_accuracy: 0.4739\n",
            "Epoch 2/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6988 - accuracy: 0.5087 - val_loss: 0.6895 - val_accuracy: 0.5471\n",
            "Epoch 3/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.6783 - accuracy: 0.5729 - val_loss: 0.6692 - val_accuracy: 0.6087\n",
            "Epoch 4/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6647 - accuracy: 0.5959 - val_loss: 0.6601 - val_accuracy: 0.5754\n",
            "Epoch 5/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6549 - accuracy: 0.6142 - val_loss: 0.6500 - val_accuracy: 0.6352\n",
            "Epoch 6/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.6448 - accuracy: 0.6487 - val_loss: 0.6411 - val_accuracy: 0.6889\n",
            "Epoch 7/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.6350 - accuracy: 0.6884 - val_loss: 0.6316 - val_accuracy: 0.7006\n",
            "Epoch 8/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6250 - accuracy: 0.7177 - val_loss: 0.6233 - val_accuracy: 0.7097\n",
            "Epoch 9/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6160 - accuracy: 0.7218 - val_loss: 0.6120 - val_accuracy: 0.7202\n",
            "Epoch 10/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.6050 - accuracy: 0.7278 - val_loss: 0.6052 - val_accuracy: 0.7166\n",
            "Epoch 11/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5939 - accuracy: 0.7302 - val_loss: 0.5919 - val_accuracy: 0.7305\n",
            "Epoch 12/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5834 - accuracy: 0.7353 - val_loss: 0.5826 - val_accuracy: 0.7261\n",
            "Epoch 13/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5756 - accuracy: 0.7394 - val_loss: 0.5761 - val_accuracy: 0.7281\n",
            "Epoch 14/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5694 - accuracy: 0.7416 - val_loss: 0.5751 - val_accuracy: 0.7444\n",
            "Epoch 15/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5645 - accuracy: 0.7451 - val_loss: 0.5684 - val_accuracy: 0.7269\n",
            "Epoch 16/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5614 - accuracy: 0.7457 - val_loss: 0.5654 - val_accuracy: 0.7416\n",
            "Epoch 17/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5586 - accuracy: 0.7485 - val_loss: 0.5648 - val_accuracy: 0.7303\n",
            "Epoch 18/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5563 - accuracy: 0.7493 - val_loss: 0.5617 - val_accuracy: 0.7424\n",
            "Epoch 19/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5555 - accuracy: 0.7481 - val_loss: 0.5634 - val_accuracy: 0.7541\n",
            "Epoch 20/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5534 - accuracy: 0.7519 - val_loss: 0.5592 - val_accuracy: 0.7422\n",
            "Epoch 21/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5532 - accuracy: 0.7507 - val_loss: 0.5645 - val_accuracy: 0.7453\n",
            "Epoch 22/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5524 - accuracy: 0.7512 - val_loss: 0.5587 - val_accuracy: 0.7481\n",
            "Epoch 23/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5515 - accuracy: 0.7525 - val_loss: 0.5576 - val_accuracy: 0.7525\n",
            "Epoch 24/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5507 - accuracy: 0.7532 - val_loss: 0.5607 - val_accuracy: 0.7384\n",
            "Epoch 25/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5505 - accuracy: 0.7521 - val_loss: 0.5580 - val_accuracy: 0.7545\n",
            "Epoch 26/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5506 - accuracy: 0.7541 - val_loss: 0.5581 - val_accuracy: 0.7537\n",
            "Epoch 27/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5505 - accuracy: 0.7554 - val_loss: 0.5575 - val_accuracy: 0.7473\n",
            "Epoch 28/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5494 - accuracy: 0.7545 - val_loss: 0.5578 - val_accuracy: 0.7398\n",
            "Epoch 29/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5497 - accuracy: 0.7533 - val_loss: 0.5557 - val_accuracy: 0.7495\n",
            "Epoch 30/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5487 - accuracy: 0.7553 - val_loss: 0.5610 - val_accuracy: 0.7295\n",
            "Epoch 31/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5484 - accuracy: 0.7554 - val_loss: 0.5551 - val_accuracy: 0.7529\n",
            "Epoch 32/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5488 - accuracy: 0.7545 - val_loss: 0.5546 - val_accuracy: 0.7523\n",
            "Epoch 33/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5476 - accuracy: 0.7552 - val_loss: 0.5551 - val_accuracy: 0.7475\n",
            "Epoch 34/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5488 - accuracy: 0.7539 - val_loss: 0.5546 - val_accuracy: 0.7556\n",
            "Epoch 35/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5470 - accuracy: 0.7573 - val_loss: 0.5565 - val_accuracy: 0.7529\n",
            "Epoch 36/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5477 - accuracy: 0.7559 - val_loss: 0.5537 - val_accuracy: 0.7525\n",
            "Epoch 37/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5480 - accuracy: 0.7545 - val_loss: 0.5566 - val_accuracy: 0.7382\n",
            "Epoch 38/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5472 - accuracy: 0.7553 - val_loss: 0.5563 - val_accuracy: 0.7527\n",
            "Epoch 39/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5467 - accuracy: 0.7560 - val_loss: 0.5529 - val_accuracy: 0.7527\n",
            "Epoch 40/50\n",
            "361/361 [==============================] - 2s 5ms/step - loss: 0.5465 - accuracy: 0.7562 - val_loss: 0.5532 - val_accuracy: 0.7558\n",
            "Epoch 41/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5459 - accuracy: 0.7573 - val_loss: 0.5553 - val_accuracy: 0.7552\n",
            "Epoch 42/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5452 - accuracy: 0.7568 - val_loss: 0.5561 - val_accuracy: 0.7396\n",
            "Epoch 43/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5460 - accuracy: 0.7563 - val_loss: 0.5550 - val_accuracy: 0.7400\n",
            "Epoch 44/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5456 - accuracy: 0.7571 - val_loss: 0.5527 - val_accuracy: 0.7485\n",
            "Epoch 45/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5456 - accuracy: 0.7552 - val_loss: 0.5583 - val_accuracy: 0.7436\n",
            "Epoch 46/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5451 - accuracy: 0.7549 - val_loss: 0.5519 - val_accuracy: 0.7525\n",
            "Epoch 47/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5449 - accuracy: 0.7560 - val_loss: 0.5513 - val_accuracy: 0.7556\n",
            "Epoch 48/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5446 - accuracy: 0.7563 - val_loss: 0.5558 - val_accuracy: 0.7505\n",
            "Epoch 49/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5448 - accuracy: 0.7562 - val_loss: 0.5549 - val_accuracy: 0.7505\n",
            "Epoch 50/50\n",
            "361/361 [==============================] - 2s 6ms/step - loss: 0.5441 - accuracy: 0.7584 - val_loss: 0.5510 - val_accuracy: 0.7558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAveNFNrvrX"
      },
      "source": [
        "## Attack Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9GxZE5Yntpw"
      },
      "source": [
        "def evaluate_attack(attack_model, X_attack, y_attack, n_classes):\n",
        "  acc_per_class = []\n",
        "  for c in range(n_classes):\n",
        "    class_instances = X_attack[:, 0] == c # get same class samples\n",
        "    test_loss, test_acc = attack_model.evaluate(X_attack[class_instances, :], y_attack[class_instances], verbose=0)\n",
        "    acc_per_class.append(test_acc)\n",
        "    print(f\"class-{c+1}: {test_acc}\")\n",
        "  return acc_per_class\n",
        "\n"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiQyYdB7SABg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f0ac9d2-ad33-4d64-d0ac-89e6d5b43fc5"
      },
      "source": [
        "# create a test dataset \n",
        "\n",
        "D_in = prepare_batch(target_model, train_images[:1000], train_labels[:1000], True)\n",
        "print(\"Testing with 'in' data only:\")\n",
        "res_in = evaluate_attack(attack_model_bundle, D_in[:, :-1], D_in[:, -1], 10)\n",
        "\n",
        "D_out = prepare_batch(target_model, attacker_images[:1000], attacker_labels[:1000], False)\n",
        "print(\"\\nTesting with 'out' data only:\")\n",
        "res_out = evaluate_attack(attack_model_bundle, D_out[:, :-1], D_out[:, -1], 10)\n",
        "\n",
        "print(\"\\nTesting with all prev data: \")\n",
        "res_all = evaluate_attack(attack_model_bundle, np.concatenate((D_out[:, :-1], D_in[:, :-1])), np.concatenate((D_out[:, -1], D_in[:, -1])), 10)\n",
        "\n",
        "print(f\"\\nTotal attack accuracy: {np.mean(res_all)}\")"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "Testing with 'in' data only:\n",
            "class-1: 0.9732142686843872\n",
            "class-2: 1.0\n",
            "class-3: 0.9387755393981934\n",
            "class-4: 0.9368420839309692\n",
            "class-5: 0.9909090995788574\n",
            "class-6: 0.9418604373931885\n",
            "class-7: 1.0\n",
            "class-8: 0.957446813583374\n",
            "class-9: 1.0\n",
            "class-10: 0.9892473220825195\n",
            "Applying 7 Rotation\n",
            "OK\n",
            "Applying 5 Translates\n",
            "OK\n",
            "\n",
            "Testing with 'out' data only:\n",
            "class-1: 0.561904788017273\n",
            "class-2: 0.450549453496933\n",
            "class-3: 0.800000011920929\n",
            "class-4: 0.8723404407501221\n",
            "class-5: 0.5978260636329651\n",
            "class-6: 0.800000011920929\n",
            "class-7: 0.4020618498325348\n",
            "class-8: 0.4954954981803894\n",
            "class-9: 0.3199999928474426\n",
            "class-10: 0.48695650696754456\n",
            "\n",
            "Testing with all prev data: \n",
            "class-1: 0.774193525314331\n",
            "class-2: 0.7382199168205261\n",
            "class-3: 0.868686854839325\n",
            "class-4: 0.9047619104385376\n",
            "class-5: 0.8118811845779419\n",
            "class-6: 0.8674033284187317\n",
            "class-7: 0.7010309100151062\n",
            "class-8: 0.707317054271698\n",
            "class-9: 0.6837209463119507\n",
            "class-10: 0.7115384340286255\n",
            "\n",
            "Total attack accuracy: 0.7768754065036774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grjprA4PmE7"
      },
      "source": [
        "# Questions for meeting\n",
        "\n",
        "- Paper said of accuracy above 80%? Am I doing something wrong?\n",
        "- How to get more features in this threat model, so that attack is even more successful\n",
        "- Should we try to attack model with MIA defences on, or is it too early?\n",
        "- What's next?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqxfkv9lQG23"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}