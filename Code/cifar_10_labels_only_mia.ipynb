{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vzAuc5Xo3j2"
      },
      "source": [
        "# Label Only Membership Inference (Revisited on points)\n",
        "\n",
        "### Threat Model:\n",
        "\n",
        "- **Black Box** access to an overfitted classifier with no access to actual $D_{train}$\n",
        "- Predict API returns **only labels instead of confidence vectors**\n",
        "- We have some insight on the training data distribution, $D_{out}$ , **but** $D_{train} \\cap D_{out} = \\varnothing$\n",
        "\n",
        "\n",
        "### Attack Target: \n",
        "- Use a shadow model to attack local shadow models and extract membership leakage features\n",
        "- Use data perturbations in order to exploit test/training data approximation relevancies to the classification boundaries.\n",
        "- Perfom the boundary-based attack on the actual model\n",
        "\n",
        "### Evaluation Target\n",
        "- Score over $50\\%$ accuracy\n",
        "- Train attack model based on this assumption and compare with conf-vector attack\n",
        "\n",
        "Implemented based on [this paper](https://arxiv.org/abs/2007.14321)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg_WQJ7j5n3B",
        "outputId": "1b861a50-0055-489e-ce10-4e89742e87ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-26 19:54:31.480414: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-26 19:54:31.786516: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-12-26 19:54:31.786591: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vissam-HP-Laptop-15-da0xxx): /proc/driver/nvidia/version does not exist\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# for image interpolation\n",
        "import scipy.ndimage.interpolation as interpolation\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kv7Qon0qRTk"
      },
      "source": [
        "## Target Model\n",
        "\n",
        "### Model Architecture\n",
        "- 2 layers of 32 $3\\times 3$ Conv2D filters with Max Pooling\n",
        "- 2 layers of 64 $3\\times 3$ Conv2D filters with MaxPooling\n",
        "- Dense Layer of 512 neurons\n",
        "- Dense Output layer of 10 neurons\n",
        "- Each layer has ReLU activation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zacp4ArauIET"
      },
      "outputs": [],
      "source": [
        "D_TARGET_SIZE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1qg7LkXX0zOF"
      },
      "outputs": [],
      "source": [
        "def f_target(X_train, y_train, X_test=None, y_test=None, epochs=100):\n",
        "  \"\"\"\n",
        "  Returns a trained target model, if test data are specified we will evaluate the model and print its accuracy\n",
        "  \"\"\"\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  if X_test is None or y_test is None:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_split=0.2)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_data=(X_test, y_test))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oy2NLipP75sX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "  3694592/170498071 [..............................] - ETA: 14:24"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "# use the rest as testing - 'out' records\n",
        "attacker_labels = np.concatenate((train_labels[D_TARGET_SIZE:], test_labels))\n",
        "attacker_images = np.concatenate((train_images[D_TARGET_SIZE:], test_images))\n",
        "target_images = train_images[:D_TARGET_SIZE]\n",
        "target_labels = train_labels[:D_TARGET_SIZE]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap02yKRT76RJ",
        "outputId": "14bb60f8-fb8f-4cd0-f2ac-454229a481f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 5s 16ms/step - loss: 2.3764 - accuracy: 0.2890 - val_loss: 1.8053 - val_accuracy: 0.3315\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 1.5868 - accuracy: 0.4184 - val_loss: 1.5981 - val_accuracy: 0.4130\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 1.3697 - accuracy: 0.5049 - val_loss: 1.5021 - val_accuracy: 0.4625\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 1.1688 - accuracy: 0.5819 - val_loss: 1.4752 - val_accuracy: 0.4810\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.9723 - accuracy: 0.6463 - val_loss: 1.6728 - val_accuracy: 0.4645\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.7416 - accuracy: 0.7371 - val_loss: 1.6600 - val_accuracy: 0.5015\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.5305 - accuracy: 0.8183 - val_loss: 1.9249 - val_accuracy: 0.4855\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.3814 - accuracy: 0.8691 - val_loss: 2.3684 - val_accuracy: 0.4680\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.3311 - accuracy: 0.8915 - val_loss: 2.8415 - val_accuracy: 0.4565\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.2468 - accuracy: 0.9175 - val_loss: 3.0826 - val_accuracy: 0.4690\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.2185 - accuracy: 0.9266 - val_loss: 2.7702 - val_accuracy: 0.4875\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.1688 - accuracy: 0.9466 - val_loss: 3.1945 - val_accuracy: 0.4790\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.1781 - accuracy: 0.9436 - val_loss: 3.8065 - val_accuracy: 0.4605\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 4s 14ms/step - loss: 0.1768 - accuracy: 0.9451 - val_loss: 3.4248 - val_accuracy: 0.4760\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.1414 - accuracy: 0.9516 - val_loss: 4.0397 - val_accuracy: 0.4575\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1449 - accuracy: 0.9545 - val_loss: 3.3839 - val_accuracy: 0.4905\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.2054 - accuracy: 0.9346 - val_loss: 3.3224 - val_accuracy: 0.4835\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1326 - accuracy: 0.9601 - val_loss: 3.5494 - val_accuracy: 0.4965\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.1311 - accuracy: 0.9605 - val_loss: 4.6039 - val_accuracy: 0.4605\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.1055 - accuracy: 0.9665 - val_loss: 4.8665 - val_accuracy: 0.4645\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1424 - accuracy: 0.9620 - val_loss: 4.5169 - val_accuracy: 0.4720\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0993 - accuracy: 0.9696 - val_loss: 4.6273 - val_accuracy: 0.4690\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.1233 - accuracy: 0.9632 - val_loss: 4.5245 - val_accuracy: 0.4680\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1300 - accuracy: 0.9607 - val_loss: 4.7981 - val_accuracy: 0.4615\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1240 - accuracy: 0.9649 - val_loss: 4.7088 - val_accuracy: 0.4665\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1249 - accuracy: 0.9646 - val_loss: 5.0257 - val_accuracy: 0.4575\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1198 - accuracy: 0.9655 - val_loss: 5.2207 - val_accuracy: 0.4430\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1542 - accuracy: 0.9601 - val_loss: 4.9880 - val_accuracy: 0.4640\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1607 - accuracy: 0.9571 - val_loss: 4.5912 - val_accuracy: 0.4600\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0554 - accuracy: 0.9811 - val_loss: 5.2557 - val_accuracy: 0.4635\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 5.5245 - val_accuracy: 0.4620\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0658 - accuracy: 0.9819 - val_loss: 5.1764 - val_accuracy: 0.4735\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1301 - accuracy: 0.9649 - val_loss: 4.9899 - val_accuracy: 0.4885\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1251 - accuracy: 0.9653 - val_loss: 5.5844 - val_accuracy: 0.4620\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0562 - accuracy: 0.9855 - val_loss: 5.5091 - val_accuracy: 0.4455\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1071 - accuracy: 0.9705 - val_loss: 5.4104 - val_accuracy: 0.4715\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1222 - accuracy: 0.9688 - val_loss: 6.1929 - val_accuracy: 0.4465\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0808 - accuracy: 0.9764 - val_loss: 6.3093 - val_accuracy: 0.4625\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0966 - accuracy: 0.9743 - val_loss: 5.5130 - val_accuracy: 0.4670\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1140 - accuracy: 0.9700 - val_loss: 5.4776 - val_accuracy: 0.4605\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1041 - accuracy: 0.9724 - val_loss: 5.7391 - val_accuracy: 0.4880\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0858 - accuracy: 0.9754 - val_loss: 5.6957 - val_accuracy: 0.4845\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1020 - accuracy: 0.9750 - val_loss: 5.4524 - val_accuracy: 0.4580\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1149 - accuracy: 0.9686 - val_loss: 5.3280 - val_accuracy: 0.4940\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0582 - accuracy: 0.9845 - val_loss: 6.1105 - val_accuracy: 0.4700\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0413 - accuracy: 0.9891 - val_loss: 6.7522 - val_accuracy: 0.4430\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 4s 14ms/step - loss: 0.0997 - accuracy: 0.9749 - val_loss: 6.1287 - val_accuracy: 0.4495\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1423 - accuracy: 0.9631 - val_loss: 6.8426 - val_accuracy: 0.4620\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.1918 - accuracy: 0.9524 - val_loss: 6.2556 - val_accuracy: 0.4665\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0994 - accuracy: 0.9755 - val_loss: 6.4931 - val_accuracy: 0.4715\n"
          ]
        }
      ],
      "source": [
        "train_images, eval_images, train_labels, eval_labels = train_test_split(target_images, target_labels, test_size=0.2, shuffle=True)\n",
        "target_model = f_target(train_images, train_labels, eval_images, eval_labels, epochs=50) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9I5lKSrSsU"
      },
      "source": [
        "### Target Model prediction API\n",
        "Provide the users with a prediction API call that returns only the predicted label/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xvocFuQeVLsM"
      },
      "outputs": [],
      "source": [
        "# API of model to get predictions : returns labels only\n",
        "def target_predict(model, X):\n",
        "  prob = layers.Softmax()\n",
        "  ret = prob(model.predict(X)).numpy()\n",
        "  return np.apply_along_axis(np.argmax, 1, ret).reshape((-1, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l--0MCg-elRq"
      },
      "source": [
        "### Perturbed Instance Behaviour\n",
        "\n",
        "Following we will apply some perturbations to data instances from in and out of $D_{target}$ and we will count how the predicted label change in respect to this perturbations, according to each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H0PYHLFrWJ1"
      },
      "source": [
        "\n",
        "\n",
        "## Shadow Models\n",
        "Following we define our own shadow models\n",
        "\n",
        "### Shadow Model Architecture\n",
        "- 3 CNN layers of $32, 64, 128$ filters of size $3 \\times 3$ with MaxPooling and ReLU activation\n",
        "- Dense Layer of 128 nodes\n",
        "- Dense Layer of 10 nodes as Output layer\n",
        "\n",
        "All output logits pass through Softmax Unit as in the target model to acquire probability vectors\n",
        "\n",
        "\n",
        "\n",
        "### Shadow Dataset Composition\n",
        "\n",
        "We just divide the CIFAR-10 dataset to $D_{out}$ and $D_{train}$ such as $D_{train} \\cap D_{out} = \\varnothing$ and use $D_{out}$ in order to train/test shadow models and attack model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2GWyCXmmwIiJ"
      },
      "outputs": [],
      "source": [
        "N_SHADOWS = 1\n",
        "D_SHADOW_SIZE = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2rwhySHfVQjV"
      },
      "outputs": [],
      "source": [
        "def f_shadow(X_train, y_train, X_test=None, y_test=None, epochs=25):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  \n",
        "  \n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10)   )\n",
        "  \n",
        "  optimizer = keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "  if X_test is None or y_test is None:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_split=0.2)\n",
        "  else:\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, \n",
        "                    validation_data=(X_test, y_test))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sliyw7xO2PTg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def divide_dataset(n_shadows, shadow_dataset_size, X, y):\n",
        "  D_shadows = []\n",
        "  for i in range(n_shadows):\n",
        "    sample_i = np.random.choice(range(X.shape[0]), shadow_dataset_size, replace=False)\n",
        "    assert np.unique(sample_i).shape[0] == shadow_dataset_size # sanity check\n",
        "    D_shadows.append((X[sample_i, :], y[sample_i, :]))\n",
        "  return D_shadows\n",
        "\n",
        "# returns a list of 'n_shadows' datasets\n",
        "def generate_shadow_dataset(target_model, n_shadows, shadow_dataset_size, n_classes, attacker_X=None, attacker_y=None):\n",
        "  # param target model is not used yet\n",
        "\n",
        "\n",
        "  # in case we give test data we will just divide those to train the shadow models\n",
        "  if attacker_X is not None and attacker_y is not None:\n",
        "    return divide_dataset(n_shadows, shadow_dataset_size, attacker_X, attacker_y)\n",
        "  else:\n",
        "    raise ValueError(\"X and y provided are None.\")\n",
        "\n",
        "# returns list of (trained shadow_model, D_shadow)\n",
        "def create_shadows(D_shadows):\n",
        "  shadow_models = [] # shadow model list\n",
        "\n",
        "  for D_shadow in D_shadows:\n",
        "    # sample data to feed/evaluate the model\n",
        "    X_shadow, y_shadow = D_shadow\n",
        "    shadow_X_train, shadow_X_test, shadow_y_train, shadow_y_test = train_test_split(X_shadow, y_shadow, shuffle=True, test_size=0.33)\n",
        "\n",
        "    # generate the shadow model\n",
        "    shadow_model = f_shadow(shadow_X_train, shadow_y_train, shadow_X_test, shadow_y_test)\n",
        "\n",
        "    D_shadow = (shadow_X_train, shadow_y_train), (shadow_X_test, shadow_y_test)\n",
        "    shadow_models.append((shadow_model, D_shadow))\n",
        "\n",
        "  return shadow_models # return a list where every item is (model, acc), train-data, test-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "q3ziH9LP3CY5"
      },
      "outputs": [],
      "source": [
        "# generate shadow datasets\n",
        "D_shadows = generate_shadow_dataset(target_model, N_SHADOWS, D_SHADOW_SIZE, 10, attacker_images, attacker_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc8morl-NRP",
        "outputId": "2aa16b9e-0bc3-4875-af7a-bc0e251d366c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "210/210 [==============================] - 3s 12ms/step - loss: 3.6046 - accuracy: 0.2458 - val_loss: 1.7847 - val_accuracy: 0.3676\n",
            "Epoch 2/25\n",
            "210/210 [==============================] - 3s 13ms/step - loss: 1.6999 - accuracy: 0.3842 - val_loss: 1.6579 - val_accuracy: 0.4033\n",
            "Epoch 3/25\n",
            "210/210 [==============================] - 2s 12ms/step - loss: 1.5558 - accuracy: 0.4467 - val_loss: 1.5917 - val_accuracy: 0.4133\n",
            "Epoch 4/25\n",
            "210/210 [==============================] - 3s 12ms/step - loss: 1.3873 - accuracy: 0.5031 - val_loss: 1.5090 - val_accuracy: 0.4433\n",
            "Epoch 5/25\n",
            "210/210 [==============================] - 2s 12ms/step - loss: 1.3071 - accuracy: 0.5355 - val_loss: 1.6344 - val_accuracy: 0.4448\n",
            "Epoch 6/25\n",
            "210/210 [==============================] - 3s 12ms/step - loss: 1.1662 - accuracy: 0.5878 - val_loss: 1.5977 - val_accuracy: 0.4606\n",
            "Epoch 7/25\n",
            "210/210 [==============================] - 2s 12ms/step - loss: 1.0643 - accuracy: 0.6258 - val_loss: 1.5484 - val_accuracy: 0.4806\n",
            "Epoch 8/25\n",
            "210/210 [==============================] - 3s 14ms/step - loss: 0.9475 - accuracy: 0.6660 - val_loss: 1.7196 - val_accuracy: 0.4748\n",
            "Epoch 9/25\n",
            "210/210 [==============================] - 2s 12ms/step - loss: 0.8340 - accuracy: 0.7040 - val_loss: 1.7755 - val_accuracy: 0.4694\n",
            "Epoch 10/25\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.7588 - accuracy: 0.7357 - val_loss: 1.7317 - val_accuracy: 0.4879\n",
            "Epoch 11/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.6361 - accuracy: 0.7716 - val_loss: 1.8464 - val_accuracy: 0.4888\n",
            "Epoch 12/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.6173 - accuracy: 0.7843 - val_loss: 1.9191 - val_accuracy: 0.4952\n",
            "Epoch 13/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.5373 - accuracy: 0.8143 - val_loss: 2.0449 - val_accuracy: 0.4767\n",
            "Epoch 14/25\n",
            "210/210 [==============================] - 2s 11ms/step - loss: 0.4129 - accuracy: 0.8566 - val_loss: 2.3088 - val_accuracy: 0.4864\n",
            "Epoch 15/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.4330 - accuracy: 0.8500 - val_loss: 2.5554 - val_accuracy: 0.4597\n",
            "Epoch 16/25\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.3984 - accuracy: 0.8628 - val_loss: 2.5063 - val_accuracy: 0.4712\n",
            "Epoch 17/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.3436 - accuracy: 0.8827 - val_loss: 2.7809 - val_accuracy: 0.4561\n",
            "Epoch 18/25\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.3456 - accuracy: 0.8872 - val_loss: 2.8384 - val_accuracy: 0.4748\n",
            "Epoch 19/25\n",
            "210/210 [==============================] - 2s 10ms/step - loss: 0.2923 - accuracy: 0.8975 - val_loss: 2.8639 - val_accuracy: 0.4836\n",
            "Epoch 20/25\n",
            "210/210 [==============================] - 2s 11ms/step - loss: 0.2919 - accuracy: 0.8981 - val_loss: 3.0141 - val_accuracy: 0.4748\n",
            "Epoch 21/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.2873 - accuracy: 0.9042 - val_loss: 3.0473 - val_accuracy: 0.4782\n",
            "Epoch 22/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.2658 - accuracy: 0.9104 - val_loss: 3.2204 - val_accuracy: 0.4709\n",
            "Epoch 23/25\n",
            "210/210 [==============================] - 2s 11ms/step - loss: 0.2928 - accuracy: 0.9045 - val_loss: 3.2661 - val_accuracy: 0.4800\n",
            "Epoch 24/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.2448 - accuracy: 0.9143 - val_loss: 3.4526 - val_accuracy: 0.4900\n",
            "Epoch 25/25\n",
            "210/210 [==============================] - 2s 9ms/step - loss: 0.2180 - accuracy: 0.9281 - val_loss: 3.5932 - val_accuracy: 0.4670\n"
          ]
        }
      ],
      "source": [
        "# train the shadow models\n",
        "shadow_models = create_shadows(D_shadows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJQxvjrfrfnW"
      },
      "source": [
        "## Attack Model\n",
        "\n",
        "### Attack Model Architecture\n",
        "The attack model is consisted of 1 swallow layer of 10 neurons just as proposed in Shokri et al. and in the relative label only attack paper.\n",
        "\n",
        "\n",
        "### Attack Dataset\n",
        "The attack dataset will be consisted of vectors $x_i$, s.t. $x_i$ contains:\n",
        "- real label\n",
        "- predicted label\n",
        "- bitstring of length $n'$, where $x_{ij+2}, \\; j \\in \\{1, ..., n'\\} $ will be 1 if perturbed label is same as predicted, otherwise it'll be zero.\n",
        "\n",
        "\n",
        "### Perturbed Queries for feature extraction and Attack Dataset\n",
        "\n",
        "In order to construct the actual attack dataset we have 2 perturbation functions:\n",
        "- Translate\n",
        "- Rotate\n",
        "\n",
        "that can apply the necessary augmentations in order to acquire the feature vector for a query.\n",
        "\n",
        "This works by applying all augmentations to the input X and querying the target model in order to return a binary vector $x_{attack}$ where $$x_{attack_p} = 1 \\; if \\;y_p == y_{true} \\; else \\; 0, \\forall p \\in Perturbations(X)$$\n",
        "\n",
        "where $y_p$ is the label for pertubation $p$ of input $X$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SrhUttNV1jR6"
      },
      "outputs": [],
      "source": [
        "r = 2 # rotate range => creating 2*r+1 rotations \n",
        "d = 1 # translate range =? creating 4*d + 1 translates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DYRgNm8sqkY7"
      },
      "outputs": [],
      "source": [
        "# create all relative rotates for interpolation (returns 2*r + 1 translates)\n",
        "def create_rotates(r):\n",
        "  if r is None:\n",
        "    return None\n",
        "  if r == 1:\n",
        "    return [0.0]\n",
        "  rotates = np.linspace(-r, r, (r * 2 + 1))\n",
        "  return rotates\n",
        "\n",
        "# create all possible translates (returns 4*d+1 translates)\n",
        "def create_translates(d):\n",
        "  if d is None:\n",
        "    return None\n",
        "\n",
        "  def all_shifts(mshift):\n",
        "    if mshift == 0:\n",
        "      return [(0, 0, 0, 0)]\n",
        "    \n",
        "    all_pairs = []\n",
        "    start = (0, mshift, 0, 0)\n",
        "    end = (0, mshift, 0, 0)\n",
        "    vdir = -1\n",
        "    hdir = -1\n",
        "    first_time = True\n",
        "    while (start[1] != end[1] or start[2] != end[2]) or first_time:\n",
        "      all_pairs.append(start)\n",
        "      start = (0, start[1] + vdir, start[2] + hdir, 0)\n",
        "      if abs(start[1]) == mshift:\n",
        "        vdir *= -1\n",
        "      if abs(start[2]) == mshift:\n",
        "        hdir *= -1\n",
        "      first_time = False\n",
        "    all_pairs = [(0, 0, 0, 0)] + all_pairs  # add no shift\n",
        "    return all_pairs\n",
        "\n",
        "  translates = all_shifts(d)\n",
        "  return translates\n",
        "\n",
        "\n",
        "def apply_augment(d, augment, type_):\n",
        "  if type_ == 'd':\n",
        "    d = interpolation.shift(d, augment, mode='constant')\n",
        "  elif type_ == 'r':\n",
        "    d = interpolation.rotate(d, augment, (1, 2), reshape=False)\n",
        "  else:\n",
        "    raise ValueError(f'Augmentation Type: \\'{type_}\\' doesn\\'t exist. Try \\'r\\' or \\'d\\'')\n",
        "  return d\n",
        "\n",
        "# param model the model to query\n",
        "# param X the input to perurb\n",
        "# param y_pred is the predictions of the model for given input\n",
        "def augmented_queries(model, X, y_pred, r=3, d=1):\n",
        "  #create perturbations\n",
        "  rotates = create_rotates(r)\n",
        "  translates = create_translates(d)\n",
        "\n",
        "  X_attack = None\n",
        "  for rot in rotates:\n",
        "    #  create perturbed image\n",
        "    X_perturbed = apply_augment(X, rot, 'r')\n",
        "    # return query line\n",
        "    y_perturbed = target_predict(model, X_perturbed)\n",
        "    X_attack_col = y_perturbed #(y_pred == y_perturbed).astype(int) # transform the prediction column into a binary collumn where x_i = 1 when y_true == y_pred else 0\n",
        "    \n",
        "    if X_attack is None:\n",
        "      X_attack = X_attack_col\n",
        "    else:\n",
        "      X_attack = np.concatenate((X_attack, X_attack_col), axis=1)\n",
        "\n",
        "  for tra in translates:\n",
        "    X_perturbed = apply_augment(X, tra, 'd')\n",
        "    # return query line\n",
        "    y_perturbed = target_predict(model, X_perturbed)\n",
        "    X_attack_col = y_perturbed #(y_pred == y_perturbed).astype(int) # transform the prediction column into a binary collumn where x_i = 1 when y_true == y_pred else 0\n",
        "    # concate the col to the rest of x_attack feature vector\n",
        "    if X_attack is None:\n",
        "      X_attack = X_attack_col\n",
        "    else:\n",
        "      X_attack = np.concatenate((X_attack, X_attack_col), axis=1)\n",
        "  return X_attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "A6lVDDuD2DA5"
      },
      "outputs": [],
      "source": [
        "# helper function to prepare each shadow dataset batch\n",
        "def prepare_batch(model, X, y, in_D):\n",
        "  #decide membership\n",
        "  y_member = np.ones(shape=(y.shape[0], 1)) if in_D else np.zeros(shape=(y.shape[0], 1))\n",
        "\n",
        "  # get the y_pred \n",
        "  prob = layers.Softmax()\n",
        "  ret = prob(model.predict(X)).numpy()\n",
        "  y_pred = np.apply_along_axis(np.argmax, 1, ret).reshape((-1, 1))\n",
        "  perturbed_queries_res = augmented_queries(model, X, y_pred, r, d)\n",
        "  \n",
        "  # return an instance <actual class, predicted class, perturbed_queries_res from shadow models, 'in'/'out' D_target membership> \n",
        "  return np.concatenate((y.reshape(-1, 1), y_pred, perturbed_queries_res, y_member), axis=1)\n",
        "\n",
        "def generate_attack_dataset(shadow_models, n_classes):\n",
        "  # input is a list where items are model, (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "  D_attack = None\n",
        "  # D_attack_i format = <class, prob_vec, membership label (1 or 0)> \n",
        "  for shadow_model, ((X_train, y_train), (X_test, y_test)) in shadow_models:\n",
        "    s = min(X_train.shape[0], X_test.shape[0])\n",
        "    print(f\"Preparing shadow batch of size {2*s}\")\n",
        "    batch = np.concatenate((\n",
        "        prepare_batch(shadow_model, X_train[:s], y_train[:s], True), # members of shadow dataset \n",
        "        prepare_batch(shadow_model, X_test[:s], y_test[:s], False)   # non members of shadow dataset\n",
        "    ))   \n",
        "\n",
        "    D_attack = np.concatenate((D_attack, batch)) if D_attack is not None else batch  \n",
        "    print(\"Done!\")\n",
        "  return D_attack "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yh5MsDOgVT4V"
      },
      "outputs": [],
      "source": [
        "def __f_attack(X_train, y_train, X_test, y_test, epochs=100):\n",
        "  print(X_train.shape, X_test.shape)\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(10, input_shape=(X_train.shape[1],)))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  history = model.fit(X_train, y_train, epochs=epochs,\n",
        "                    validation_data=(X_test, y_test), verbose=True)\n",
        "  \n",
        "  return model\n",
        "\n",
        "def f_attack(X, y):\n",
        "  # X_i = (class, probability vector, )\n",
        "  classes = np.unique(train_labels) # all class labels\n",
        "  with tf.device('/gpu:0'):\n",
        "  # split to train and test datasets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3)\n",
        "    attack_model = __f_attack(X_train, y_train, X_test, y_test)\n",
        "\n",
        "  return attack_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_yfm1hK-Sg7",
        "outputId": "9c15fcd9-ea13-4996-e38e-0384cb45bce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing shadow batch of size 6600\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "D_attack = generate_attack_dataset(shadow_models, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnhE29HBBYGy",
        "outputId": "bf86bbe8-3694-401b-da7c-537400ef9f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4620, 12) (1980, 12)\n",
            "Epoch 1/100\n",
            "145/145 [==============================] - 2s 8ms/step - loss: 1.0268 - accuracy: 0.5340 - val_loss: 0.7501 - val_accuracy: 0.5364\n",
            "Epoch 2/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.7316 - accuracy: 0.5602 - val_loss: 0.7196 - val_accuracy: 0.5389\n",
            "Epoch 3/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.7105 - accuracy: 0.5732 - val_loss: 0.6984 - val_accuracy: 0.5510\n",
            "Epoch 4/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6935 - accuracy: 0.5784 - val_loss: 0.6885 - val_accuracy: 0.5848\n",
            "Epoch 5/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6839 - accuracy: 0.6052 - val_loss: 0.6823 - val_accuracy: 0.5919\n",
            "Epoch 6/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6769 - accuracy: 0.6043 - val_loss: 0.6808 - val_accuracy: 0.5934\n",
            "Epoch 7/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6704 - accuracy: 0.6253 - val_loss: 0.6710 - val_accuracy: 0.6197\n",
            "Epoch 8/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6645 - accuracy: 0.6251 - val_loss: 0.6620 - val_accuracy: 0.6389\n",
            "Epoch 9/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6584 - accuracy: 0.6396 - val_loss: 0.6606 - val_accuracy: 0.6263\n",
            "Epoch 10/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6520 - accuracy: 0.6487 - val_loss: 0.6510 - val_accuracy: 0.6540\n",
            "Epoch 11/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6456 - accuracy: 0.6619 - val_loss: 0.6524 - val_accuracy: 0.6343\n",
            "Epoch 12/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6412 - accuracy: 0.6626 - val_loss: 0.6462 - val_accuracy: 0.6470\n",
            "Epoch 13/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6365 - accuracy: 0.6656 - val_loss: 0.6415 - val_accuracy: 0.6495\n",
            "Epoch 14/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6328 - accuracy: 0.6693 - val_loss: 0.6389 - val_accuracy: 0.6495\n",
            "Epoch 15/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6280 - accuracy: 0.6714 - val_loss: 0.6342 - val_accuracy: 0.6551\n",
            "Epoch 16/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6242 - accuracy: 0.6777 - val_loss: 0.6368 - val_accuracy: 0.6520\n",
            "Epoch 17/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6200 - accuracy: 0.6846 - val_loss: 0.6338 - val_accuracy: 0.6606\n",
            "Epoch 18/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.6838 - val_loss: 0.6454 - val_accuracy: 0.6475\n",
            "Epoch 19/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.6827 - val_loss: 0.6263 - val_accuracy: 0.6697\n",
            "Epoch 20/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6117 - accuracy: 0.6926 - val_loss: 0.6358 - val_accuracy: 0.6596\n",
            "Epoch 21/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6106 - accuracy: 0.6918 - val_loss: 0.6264 - val_accuracy: 0.6722\n",
            "Epoch 22/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6076 - accuracy: 0.6968 - val_loss: 0.6240 - val_accuracy: 0.6732\n",
            "Epoch 23/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6056 - accuracy: 0.6965 - val_loss: 0.6228 - val_accuracy: 0.6737\n",
            "Epoch 24/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6039 - accuracy: 0.6989 - val_loss: 0.6217 - val_accuracy: 0.6742\n",
            "Epoch 25/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6014 - accuracy: 0.7017 - val_loss: 0.6229 - val_accuracy: 0.6747\n",
            "Epoch 26/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.6002 - accuracy: 0.6996 - val_loss: 0.6189 - val_accuracy: 0.6717\n",
            "Epoch 27/100\n",
            "145/145 [==============================] - 1s 6ms/step - loss: 0.6006 - accuracy: 0.7032 - val_loss: 0.6189 - val_accuracy: 0.6763\n",
            "Epoch 28/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5970 - accuracy: 0.7017 - val_loss: 0.6189 - val_accuracy: 0.6758\n",
            "Epoch 29/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5949 - accuracy: 0.7069 - val_loss: 0.6243 - val_accuracy: 0.6753\n",
            "Epoch 30/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5947 - accuracy: 0.7115 - val_loss: 0.6292 - val_accuracy: 0.6717\n",
            "Epoch 31/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5928 - accuracy: 0.7106 - val_loss: 0.6359 - val_accuracy: 0.6672\n",
            "Epoch 32/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5945 - accuracy: 0.7104 - val_loss: 0.6220 - val_accuracy: 0.6833\n",
            "Epoch 33/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5919 - accuracy: 0.7158 - val_loss: 0.6266 - val_accuracy: 0.6788\n",
            "Epoch 34/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5927 - accuracy: 0.7110 - val_loss: 0.6170 - val_accuracy: 0.6874\n",
            "Epoch 35/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5891 - accuracy: 0.7126 - val_loss: 0.6314 - val_accuracy: 0.6429\n",
            "Epoch 36/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5928 - accuracy: 0.7154 - val_loss: 0.6247 - val_accuracy: 0.6838\n",
            "Epoch 37/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5877 - accuracy: 0.7180 - val_loss: 0.6167 - val_accuracy: 0.6894\n",
            "Epoch 38/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5905 - accuracy: 0.7182 - val_loss: 0.6173 - val_accuracy: 0.6879\n",
            "Epoch 39/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5879 - accuracy: 0.7219 - val_loss: 0.6253 - val_accuracy: 0.6823\n",
            "Epoch 40/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5861 - accuracy: 0.7229 - val_loss: 0.6253 - val_accuracy: 0.6813\n",
            "Epoch 41/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.7199 - val_loss: 0.6454 - val_accuracy: 0.6641\n",
            "Epoch 42/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5854 - accuracy: 0.7210 - val_loss: 0.6195 - val_accuracy: 0.6838\n",
            "Epoch 43/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5858 - accuracy: 0.7249 - val_loss: 0.6173 - val_accuracy: 0.6894\n",
            "Epoch 44/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5864 - accuracy: 0.7193 - val_loss: 0.6172 - val_accuracy: 0.6874\n",
            "Epoch 45/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5835 - accuracy: 0.7262 - val_loss: 0.6252 - val_accuracy: 0.6803\n",
            "Epoch 46/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5850 - accuracy: 0.7240 - val_loss: 0.6162 - val_accuracy: 0.6939\n",
            "Epoch 47/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5838 - accuracy: 0.7247 - val_loss: 0.6194 - val_accuracy: 0.6823\n",
            "Epoch 48/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5842 - accuracy: 0.7225 - val_loss: 0.6475 - val_accuracy: 0.6652\n",
            "Epoch 49/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5843 - accuracy: 0.7249 - val_loss: 0.6177 - val_accuracy: 0.6879\n",
            "Epoch 50/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5826 - accuracy: 0.7251 - val_loss: 0.6299 - val_accuracy: 0.6758\n",
            "Epoch 51/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5835 - accuracy: 0.7190 - val_loss: 0.6201 - val_accuracy: 0.6859\n",
            "Epoch 52/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5811 - accuracy: 0.7240 - val_loss: 0.6166 - val_accuracy: 0.6914\n",
            "Epoch 53/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5804 - accuracy: 0.7281 - val_loss: 0.6179 - val_accuracy: 0.6879\n",
            "Epoch 54/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5812 - accuracy: 0.7253 - val_loss: 0.6238 - val_accuracy: 0.6813\n",
            "Epoch 55/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5796 - accuracy: 0.7242 - val_loss: 0.6246 - val_accuracy: 0.6798\n",
            "Epoch 56/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5808 - accuracy: 0.7242 - val_loss: 0.6220 - val_accuracy: 0.6843\n",
            "Epoch 57/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5813 - accuracy: 0.7255 - val_loss: 0.6177 - val_accuracy: 0.6919\n",
            "Epoch 58/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5805 - accuracy: 0.7277 - val_loss: 0.6187 - val_accuracy: 0.6843\n",
            "Epoch 59/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5794 - accuracy: 0.7286 - val_loss: 0.6164 - val_accuracy: 0.6924\n",
            "Epoch 60/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5791 - accuracy: 0.7262 - val_loss: 0.6189 - val_accuracy: 0.6859\n",
            "Epoch 61/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5819 - accuracy: 0.7281 - val_loss: 0.6193 - val_accuracy: 0.6869\n",
            "Epoch 62/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5790 - accuracy: 0.7281 - val_loss: 0.6167 - val_accuracy: 0.6914\n",
            "Epoch 63/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7275 - val_loss: 0.6243 - val_accuracy: 0.6813\n",
            "Epoch 64/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5808 - accuracy: 0.7281 - val_loss: 0.6196 - val_accuracy: 0.6848\n",
            "Epoch 65/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5770 - accuracy: 0.7299 - val_loss: 0.6166 - val_accuracy: 0.6879\n",
            "Epoch 66/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5790 - accuracy: 0.7262 - val_loss: 0.6223 - val_accuracy: 0.6848\n",
            "Epoch 67/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5773 - accuracy: 0.7292 - val_loss: 0.6187 - val_accuracy: 0.6889\n",
            "Epoch 68/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5769 - accuracy: 0.7299 - val_loss: 0.6187 - val_accuracy: 0.6869\n",
            "Epoch 69/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5772 - accuracy: 0.7279 - val_loss: 0.6333 - val_accuracy: 0.6742\n",
            "Epoch 70/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5786 - accuracy: 0.7271 - val_loss: 0.6173 - val_accuracy: 0.6904\n",
            "Epoch 71/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5784 - accuracy: 0.7286 - val_loss: 0.6211 - val_accuracy: 0.6838\n",
            "Epoch 72/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5756 - accuracy: 0.7323 - val_loss: 0.6149 - val_accuracy: 0.6965\n",
            "Epoch 73/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5761 - accuracy: 0.7325 - val_loss: 0.6181 - val_accuracy: 0.6899\n",
            "Epoch 74/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5764 - accuracy: 0.7327 - val_loss: 0.6149 - val_accuracy: 0.6914\n",
            "Epoch 75/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5751 - accuracy: 0.7299 - val_loss: 0.6247 - val_accuracy: 0.6768\n",
            "Epoch 76/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5772 - accuracy: 0.7268 - val_loss: 0.6210 - val_accuracy: 0.6833\n",
            "Epoch 77/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5770 - accuracy: 0.7262 - val_loss: 0.6293 - val_accuracy: 0.6753\n",
            "Epoch 78/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5763 - accuracy: 0.7320 - val_loss: 0.6154 - val_accuracy: 0.6919\n",
            "Epoch 79/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5770 - accuracy: 0.7271 - val_loss: 0.6165 - val_accuracy: 0.6919\n",
            "Epoch 80/100\n",
            "145/145 [==============================] - 1s 6ms/step - loss: 0.5745 - accuracy: 0.7323 - val_loss: 0.6145 - val_accuracy: 0.6944\n",
            "Epoch 81/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5728 - accuracy: 0.7320 - val_loss: 0.6158 - val_accuracy: 0.6924\n",
            "Epoch 82/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5735 - accuracy: 0.7320 - val_loss: 0.6137 - val_accuracy: 0.6949\n",
            "Epoch 83/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5739 - accuracy: 0.7314 - val_loss: 0.6214 - val_accuracy: 0.6818\n",
            "Epoch 84/100\n",
            "145/145 [==============================] - 1s 6ms/step - loss: 0.5736 - accuracy: 0.7314 - val_loss: 0.6136 - val_accuracy: 0.6944\n",
            "Epoch 85/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5729 - accuracy: 0.7344 - val_loss: 0.6131 - val_accuracy: 0.6970\n",
            "Epoch 86/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5711 - accuracy: 0.7325 - val_loss: 0.6157 - val_accuracy: 0.6939\n",
            "Epoch 87/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5725 - accuracy: 0.7331 - val_loss: 0.6163 - val_accuracy: 0.6909\n",
            "Epoch 88/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5733 - accuracy: 0.7312 - val_loss: 0.6131 - val_accuracy: 0.7000\n",
            "Epoch 89/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5726 - accuracy: 0.7294 - val_loss: 0.6148 - val_accuracy: 0.6975\n",
            "Epoch 90/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5729 - accuracy: 0.7355 - val_loss: 0.6127 - val_accuracy: 0.6934\n",
            "Epoch 91/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5734 - accuracy: 0.7292 - val_loss: 0.6141 - val_accuracy: 0.6965\n",
            "Epoch 92/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5719 - accuracy: 0.7333 - val_loss: 0.6308 - val_accuracy: 0.6742\n",
            "Epoch 93/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5731 - accuracy: 0.7301 - val_loss: 0.6183 - val_accuracy: 0.6909\n",
            "Epoch 94/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5724 - accuracy: 0.7340 - val_loss: 0.6127 - val_accuracy: 0.6944\n",
            "Epoch 95/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5698 - accuracy: 0.7364 - val_loss: 0.6144 - val_accuracy: 0.6924\n",
            "Epoch 96/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5711 - accuracy: 0.7327 - val_loss: 0.6129 - val_accuracy: 0.6934\n",
            "Epoch 97/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5714 - accuracy: 0.7335 - val_loss: 0.6161 - val_accuracy: 0.6914\n",
            "Epoch 98/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5702 - accuracy: 0.7338 - val_loss: 0.6147 - val_accuracy: 0.7015\n",
            "Epoch 99/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7323 - val_loss: 0.6120 - val_accuracy: 0.6970\n",
            "Epoch 100/100\n",
            "145/145 [==============================] - 1s 5ms/step - loss: 0.5725 - accuracy: 0.7346 - val_loss: 0.6111 - val_accuracy: 0.7005\n"
          ]
        }
      ],
      "source": [
        "attack_model_bundle = f_attack(D_attack[:, :-1], D_attack[:, -1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAveNFNrvrX"
      },
      "source": [
        "## Attack Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "g9GxZE5Yntpw"
      },
      "outputs": [],
      "source": [
        "def evaluate_attack(attack_model, X_attack, y_attack, n_classes):\n",
        "  acc_per_class = []\n",
        "  for c in range(n_classes):\n",
        "    class_instances = X_attack[:, 0] == c # get same class samples\n",
        "    test_loss, test_acc = attack_model.evaluate(X_attack[class_instances, :], y_attack[class_instances], verbose=0)\n",
        "    acc_per_class.append(test_acc)\n",
        "    print(f\"class-{c+1}: {test_acc}\")\n",
        "  return acc_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiQyYdB7SABg",
        "outputId": "b4e35c78-93c4-4c6b-e371-9be48b623478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with 'in' data only:\n",
            "class-1: 0.987500011920929\n",
            "class-2: 0.9655172228813171\n",
            "class-3: 0.9487179517745972\n",
            "class-4: 0.9677419066429138\n",
            "class-5: 0.9636363387107849\n",
            "class-6: 0.989130437374115\n",
            "class-7: 0.9830508232116699\n",
            "class-8: 0.9793814420700073\n",
            "class-9: 0.9239130616188049\n",
            "class-10: 0.929411768913269\n",
            "\n",
            "Testing with 'out' data only:\n",
            "class-1: 0.529411792755127\n",
            "class-2: 0.4848484992980957\n",
            "class-3: 0.6582278609275818\n",
            "class-4: 0.7551020383834839\n",
            "class-5: 0.6363636255264282\n",
            "class-6: 0.5957446694374084\n",
            "class-7: 0.36082473397254944\n",
            "class-8: 0.6101694703102112\n",
            "class-9: 0.44736841320991516\n",
            "class-10: 0.516853928565979\n",
            "\n",
            "Testing with all prev data: \n",
            "class-1: 0.7307692170143127\n",
            "class-2: 0.7441860437393188\n",
            "class-3: 0.831632673740387\n",
            "class-4: 0.8586387634277344\n",
            "class-5: 0.800000011920929\n",
            "class-6: 0.7903226017951965\n",
            "class-7: 0.7023255825042725\n",
            "class-8: 0.7767441868782043\n",
            "class-9: 0.6601941585540771\n",
            "class-10: 0.7183908224105835\n",
            "\n",
            "Total attack accuracy: 0.7613204061985016\n"
          ]
        }
      ],
      "source": [
        "# create a test dataset \n",
        "\n",
        "D_in = prepare_batch(target_model, train_images[:1000], train_labels[:1000], True)\n",
        "print(\"Testing with 'in' data only:\")\n",
        "res_in = evaluate_attack(attack_model_bundle, D_in[:, :-1], D_in[:, -1], 10)\n",
        "\n",
        "D_out = prepare_batch(target_model, attacker_images[:1000], attacker_labels[:1000], False)\n",
        "print(\"\\nTesting with 'out' data only:\")\n",
        "res_out = evaluate_attack(attack_model_bundle, D_out[:, :-1], D_out[:, -1], 10)\n",
        "\n",
        "print(\"\\nTesting with all prev data: \")\n",
        "res_all = evaluate_attack(attack_model_bundle, np.concatenate((D_out[:, :-1], D_in[:, :-1])), np.concatenate((D_out[:, -1], D_in[:, -1])), 10)\n",
        "\n",
        "print(f\"\\nTotal attack accuracy: {np.mean(res_all)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wDNdLqnnyVp",
        "outputId": "c08b1292-a9f9-4205-bcd8-15fdfff3e371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      0.56      0.70      1000\n",
            "         1.0       0.69      0.96      0.80      1000\n",
            "\n",
            "    accuracy                           0.76      2000\n",
            "   macro avg       0.81      0.76      0.75      2000\n",
            "weighted avg       0.81      0.76      0.75      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = (attack_model_bundle.predict(np.concatenate((D_out[:, :-1], D_in[:, :-1]))) > 0.5).astype(np.int8)\n",
        "y_true = np.concatenate((D_out[:, -1], D_in[:, -1]))\n",
        "print(classification_report(y_true.reshape(-1), y_pred.reshape(-1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "G8aQH6Nqp3Ah",
        "outputId": "138fbe30-7c9b-4e5f-9e4e-7eaf18c48247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC = 0.7618734999999999\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdC0lEQVR4nO3de3zWdd3H8ddnJ8ZgjMM2kLExkHEYKqADjyUGIppBhzuF8laLW8rSO8ssy240s0d3mWYHuotKU7vN1MpWoBQe8k5FDiGDcRyIMGBsDBgbY4dr1/f+47qkOTZ3wa5dv+vwfj4ePB7X77Drev/YePPb93cy5xwiIhL7krwOICIi4aFCFxGJEyp0EZE4oUIXEYkTKnQRkTiR4tUHZ2dnu8LCQq8+XkQkJq1du/agcy6ns2WeFXphYSFr1qzx6uNFRGKSmb3d1TINuYiIxAkVuohInFChi4jECRW6iEicUKGLiMSJbgvdzB42s2oz29jFcjOzH5lZhZmVmdm54Y8pIiLdCWUP/dfA7PdYfiVQFPyzEPifnscSEZFT1e156M65V8ys8D1WmQs85gL34V1pZgPN7Azn3P4wZRQRiZjq+iZqG1p4u7aRJHv3Mp/fseqtQwxI79klPDMmDGVS/sAevUdnwnFhUR6wp910ZXDeSYVuZgsJ7MVTUFAQho8WkURSfbSJljb/SfMrqhtoam1717yyyjqsQyE7By9uqabqaBO+NkeflHcPUtQeawk5S8f3PhW5A9KjttBD5pxbAiwBKCkp0ZM1ROQka98+xPLyAyQFG3Pz/qPsPNjAnkPHT+v9UtrtZrc5h3PQJyWJIf3S+MCE3JPWP9LYyiVjsklPTWZMbv+TlmekJTM65+T50SAchb4XyG83PSI4T0R6ybFmH9X1ze+at7/uODX1zVhPdh07eGNnLf36dF0Tr++oJbOb4YeVO2tJS0kiNbn7Q3b1Tb4Tr1OTDTOjxRfYI88f3JdxQzOZVTwMOg6FtDlG5/Qjq2/qu+aPzulHn5Tkbj83XoSj0EuBW8zsSeB8oE7j55LIquubOHrcd9L8ysONHGls7fRr/M7xakUtAzP+VUi1Dc2U7zvK9uoG0pKTSE3+V4sda2nr7G16Td/Uzkuxtc2Pz++YWjioy689t2AQR5tauXhMdkifVdfYyrxpBUwbNfi0siaybgvdzH4LTAeyzawSuBtIBXDO/QxYBlwFVACNwKd6K6xIOLT5Ha9WHKS6vpn/fSNwn6OUjke/3sOW/fXUN/tIS04iqcNOZ1PryeO7p6p/cI+4tc1Ps8/PyCEZjMrux5h2v+b7HfRNS6IoN/NdX5vVN5X8wRk9zvCO5CSjcEhGWPf6pfeEcpbL/G6WO+DzYUskcpqcc+yqbWTL/qO8uecIDc0+koNFve9IEy9sOUBXz0S/6MwhIX/O2SOyqDraxMwJQzv+5g/AsRYf44ZmkpWRdtKyIf3SGD6wb6fv2yclqctlIqHw7Pa5IuG0vLyKO55ez9Gmdw91DAoOYfj8gYNhZ2SlM2fScNr8jsvG55I/KIO8QX1PFL9ILFOhS0xb9KeNPPb6u28PvfgT53LGwHQmDBtA37TEOSAmokKXmOP3O1a+VcsnfvHGiXkThw/gwWsmM3JIBuldHMATiXcqdIkJ63Yf5pFXd/FqxcGTLv54+cvTKczu51EykeihQpeot7RsP59/4p9AYEw8N7MPI4dkcPuscUwtHKzxb5EgFbpEra1V9Vzx0CsnpudMGs6P5k/xMJFIdFOhS1Q60tjCJ38ZGCPPSEvmz7dewplRerm1SLRQoUvU+eGK7Ty1Zg8HG5r56Ll5PHjNZK8jicQEFbpEnZ++XEGzz8+vPzWVS8fmeB1HJGao0CVq3Pn7MpaXV9Hs83PDhSOZPu7kO+GJSNdU6BIV/m97DU+uDtxW/9qSfD5ekt/NV4hIRyp08dQ/dx/mtiff5HDw3PJHbpzKZeO1Zy5yOlTo4on9dce5/an1vLajFoCphYO48MxsjZmL9IAKXSLO73dc+J0XgcAdBr/xwQn8+4WF3oYSiQMqdIkoX5ufC4JlDlD+zStICeFJNiLSPRW6RMzBhmZK7ltxYnrVXTNU5iJhpEKXiHl2XeBRsxOHD+CPn7uYtBSVuUg4qdAlIh5asY2HVmwH4OEbp6rMRXqBCl16TeXhRpaW7adsbx1LywLPDf/aleMZOiDd42Qi8UmFLr3iM4+vYXn5gRPT1184ks9ceiZ5emamSK9RoUvY1dQ3nyjzO64Yx03vG60hFpEIUKFL2P11UxUAD3x8Eh87b4THaUQSh3abJKyaWtu498+bSEtJYmLeAK/jiCQUFbqE1T+2H6TZ5+frV45n/DAVukgkqdAlbJxz3PmHMs7ISucjUzTUIhJpKnQJm9L1+zjY0MLnLhtDVkaq13FEEo4KXcKivqmV+5Zu5pwRWXxiWoHXcUQSks5ykbD44YrtHGxo5hfXl5CcZF7HEUlI2kOXHttaVc8jr+1i3tR8JucP9DqOSMJSoUuPOOdY9KeNZKancMcV472OI5LQVOjSI6Xr9/HGW4f48qxxDO6X5nUckYQWUqGb2Wwz22pmFWZ2ZyfLC8zsJTNbZ2ZlZnZV+KNKtGlo9vHtpZs5Oy+L+ToQKuK5bgvdzJKBxcCVQDEw38yKO6z2DeAp59wUYB7w03AHlejzwxXbqK5v5t65E3UgVCQKhLKHPg2ocM7tdM61AE8Cczus44B3LgvMAvaFL6JEo+0H6nnk1V1cW5LPlIJBXscREUIr9DxgT7vpyuC89u4BrjOzSmAZcGtnb2RmC81sjZmtqampOY24Eg0CB0LL6dcnha/MHud1HBEJCtdB0fnAr51zI4CrgMfN7KT3ds4tcc6VOOdKcnJywvTREml/LtvP6ztr+fIV4xjSv4/XcUQkKJRC3wvkt5seEZzX3gLgKQDn3OtAOpAdjoASXQIHQjdxVt4AXREqEmVCKfTVQJGZjTKzNAIHPUs7rLMbmAFgZhMIFLrGVOLQj1/YzoGjzdw79ywdCBWJMt0WunPOB9wCLAc2EzibpdzM7jWzOcHVbgduMrP1wG+BG51zrrdCizcqquv51T/e4pqSEZyrA6EiUSeke7k455YRONjZft6idq83AReHN5pEm+8v34bP7/jKbF0RKhKNdKWohGRrVT3Pl1cxpF8aQ3RFqEhU0t0WpVuNLT5ueeKfZPfvw19uvQQzjZ2LRCMVunTrntJyKmoaePzT5zMsK93rOCLSBQ25yHt6dt1enlpTyeenj+GSIp2JKhLNVOjSpZ01Ddz1xw1MLRzEbTOLvI4jIt1QoUunmlrbuOWJdaSmJPHDeVNISdaPiki00xi6dOo7yzazaf9Rfnl9CcMH9vU6joiEQLtdcpLnN+7n0dffZsElo5hZPNTrOCISIhW6vMueQ4185ZkyzhmRxVd1AZFITFGhywkNzT4+8/hanIMfz59CWop+PERiicbQBQicnnjb794E4CefmMLIIf08TiQip0qFLgD87xtvM7hfGrfNLOLqc4Z7HUdEToN+pxb2HjnO6l2HufqcM7j+wkKv44jIaVKhJ7jDx1q4/MG/A/CJ8/XACpFYpiGXBDflW38D4Aszihg/bEA3a4tINNMeegJraPadeP3Fy8d6mEREwkGFnsC+vXQzAHd/qNjjJCISDir0BFXf1MpvV+3m4jFD+PDkPK/jiEgYqNAT1I6aYwDccGEhg/QEIpG4oEJPUBXVDQCMye3vcRIRCRcVeoLaXl1PWnISBYMzvI4iImGiQk9QO6obKMzO0H3OReKI/jUnqIrqBg23iMQZFXoCamptY/ehRsbkZnodRUTCSIWegHbVHsPvdEBUJN6o0BPQiTNcclToIvFEhZ6AKqobMIPRObrnuUg8UaEnoO3VDeQPyiA9NdnrKCISRir0BLSjuoEijZ+LxB0VeoJpbfOzpapeB0RF4lBIhW5ms81sq5lVmNmdXaxzjZltMrNyM3sivDElXJ5ZWwlAwRBdISoSb7p9wIWZJQOLgcuBSmC1mZU65za1W6cI+BpwsXPusJnl9lZg6Rmf3wFw2Th9i0TiTSh76NOACufcTudcC/AkMLfDOjcBi51zhwGcc9XhjSnhsvfwcQBSdcm/SNwJ5RF0ecCedtOVwPkd1hkLYGavAsnAPc655zu+kZktBBYCFBTo+ZWRtGLTAb69bDNvHTzGpWNzyO6vW+aKxJtwPVM0BSgCpgMjgFfM7Gzn3JH2KznnlgBLAEpKSlyYPlu60dDs40tPvcnRJh+3Xz6Wm6efiZl5HUtEwiyU37v3AvntpkcE57VXCZQ651qdc28B2wgUvESBZ9bs4WiTj89fdia3zijSHRZF4lQo/7JXA0VmNsrM0oB5QGmHdZ4lsHeOmWUTGILZGcac0gMvbq0hLSWJL87Ug6BF4lm3he6c8wG3AMuBzcBTzrlyM7vXzOYEV1sO1JrZJuAl4A7nXG1vhZZT09DUypT8gdozF4lzIY2hO+eWAcs6zFvU7rUDvhT8I1Fk9a5D/HP3ERa+f7TXUUSkl2mXLc79tbxKwy0iCUKFHudW7TrM5BED6ZumG3GJxDsVehw71uyjfG8dU0cN8jqKiESACj2Ordt9BJ/fMW3UEK+jiEgEqNDj2Kpdh0gyOLdgoNdRRCQCVOhxbNVbtRQPH0BmeqrXUUQkAlTocarF52fd7iNMLRzsdRQRiRAVepzasLeOZp+f80ep0EUShQo9Tt23NHC7+hLtoYskDBV6nGpsbgMgu38fj5OISKSo0OPQH9dVsvVAPZeNy/E6iohEkAo9zvj9ji/+bj0AN08f43EaEYkkFXqcWV8ZeKbIWXkDmKYDoiIJRYUeR5xz3PLEOvqmJvPQtVO8jiMiEaZCjyMV1Q3sPXKcr101njG5/b2OIyIRpkKPI8vLqwCYVTzM4yQi4gUVehz566YDTM4fyLCsdK+jiIgHVOhxYt+R45RV1jFr4lCvo4iIR1TocWLF5gOAhltEEpkKPU4sL69idE4/HQwVSWAq9DhQ19jKyp2HuGKi9s5FEpkKPQ68uPUAbX7HrGKNn4skMhV6HFi+8QC5mX2YNEJPJhJJZCr0GFff1Mrz5VXMmjiUpCTzOo6IeEiFHuMe/Ns2AGZPPMPjJCLiNRV6jGtt8wNw8ZghHicREa+p0GOY3+/4zcrdZKQlY6bhFpFEl+J1ADl1b9ceY8Xmal6rOAjAoIw0jxOJSDRQoceYY80+Lr3/5RPTAzNSWf7F93sXSESihgo9xmzafxSAMbn9+f3NF9E3NZm0FI2ciYgKPea8cxD0m3MmktU31eM0IhJNQtq1M7PZZrbVzCrM7M73WO9jZubMrCR8EaW9iuoGAEZl9/M4iYhEm24L3cySgcXAlUAxMN/MijtZLxP4AvBGuEPKv5RV1pHdP40zdM9zEekglD30aUCFc26nc64FeBKY28l63wK+CzSFMZ90sKGyjrPzsnSaooicJJRCzwP2tJuuDM47wczOBfKdc0vf643MbKGZrTGzNTU1NaccNtE1tvjYXl3PObpni4h0osenR5hZEvAgcHt36zrnljjnSpxzJTk5OT396ISzad9R/A7OGZHldRQRiUKhFPpeIL/d9IjgvHdkAmcBL5vZLuACoFQHRsOvrLIOgLPzVOgicrJQCn01UGRmo8wsDZgHlL6z0DlX55zLds4VOucKgZXAHOfcml5JnMDKKo8wbEA6uQN0QFRETtZtoTvnfMAtwHJgM/CUc67czO41szm9HVD+pWxvHWdruEVEuhDShUXOuWXAsg7zFnWx7vSex5KO6pta2VlzjI9Mzut+ZRFJSLpmPEZs3Bu45F976CLSFRV6DGht8/PTlysAKByiK0RFpHMq9Cjna/Oz4NE1/N/2wK1yB2bo/i0i0jkVepR79PW3eWVb4CKsVXfNYKDufS4iXVChR7HWNj9PrwlcpPvSl6eTm6nTFUWkayr0KHbH0+vZUlXPNz44QXdXFJFuqdCj1Os7ann2zX1MKRjIgktGeR1HRGKACj0K+f2O+5ZuYtiAdJ74jwt0Z0URCYkKPQr9/p+VlO87yteuGk/ftGSv44hIjFChR5nGFh/3L9/K5PyBzJk03Os4IhJDVOhR5md/30l1fTP/dXWxhlpE5JSo0KPI/rrjLHllB1efcwbnjRzkdRwRiTEq9Chy//Nb8Tv46uzxXkcRkRikQo8SZZVH+MO6vSy4ZBT5gzO8jiMiMUiFHgWcc3zrL5vI7p/G56af6XUcEYlRKvQo8PzGKlbvOsyXLh9HZrpuviUip0eF7rFmXxvfeW4L44dlcu3U/O6/QESkCyp0jz362i52H2rkrg9OIDlJpymKyOlToXuotqGZH79QwQfG5/K+ohyv44hIjFOhe+ihFdtpbG3j61fpNEUR6TkVuke2H6jniVW7ue78AsbkZnodR0TigArdI/ct3UxGWjJfmDnW6ygiEidU6B54eWs1f99WwxdmFDG4nx4pJyLhoUKPsJe2VLPw8bWMHJLBv1840us4IhJHUrwOkCg27q3jf/6+g6Vl+wH474+eQ58U3etcRMJHhR4BtQ3NXP3jfwBw2bgcbp81jrPysjxOJSLxRoUeAV/9fRkAv7qhhBkThnqcRkTilcbQe9mrFQdZsbma2y8fqzIXkV6lQu9FrW1+7i4tp2BwBje9f7TXcUQkzqnQe9Fjr79NRXUDi64uJj1VB0BFpHeFVOhmNtvMtppZhZnd2cnyL5nZJjMrM7MXzCzhz8erqW/mob9t49KxOcyYkOt1HBFJAN0WupklA4uBK4FiYL6ZFXdYbR1Q4pw7B3gG+F64g8aa7z2/hSZfG3d/SA97FpHICGUPfRpQ4Zzb6ZxrAZ4E5rZfwTn3knOuMTi5EhgR3pixZd3uwzy9tpJPXzKK0Tn9vY4jIgkilELPA/a0m64MzuvKAuC5zhaY2UIzW2Nma2pqakJPGUP8fsc9peXkZvbh1g8UeR1HRBJIWA+Kmtl1QAlwf2fLnXNLnHMlzrmSnJz4vP/3M2srWV9Zx9euGk//PjrNX0QiJ5TG2Qu0fzbaiOC8dzGzmcBdwKXOuebwxIstdcdb+e7zWygZOYgPT36vX2JERMIvlD301UCRmY0yszRgHlDafgUzmwL8HJjjnKsOf8zY8NCKbRxqbOGeORN1IFREIq7bQnfO+YBbgOXAZuAp51y5md1rZnOCq90P9AeeNrM3zay0i7eLW9sO1PPY628zf1qB7tMiIp4IaZDXObcMWNZh3qJ2r2eGOVdMcS5wILR/nxTumDXO6zgikqB01K6Hth+o56M/fY36Zh/3fKiYQXpghYh4RIXeAxXVDVz+g1cAGJ6VzkfPS+jT70XEYyr007RyZy2feXwt2f3TuPtDE/nQpOFeRxKRBKdCPw3PrtvLHc+sZ+SQfjxy41TyB2d4HUlERIV+Kpxz/OTFCh742zYuGD2Yn19XQlZGqtexREQAFXrIWnx+vv7HDTyztpKPTsnjvz92DmkpuvuwiEQPFXoI6o63cvNv1vLajlq+MKOI22YW6cIhEYk6KvRuVB5u5FOPrGZX7TG+//FJ/JvOZBGRKKVCfw9llUdY8OgamlrbePRT07hoTLbXkUREuqRC78LfNh3gP3+7jsH90njiP86naGim15FERN6TCr0Tv371Lb75l02cnZfFL28oITcz3etIIiLdUqF3sPilCu5fvpXLi4fyw3mTyUjTX5GIxAa1VTsvbjnA/cu3ct7IQfzsuvNITtKZLCISO3QiddDhYy185ZkNjB+WycM3TFWZi0jM0R560N2l5dQdb+GxT0/T1Z8iEpO0hw48t2E/pev38Z8fKKJ4+ACv44iInJaEL/SDDc3c9exGzs7L4rPTz/Q6jojIaUvoQnfO8V/PbqShyccD10wiNTmh/zpEJMYldIP9uWw/z22s4ouXj2WsLhwSkRiXsIVeXd/Eoj9tZHL+QG563yiv44iI9FhCFrpzjq//YQPHW9p44JpJpGioRUTiQMKdtvj8xir+vq2GFZur+cYHJ3BmTn+vI4mIhEVCFfo7l/UDzBify6cu1lCLiMSPhCj0LVVH+eQv3qD2WAsAL9x+KaOz++khFSISVxKi0K/75Spqj7WQ2SeFn3zyXA2ziEhcittCb/H5KV2/jx+9sJ2DDc0Mykhl3aJZXscSEek1cVfoVXVNLNuwnx+9uJ0jja0AFOX25/sfn+RxMhGR3hVXhX7/8i0sfmnHien3FWVz28yxnDdykIepREQiI24K/R/bD54o89svH8u1U/PJHaAnDYlI4oj5Qv/pyxU8t6GKDXvrAPjBtZP4yJQRHqcSEYm8mC70V7bV8L3nA+eVX3dBATdeNIoxuTqDRUQSU0jXvJvZbDPbamYVZnZnJ8v7mNnvgsvfMLPCcAftqLXNz/UPrwJg0dXF3Pfhs1XmIpLQui10M0sGFgNXAsXAfDMr7rDaAuCwc24M8APgu+EO2t7GvXU88NdtANx4USGfvkRXfIqIhDLkMg2ocM7tBDCzJ4G5wKZ268wF7gm+fgb4iZmZc86FMSsQuBfLZ3+z9sT0DRcVhvsjRERiUiiFngfsaTddCZzf1TrOOZ+Z1QFDgIPtVzKzhcBCgIKCgtMKnGSB0xHvvHI8RbmZpKXoTokiIhDhg6LOuSXAEoCSkpLT2nufNXEYsyYOC2suEZF4EMru7V4gv930iOC8TtcxsxQgC6gNR0AREQlNKIW+Gigys1FmlgbMA0o7rFMK3BB8/W/Ai70xfi4iIl3rdsglOCZ+C7AcSAYeds6Vm9m9wBrnXCnwK+BxM6sADhEofRERiaCQxtCdc8uAZR3mLWr3ugn4eHijiYjIqdApIiIicUKFLiISJ1ToIiJxQoUuIhInzKuzC82sBnj7NL88mw5XoSYAbXNi0DYnhp5s80jnXE5nCzwr9J4wszXOuRKvc0SStjkxaJsTQ29ts4ZcRETihApdRCROxGqhL/E6gAe0zYlB25wYemWbY3IMXUREThare+giItKBCl1EJE5EdaFH48Ope1sI2/wlM9tkZmVm9oKZjfQiZzh1t83t1vuYmTkzi/lT3ELZZjO7Jvi9LjezJyKdMdxC+NkuMLOXzGxd8Of7Ki9yhouZPWxm1Wa2sYvlZmY/Cv59lJnZuT3+UOdcVP4hcKveHcBoIA1YDxR3WOdzwM+Cr+cBv/M6dwS2+TIgI/j65kTY5uB6mcArwEqgxOvcEfg+FwHrgEHB6Vyvc0dgm5cANwdfFwO7vM7dw21+P3AusLGL5VcBzwEGXAC80dPPjOY99BMPp3bOtQDvPJy6vbnAo8HXzwAzzMwimDHcut1m59xLzrnG4ORKAk+QimWhfJ8BvgV8F2iKZLheEso23wQsds4dBnDOVUc4Y7iFss0OGBB8nQXsi2C+sHPOvULg+RBdmQs85gJWAgPN7IyefGY0F3pnD6fO62od55wPeOfh1LEqlG1ubwGB/+FjWbfbHPxVNN85tzSSwXpRKN/nscBYM3vVzFaa2eyIpesdoWzzPcB1ZlZJ4PkLt0YmmmdO9d97tyL6kGgJHzO7DigBLvU6S28ysyTgQeBGj6NEWgqBYZfpBH4Le8XMznbOHfE0Ve+aD/zaOfeAmV1I4CloZznn/F4HixXRvIeeiA+nDmWbMbOZwF3AHOdcc4Sy9ZbutjkTOAt42cx2ERhrLI3xA6OhfJ8rgVLnXKtz7i1gG4GCj1WhbPMC4CkA59zrQDqBm1jFq5D+vZ+KaC70RHw4dbfbbGZTgJ8TKPNYH1eFbrbZOVfnnMt2zhU65woJHDeY45xb403csAjlZ/tZAnvnmFk2gSGYnZEMGWahbPNuYAaAmU0gUOg1EU0ZWaXA9cGzXS4A6pxz+3v0jl4fCe7mKPFVBPZMdgB3BefdS+AfNAS+4U8DFcAqYLTXmSOwzSuAA8CbwT+lXmfu7W3usO7LxPhZLiF+n43AUNMmYAMwz+vMEdjmYuBVAmfAvAnM8jpzD7f3t8B+oJXAb1wLgM8Cn233PV4c/PvYEI6fa136LyISJ6J5yEVERE6BCl1EJE6o0EVE4oQKXUQkTqjQRUTihApdRCROqNBFROLE/wMIqOGl7MhKxgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "y_pred = attack_model_bundle.predict(np.concatenate((D_out[:, :-1], D_in[:, :-1])))\n",
        "y_true = np.concatenate((D_out[:, -1], D_in[:, -1]))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "\n",
        "print(f\"AUC = {roc_auc_score(y_true, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grjprA4PmE7"
      },
      "source": [
        "# Extras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9g2jus3rP1j"
      },
      "source": [
        "## Check target model's behaviour in perturbed images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sD5YbfusfCob"
      },
      "outputs": [],
      "source": [
        "def study_perturbations(model, X, y, rs, ts):\n",
        "  diffs = []\n",
        "  y_pred = target_predict(model, X)    \n",
        "  for c in range(10):\n",
        "    #  given class acquire the changes in perturbed input instances given the model\n",
        "    idx = y_pred[:, 0] == c\n",
        "    X_c = X[idx]\n",
        "    y_pred_c = y_pred[idx]\n",
        "    perturbed_labels = (augmented_queries(model, X_c, y_pred_c, rs, ts) == y_pred_c).astype(np.int8)\n",
        "    # Now we have to count how many labels diverge from the predicted label\n",
        "    diff = len(perturbed_labels.reshape(-1)) - sum(perturbed_labels.reshape(-1)) # the labels are binary where 1 == y_pred = y_perturbed, otherwise 0\n",
        "    diffs.append(int(100 * diff/len(perturbed_labels.reshape(-1)))) # append the percentage of changes in the class sample\n",
        "    \n",
        "  return diffs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "w-0sJVhfbfQ3"
      },
      "outputs": [],
      "source": [
        "N_SAMPLES = 100\n",
        "train_idx = np.random.choice(range(train_images.shape[0]), N_SAMPLES, replace=False)\n",
        "test_idx = np.random.choice(range(attacker_images.shape[0]), N_SAMPLES, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dpYCPdS0EA-p",
        "outputId": "3e9f8278-ef1c-4ae3-928d-549c439d84f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7f43ffa1fed0>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffa1f890>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa8fd790>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa1a9250>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa35f750>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8ebeb90>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8ebe350>,\n",
              " <matplotlib.axis.XTick at 0x7f43f9124450>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa374f50>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8f885d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa2093d0>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7f43ffae6f50>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffae6fd0>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffae6790>,\n",
              " <matplotlib.axis.XTick at 0x7f43f9089610>,\n",
              " <matplotlib.axis.XTick at 0x7f43f9089910>,\n",
              " <matplotlib.axis.XTick at 0x7f43f9089150>,\n",
              " <matplotlib.axis.XTick at 0x7f43f913a2d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43f913add0>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa209850>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8f9f090>,\n",
              " <matplotlib.axis.XTick at 0x7f43f9089250>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7f43ffa09110>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffa09e90>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffa09350>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8e73d90>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8fa5f90>,\n",
              " <matplotlib.axis.XTick at 0x7f43f901a710>,\n",
              " <matplotlib.axis.XTick at 0x7f43f901a210>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa342e50>,\n",
              " <matplotlib.axis.XTick at 0x7f43f901ad90>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa209310>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa342b10>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%')]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# tests in D_in\n",
        "diffs_per_class_D_in = study_perturbations(target_model, train_images[train_idx], train_labels[train_idx], r, d) \n",
        "total_diffs_in = sum(diffs_per_class_D_in)/10\n",
        "axes[0].set_title('D_in predicted label divergence');\n",
        "axes[0].barh(list(range(10)), diffs_per_class_D_in, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "# tests in D_out  \n",
        "diffs_per_class_D_out= study_perturbations(target_model,attacker_images[test_idx],attacker_labels[test_idx], r, d)\n",
        "total_diffs_out = sum(diffs_per_class_D_out)/10\n",
        "axes[1].set_title('D_out predicted label divergence');\n",
        "axes[1].barh(list(range(10)), diffs_per_class_D_out, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "axes[2].set_title('Total predicted label divergence percentage');\n",
        "axes[2].barh([1, 0], [total_diffs_in, total_diffs_out], tick_label=['In', 'Out'])\n",
        "\n",
        "plt.setp(axes, xticks=range(0, 101, 10), xticklabels=[f'{i}%' for i in range(0, 101, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZOpEdcmCMXX"
      },
      "source": [
        "## Attack a perturbation trained model\n",
        "\n",
        "- We will apply augmentations to the dataset and re-train the target model.\n",
        "- The attacker **does not** know our augmentation settings, so he will train with a normal dataset of zero augmentations\n",
        "- We want to measure the quality of the attack when the target tries to defend MIAs by adding perturbed images of data samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4Cl0sR-1I_sG"
      },
      "outputs": [],
      "source": [
        "# We will defend against the same rotations and translations that the attack models uses (worst case for the attacker)\n",
        "rotates = create_rotates(r)\n",
        "translates = create_translates(d)\n",
        "\n",
        "X_train_aug = train_images\n",
        "X_eval_aug = eval_images\n",
        "y_train_aug = np.concatenate(tuple([train_labels] + [train_labels for rot in rotates] + [train_labels for tra in translates]))\n",
        "y_eval_aug = np.concatenate(tuple([eval_labels] + [eval_labels for rot in rotates] + [eval_labels for tra in translates]))\n",
        "\n",
        "\n",
        "\n",
        "for rot in rotates:\n",
        "  aug_x = apply_augment(train_images, rot, 'r')\n",
        "  X_train_aug = np.concatenate((X_train_aug,aug_x))\n",
        "  aug_x = apply_augment(eval_images, rot, 'r')\n",
        "  X_eval_aug = np.concatenate((X_eval_aug,aug_x))\n",
        "\n",
        "for tra in translates:\n",
        "  aug_x = apply_augment(train_images, tra, 'd')\n",
        "  X_train_aug = np.concatenate((X_train_aug,aug_x))\n",
        "  aug_x = apply_augment(eval_images, tra, 'd')\n",
        "  X_eval_aug = np.concatenate((X_eval_aug ,aug_x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaNvyxztuwED",
        "outputId": "4d0291aa-721e-46e2-f13d-bf65207b07e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2750/2750 [==============================] - 32s 12ms/step - loss: 0.9559 - accuracy: 0.6728 - val_loss: 2.1167 - val_accuracy: 0.5041\n",
            "Epoch 2/10\n",
            "2750/2750 [==============================] - 32s 12ms/step - loss: 0.2370 - accuracy: 0.9256 - val_loss: 3.0169 - val_accuracy: 0.5290\n",
            "Epoch 3/10\n",
            "2750/2750 [==============================] - 31s 11ms/step - loss: 0.1612 - accuracy: 0.9522 - val_loss: 3.8059 - val_accuracy: 0.5216\n",
            "Epoch 4/10\n",
            "2750/2750 [==============================] - 34s 12ms/step - loss: 0.1366 - accuracy: 0.9618 - val_loss: 3.6493 - val_accuracy: 0.5168\n",
            "Epoch 5/10\n",
            "2750/2750 [==============================] - 31s 11ms/step - loss: 0.1161 - accuracy: 0.9687 - val_loss: 4.0856 - val_accuracy: 0.5143\n",
            "Epoch 6/10\n",
            "2750/2750 [==============================] - 35s 13ms/step - loss: 0.1151 - accuracy: 0.9698 - val_loss: 4.9101 - val_accuracy: 0.5225\n",
            "Epoch 7/10\n",
            "2750/2750 [==============================] - 35s 13ms/step - loss: 0.1116 - accuracy: 0.9724 - val_loss: 5.0081 - val_accuracy: 0.5160\n",
            "Epoch 8/10\n",
            "2750/2750 [==============================] - 36s 13ms/step - loss: 0.1123 - accuracy: 0.9733 - val_loss: 5.5280 - val_accuracy: 0.5055\n",
            "Epoch 9/10\n",
            "2750/2750 [==============================] - 34s 13ms/step - loss: 0.1068 - accuracy: 0.9766 - val_loss: 5.7763 - val_accuracy: 0.5006\n",
            "Epoch 10/10\n",
            "2750/2750 [==============================] - 35s 13ms/step - loss: 0.0957 - accuracy: 0.9787 - val_loss: 6.5052 - val_accuracy: 0.5153\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  X_train_aug = tf.convert_to_tensor(X_train_aug)\n",
        "  y_train_aug = tf.convert_to_tensor(y_train_aug)\n",
        "  X_eval_aug = tf.convert_to_tensor(X_eval_aug)\n",
        "  y_eval_aug = tf.convert_to_tensor(y_eval_aug)\n",
        "  target_model = f_target(X_train_aug, y_train_aug, X_eval_aug, y_eval_aug, epochs=10) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsRYuPrCUBWl"
      },
      "source": [
        "The model is quite overfitted so now all that is left is to evaluate the attack model we created before on the newly trained and \"defended\" target model with perturbations in the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyt1sD06SBFa",
        "outputId": "f6e1d45c-baec-40ea-c677-5277a94e6fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with 'in' data only:\n",
            "class-1: 0.9375\n",
            "class-2: 0.982758641242981\n",
            "class-3: 0.9572649598121643\n",
            "class-4: 0.9784946441650391\n",
            "class-5: 0.9818181991577148\n",
            "class-6: 1.0\n",
            "class-7: 0.991525411605835\n",
            "class-8: 1.0\n",
            "class-9: 0.967391312122345\n",
            "class-10: 0.9882352948188782\n",
            "\n",
            "Testing with 'out' data only:\n",
            "class-1: 0.529411792755127\n",
            "class-2: 0.3737373650074005\n",
            "class-3: 0.6455696225166321\n",
            "class-4: 0.7755101919174194\n",
            "class-5: 0.5636363625526428\n",
            "class-6: 0.457446813583374\n",
            "class-7: 0.4020618498325348\n",
            "class-8: 0.39830508828163147\n",
            "class-9: 0.3333333432674408\n",
            "class-10: 0.4157303273677826\n",
            "\n",
            "Testing with all prev data: \n",
            "class-1: 0.708791196346283\n",
            "class-2: 0.7023255825042725\n",
            "class-3: 0.831632673740387\n",
            "class-4: 0.8743455410003662\n",
            "class-5: 0.7727272510528564\n",
            "class-6: 0.725806474685669\n",
            "class-7: 0.7255814075469971\n",
            "class-8: 0.669767439365387\n",
            "class-9: 0.6165048480033875\n",
            "class-10: 0.6954023241996765\n",
            "\n",
            "Total attack accuracy: 0.7322884738445282\n"
          ]
        }
      ],
      "source": [
        "D_in = prepare_batch(target_model, train_images[:1000], train_labels[:1000], True)\n",
        "print(\"Testing with 'in' data only:\")\n",
        "res_in = evaluate_attack(attack_model_bundle, D_in[:, :-1], D_in[:, -1], 10)\n",
        "\n",
        "D_out = prepare_batch(target_model, attacker_images[:1000], attacker_labels[:1000], False)\n",
        "print(\"\\nTesting with 'out' data only:\")\n",
        "res_out = evaluate_attack(attack_model_bundle, D_out[:, :-1], D_out[:, -1], 10)\n",
        "\n",
        "print(\"\\nTesting with all prev data: \")\n",
        "res_all = evaluate_attack(attack_model_bundle, np.concatenate((D_out[:, :-1], D_in[:, :-1])), np.concatenate((D_out[:, -1], D_in[:, -1])), 10)\n",
        "\n",
        "print(f\"\\nTotal attack accuracy: {np.mean(res_all)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW_JINmBUgd_"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "To conclude if the model is more vulnerable, we must meassure the label divergence percentage in the adjusted-to-augmentations model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OWDU6N1uSCnA",
        "outputId": "b02c5fbc-eb7e-4911-dec4-7d02cf29b946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.axis.XTick at 0x7f43fa8e00d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa8e0310>,\n",
              " <matplotlib.axis.XTick at 0x7f43ff178fd0>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8c6e090>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa1b77d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8c79250>,\n",
              " <matplotlib.axis.XTick at 0x7f43ff176710>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8ac9190>,\n",
              " <matplotlib.axis.XTick at 0x7f440007c490>,\n",
              " <matplotlib.axis.XTick at 0x7f43ff176dd0>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8e28350>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7f43f8baca10>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa30a050>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8cfef90>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8ea6090>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8b13e10>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa9275d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffb482d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8fbce10>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8f225d0>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8f22790>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa9276d0>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%'),\n",
              " <matplotlib.axis.XTick at 0x7f43f8accd10>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8acc710>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8accf50>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffbdbf10>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffbdbc90>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffbdb910>,\n",
              " <matplotlib.axis.XTick at 0x7f43f8bae690>,\n",
              " <matplotlib.axis.XTick at 0x7f43ffa0ced0>,\n",
              " <matplotlib.axis.XTick at 0x7f43fa271890>,\n",
              " <matplotlib.axis.XTick at 0x7f4400071f10>,\n",
              " <matplotlib.axis.XTick at 0x7f4400071150>,\n",
              " Text(0, 0, '0%'),\n",
              " Text(0, 0, '10%'),\n",
              " Text(0, 0, '20%'),\n",
              " Text(0, 0, '30%'),\n",
              " Text(0, 0, '40%'),\n",
              " Text(0, 0, '50%'),\n",
              " Text(0, 0, '60%'),\n",
              " Text(0, 0, '70%'),\n",
              " Text(0, 0, '80%'),\n",
              " Text(0, 0, '90%'),\n",
              " Text(0, 0, '100%')]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# test it onthe same data as we tested the non-adjusted to augmentation model\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# tests in D_in\n",
        "diffs_per_class_D_in = study_perturbations(target_model, train_images[train_idx], train_labels[train_idx], r, d) \n",
        "total_diffs_in = sum(diffs_per_class_D_in)/10\n",
        "axes[0].set_title('D_in predicted label divergence');\n",
        "axes[0].barh(list(range(10)), diffs_per_class_D_in, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "# tests in D_out  \n",
        "diffs_per_class_D_out= study_perturbations(target_model,attacker_images[test_idx],attacker_labels[test_idx], r, d)\n",
        "total_diffs_out = sum(diffs_per_class_D_out)/10\n",
        "axes[1].set_title('D_out predicted label divergence');\n",
        "axes[1].barh(list(range(10)), diffs_per_class_D_out, tick_label=[f'Class-{i}' for i in range(10)])\n",
        "\n",
        "axes[2].set_title('Total predicted label divergence percentage');\n",
        "axes[2].barh([1, 0], [total_diffs_in, total_diffs_out], tick_label=['In', 'Out'])\n",
        "\n",
        "plt.setp(axes, xticks=range(0, 101, 10), xticklabels=[f'{i}%' for i in range(0, 101, 10)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVyVo6yukPGH"
      },
      "source": [
        "We can see that the general percentage of predicted label divergence has fallen, **but** the confidence of the ML algorithm in predicting the label of perturbed instances of instances in $D_{in}$ is even higher that before. This means that the adjusted model is even more vulnerable. Next step is to run all that with a well-generalized model and tune the attack model to get max accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXk2DEHBc9i9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cifar_10_labels_only_mia.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
