{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML-Leaks-Attack1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML Leaks - Attack 1\n",
        "\n",
        "In the first attack of [this](https://arxiv.org/abs/1806.01246) we contain the number of shadow models into 1 and loosen the assumptions of Shokri et al. about architecture of the model and attack data distribution. \n",
        "\n",
        "Specifically Shokri et al. determined that \n",
        "- shadow models must have very similar, if not the same, architecture with the target model, in order to mimic its behaviour.\n",
        "- Attacker must train the local shadow models with data instances of the same distribution with the target dataset.\n",
        "\n",
        "We will know prove that \n",
        "- shadow models can be of any architecture and we will still get a very similar to original, attack performance\n",
        "- attacker dataset from a different distribution can give performance close to Shokri's et al. attack\n",
        "\n",
        "First we will set up the dataset and try the attack with 1 model, following original attack assumptions. Then we will loose the shadows' arch assumption and compare to the original attack. \n",
        "\n",
        "Lastly, we will load another dataset, different in respect of data distribution and use this as attack dataset."
      ],
      "metadata": {
        "id": "n0GfUpM-ZLWj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0BNdk0kVbtG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    }
  ]
}