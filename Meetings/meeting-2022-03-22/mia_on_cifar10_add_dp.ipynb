{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "mia-on-cifar10-add-dp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MIA on DP-Trained models\n",
        "\n",
        "In this notebook we will explore the tensorflow privacy framework, especially the DP enchanced optimizers. We will train our default CNN model on a slice of CIFAR-10 data using a DP enchanced optimizer (either adam or sgd) and then use the default attack on the target model to check the results. \n",
        "\n",
        "Attacker knowledge:\n",
        "- Dataset Distribution\n",
        "- Model Type, NOT the exact structure or tuning of the model\n",
        "- Prediction Confidence for each class on a datapoint (confidence vector)"
      ],
      "metadata": {
        "id": "XW0_KQPGN37P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "!pip install tensorflow-privacy\n",
        "import tensorflow_privacy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPAdamGaussianOptimizer\n",
        "\n",
        "# for image interpolation\n",
        "import scipy.ndimage.interpolation as interpolation\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "from mia.attack_model import *\n",
        "from mia.label_only import *\n",
        "from mia.shadow_models import *\n",
        "from mia.utilities import *\n",
        "from mia.wrappers import *\n",
        "\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n"
      ],
      "metadata": {
        "id": "tg_WQJ7j5n3B",
        "outputId": "f64aba4c-6e96-444c-bdb1-2870a0f1503a",
        "execution": {
          "iopub.status.busy": "2022-03-14T16:15:20.035100Z",
          "iopub.execute_input": "2022-03-14T16:15:20.035593Z",
          "iopub.status.idle": "2022-03-14T16:15:27.973259Z",
          "shell.execute_reply.started": "2022-03-14T16:15:20.035552Z",
          "shell.execute_reply": "2022-03-14T16:15:27.972061Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Requirement already satisfied: tensorflow-privacy in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: numpy~=1.21.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.21.5)\n",
            "Requirement already satisfied: scipy~=1.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.5.4)\n",
            "Requirement already satisfied: attrs~=21.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (21.2.0)\n",
            "Requirement already satisfied: matplotlib~=3.3.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (3.3.4)\n",
            "Requirement already satisfied: tensorflow~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: scikit-learn~=1.0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.0.2)\n",
            "Requirement already satisfied: tensorflow-probability~=0.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (0.15.0)\n",
            "Requirement already satisfied: absl-py~=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.0.0)\n",
            "Requirement already satisfied: pandas~=1.1.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (1.1.5)\n",
            "Requirement already satisfied: tensorflow-datasets~=4.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-privacy) (4.5.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py~=1.0.0->tensorflow-privacy) (1.15.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (7.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.3.4->tensorflow-privacy) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.1.4->tensorflow-privacy) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=1.0.2->tensorflow-privacy) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn~=1.0.2->tensorflow-privacy) (1.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (13.0.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.10.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (1.13.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.4->tensorflow-privacy) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.4->tensorflow-privacy) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.4->tensorflow-privacy) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.4->tensorflow-privacy) (3.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (2.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (5.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.7.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets~=4.5.2->tensorflow-privacy) (4.63.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15.0->tensorflow-privacy) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability~=0.15.0->tensorflow-privacy) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets~=4.5.2->tensorflow-privacy) (1.55.0)\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Model\n"
      ],
      "metadata": {
        "id": "5Kv7Qon0qRTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "\n",
        "D_TARGET_SIZE = 10000\n",
        "\n",
        "learning_rate = 0.001\n",
        "noise_multiplier = 1.1\n",
        "l2_norm_clip = 2.5\n",
        "batch_size = 100\n",
        "num_microbatches = 100\n",
        "epochs = 200\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1e-4, patience=20)\n",
        "\n",
        "def step_decay(epoch):\n",
        "  initial_lrate = 0.001\n",
        "  drop = 1e-5\n",
        "  epochs_drop = 100\n",
        "  lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "  return lrate\n",
        "\n",
        "lrate = LearningRateScheduler(step_decay)\n",
        "callbacks_list = [lrate, es]\n"
      ],
      "metadata": {
        "id": "zacp4ArauIET",
        "execution": {
          "iopub.status.busy": "2022-03-14T16:05:24.518147Z",
          "iopub.status.idle": "2022-03-14T16:05:24.518544Z",
          "shell.execute_reply.started": "2022-03-14T16:05:24.518329Z",
          "shell.execute_reply": "2022-03-14T16:05:24.518351Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "#shuffle the datasets\n",
        "sample_i = np.random.choice(range(train_images.shape[0]), train_images.shape[0], replace=False)\n",
        "train_images = train_images[sample_i]\n",
        "train_labels = train_labels[sample_i]\n",
        "sample_i = np.random.choice(range(test_images.shape[0]), test_images.shape[0], replace=False)\n",
        "test_images = test_images[sample_i]\n",
        "test_labels = test_labels[sample_i] \n",
        "\n",
        "# use the rest as testing - 'out' records\n",
        "attacker_labels = np.concatenate((train_labels[D_TARGET_SIZE:], test_labels))\n",
        "attacker_images = np.concatenate((train_images[D_TARGET_SIZE:], test_images))\n",
        "target_images = train_images[:D_TARGET_SIZE]\n",
        "target_labels = train_labels[:D_TARGET_SIZE]\n",
        "\n",
        "target_images = np.array(target_images, dtype=np.float32)\n",
        "attacker_images = np.array(attacker_images, dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "oy2NLipP75sX",
        "execution": {
          "iopub.status.busy": "2022-03-14T16:04:14.556160Z",
          "iopub.status.idle": "2022-03-14T16:04:14.556723Z",
          "shell.execute_reply.started": "2022-03-14T16:04:14.556491Z",
          "shell.execute_reply": "2022-03-14T16:04:14.556515Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_target_def():\n",
        "  \"\"\"\n",
        "  Returns a trained target model, if test data are specified we will evaluate the model and print its accuracy\n",
        "  \"\"\"\n",
        "  model = models.Sequential([\n",
        "  layers.Conv2D(32, (3, 3), activation='tanh', input_shape=(32, 32, 3)),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "  layers.Conv2D(64, (3, 3), activation='tanh'),\n",
        "  layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='tanh'),\n",
        "  layers.Dense(10)\n",
        "  ])\n",
        "  model.summary()\n",
        "\n",
        "  optimizer = tensorflow_privacy.DPKerasAdamOptimizer(\n",
        "    l2_norm_clip=l2_norm_clip,\n",
        "    noise_multiplier=noise_multiplier,\n",
        "    num_microbatches=num_microbatches,\n",
        "    learning_rate=learning_rate)\n",
        "  \n",
        "  loss = loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
        "\n",
        "  model.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "1qg7LkXX0zOF",
        "execution": {
          "iopub.status.busy": "2022-03-14T16:04:14.554470Z",
          "iopub.status.idle": "2022-03-14T16:04:14.555027Z",
          "shell.execute_reply.started": "2022-03-14T16:04:14.554793Z",
          "shell.execute_reply": "2022-03-14T16:04:14.554818Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_target():\n",
        "  \"\"\"\n",
        "  Returns a trained target model, if test data are specified we will evaluate the model and print its accuracy\n",
        "  \"\"\"\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32,32,3)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(128, activation='relu'))\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "  model.add(layers.Dense(10))\n",
        "  model.summary()\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  \n",
        "  loss = loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  model.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "7rzBQqH8lnu_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, eval_images, train_labels, eval_labels = train_test_split(target_images, target_labels, test_size=0.2, shuffle=True)\n",
        "target_model = f_target() \n",
        "target_model_def = f_target_def()"
      ],
      "metadata": {
        "id": "Ap02yKRT76RJ",
        "outputId": "0f7d9137-7e91-4190-c6a9-26b1f08b727e",
        "execution": {
          "iopub.status.busy": "2022-03-14T16:04:14.557790Z",
          "iopub.status.idle": "2022-03-14T16:04:14.558359Z",
          "shell.execute_reply.started": "2022-03-14T16:04:14.558118Z",
          "shell.execute_reply": "2022-03-14T16:04:14.558141Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456,746\n",
            "Trainable params: 456,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               295040    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315,722\n",
            "Trainable params: 315,722\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = target_model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(eval_images, eval_labels), callbacks=[es, lrate])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnBut--7WhZ5",
        "outputId": "aae5be04-6c05-4496-b404-5ffb2541b843"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "80/80 [==============================] - 4s 24ms/step - loss: 2.1141 - accuracy: 0.2355 - val_loss: 1.8251 - val_accuracy: 0.3310 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 1.6586 - accuracy: 0.3904 - val_loss: 1.6849 - val_accuracy: 0.3735 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 1.4868 - accuracy: 0.4516 - val_loss: 1.6728 - val_accuracy: 0.4320 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 1.3536 - accuracy: 0.5065 - val_loss: 1.5039 - val_accuracy: 0.4710 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 1.2149 - accuracy: 0.5612 - val_loss: 1.4977 - val_accuracy: 0.4915 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 1.1033 - accuracy: 0.6051 - val_loss: 1.5043 - val_accuracy: 0.4840 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 1.0044 - accuracy: 0.6371 - val_loss: 1.5191 - val_accuracy: 0.4970 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.8254 - accuracy: 0.7106 - val_loss: 1.5054 - val_accuracy: 0.5215 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.7007 - accuracy: 0.7548 - val_loss: 1.5487 - val_accuracy: 0.5150 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.5569 - accuracy: 0.8181 - val_loss: 1.5486 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5566 - accuracy: 0.8184 - val_loss: 1.5484 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5563 - accuracy: 0.8184 - val_loss: 1.5483 - val_accuracy: 0.5145 - lr: 1.0000e-08\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5560 - accuracy: 0.8183 - val_loss: 1.5481 - val_accuracy: 0.5145 - lr: 1.0000e-08\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5557 - accuracy: 0.8184 - val_loss: 1.5480 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5554 - accuracy: 0.8185 - val_loss: 1.5478 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5551 - accuracy: 0.8185 - val_loss: 1.5477 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5548 - accuracy: 0.8185 - val_loss: 1.5475 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5545 - accuracy: 0.8186 - val_loss: 1.5474 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5542 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-08\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n",
            "Epoch 28/200\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.5541 - accuracy: 0.8186 - val_loss: 1.5472 - val_accuracy: 0.5150 - lr: 1.0000e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = target_model_def.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_data=(eval_images, eval_labels), callbacks=[es, lrate])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPdXwtrCl9SE",
        "outputId": "6221ad58-47d4-4491-8cf8-fee35def1ab4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "80/80 [==============================] - 43s 502ms/step - loss: 2.3022 - accuracy: 0.1538 - val_loss: 2.1908 - val_accuracy: 0.1945 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "80/80 [==============================] - 40s 502ms/step - loss: 2.1283 - accuracy: 0.2138 - val_loss: 2.0808 - val_accuracy: 0.2270 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "80/80 [==============================] - 40s 504ms/step - loss: 2.0451 - accuracy: 0.2449 - val_loss: 2.0318 - val_accuracy: 0.2445 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.9876 - accuracy: 0.2639 - val_loss: 1.9881 - val_accuracy: 0.2615 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "80/80 [==============================] - 40s 497ms/step - loss: 1.9437 - accuracy: 0.2903 - val_loss: 1.9406 - val_accuracy: 0.2770 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.9165 - accuracy: 0.2957 - val_loss: 1.9057 - val_accuracy: 0.2985 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "80/80 [==============================] - 40s 497ms/step - loss: 1.8885 - accuracy: 0.3064 - val_loss: 1.8790 - val_accuracy: 0.3220 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "80/80 [==============================] - 40s 497ms/step - loss: 1.8637 - accuracy: 0.3223 - val_loss: 1.8780 - val_accuracy: 0.3105 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.8535 - accuracy: 0.3199 - val_loss: 1.8765 - val_accuracy: 0.3195 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "80/80 [==============================] - 40s 498ms/step - loss: 1.8367 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3195 - lr: 1.0000e-08\n",
            "Epoch 11/200\n",
            "80/80 [==============================] - 40s 497ms/step - loss: 1.8367 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 12/200\n",
            "80/80 [==============================] - 40s 498ms/step - loss: 1.8367 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 13/200\n",
            "80/80 [==============================] - 40s 497ms/step - loss: 1.8367 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 14/200\n",
            "80/80 [==============================] - 40s 498ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 15/200\n",
            "80/80 [==============================] - 40s 497ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 16/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 17/200\n",
            "80/80 [==============================] - 40s 498ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 18/200\n",
            "80/80 [==============================] - 40s 495ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 19/200\n",
            "80/80 [==============================] - 40s 495ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-08\n",
            "Epoch 20/200\n",
            "80/80 [==============================] - 40s 495ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 21/200\n",
            "80/80 [==============================] - 40s 495ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 22/200\n",
            "80/80 [==============================] - 40s 499ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 23/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 24/200\n",
            "80/80 [==============================] - 40s 498ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 25/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 26/200\n",
            "80/80 [==============================] - 40s 496ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n",
            "Epoch 27/200\n",
            "80/80 [==============================] - 40s 495ms/step - loss: 1.8366 - accuracy: 0.3264 - val_loss: 1.8764 - val_accuracy: 0.3200 - lr: 1.0000e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_SHADOWS = 2\n",
        "D_SHADOW_SIZE = 10000"
      ],
      "metadata": {
        "id": "2GWyCXmmwIiJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_attack():\n",
        "\n",
        "  model = models.Sequential(name='conf-vector-attack_model')\n",
        "  model.add(layers.Dense(10, input_shape=(11, )))\n",
        "  model.add(layers.LeakyReLU(0.3))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "        \n",
        "  model.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "  \n",
        "  print(model.summary())\n",
        "  return model "
      ],
      "metadata": {
        "id": "gnhE29HBBYGy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack = ConfidenceVectorAttack(target_model, \n",
        "                                (train_images, train_labels), \n",
        "                                (attacker_images, attacker_labels), \n",
        "                                attack_model_creator=f_attack, \n",
        "                                shadow_creator=f_target, \n",
        "                                n_shadows=N_SHADOWS, \n",
        "                                D_shadow_size=D_SHADOW_SIZE, \n",
        "                                verbose=True)"
      ],
      "metadata": {
        "id": "sliyw7xO2PTg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack.perform_attack(shadow={'epochs':25, 'batch_size':128}, attack={'epochs':50, 'batch_size':128})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMuGzJlWgkrg",
        "outputId": "e40d42c7-af38-466d-8afa-2c7d26d27194"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456,746\n",
            "Trainable params: 456,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 12, 12, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               147584    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 456,746\n",
            "Trainable params: 456,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "53/53 [==============================] - 3s 32ms/step - loss: 2.3495 - accuracy: 0.1982 - val_loss: 1.8950 - val_accuracy: 0.2921\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.8459 - accuracy: 0.3087 - val_loss: 1.7297 - val_accuracy: 0.3548\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1.6695 - accuracy: 0.3776 - val_loss: 1.6363 - val_accuracy: 0.3936\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.5200 - accuracy: 0.4397 - val_loss: 1.6097 - val_accuracy: 0.4218\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1.4207 - accuracy: 0.4793 - val_loss: 1.5017 - val_accuracy: 0.4673\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.2609 - accuracy: 0.5440 - val_loss: 1.5173 - val_accuracy: 0.4603\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.1636 - accuracy: 0.5755 - val_loss: 1.4812 - val_accuracy: 0.4903\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1.0150 - accuracy: 0.6333 - val_loss: 1.5563 - val_accuracy: 0.5003\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.9419 - accuracy: 0.6643 - val_loss: 1.5751 - val_accuracy: 0.4994\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.7809 - accuracy: 0.7260 - val_loss: 1.5853 - val_accuracy: 0.5003\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.6572 - accuracy: 0.7687 - val_loss: 1.7854 - val_accuracy: 0.4882\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.5425 - accuracy: 0.8064 - val_loss: 1.9791 - val_accuracy: 0.4676\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.4338 - accuracy: 0.8497 - val_loss: 2.2210 - val_accuracy: 0.4803\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.3941 - accuracy: 0.8618 - val_loss: 2.1989 - val_accuracy: 0.4924\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.3497 - accuracy: 0.8799 - val_loss: 2.2872 - val_accuracy: 0.4688\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.3055 - accuracy: 0.8951 - val_loss: 2.5540 - val_accuracy: 0.4985\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.2528 - accuracy: 0.9107 - val_loss: 2.7481 - val_accuracy: 0.4876\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.2386 - accuracy: 0.9193 - val_loss: 2.7173 - val_accuracy: 0.4852\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.2229 - accuracy: 0.9227 - val_loss: 2.9396 - val_accuracy: 0.4906\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.1298 - accuracy: 0.9572 - val_loss: 3.2102 - val_accuracy: 0.4970\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1574 - accuracy: 0.9476 - val_loss: 3.0941 - val_accuracy: 0.4791\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.2186 - accuracy: 0.9322 - val_loss: 3.0261 - val_accuracy: 0.4779\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.1269 - accuracy: 0.9597 - val_loss: 3.3968 - val_accuracy: 0.4830\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1480 - accuracy: 0.9548 - val_loss: 3.4688 - val_accuracy: 0.4864\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.1608 - accuracy: 0.9464 - val_loss: 3.3181 - val_accuracy: 0.4764\n",
            "Epoch 1/25\n",
            "53/53 [==============================] - 2s 31ms/step - loss: 2.1911 - accuracy: 0.1964 - val_loss: 1.8880 - val_accuracy: 0.2788\n",
            "Epoch 2/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.7935 - accuracy: 0.3276 - val_loss: 1.7965 - val_accuracy: 0.3448\n",
            "Epoch 3/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.5871 - accuracy: 0.4082 - val_loss: 1.6884 - val_accuracy: 0.3791\n",
            "Epoch 4/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1.4174 - accuracy: 0.4696 - val_loss: 1.5060 - val_accuracy: 0.4573\n",
            "Epoch 5/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 1.2778 - accuracy: 0.5293 - val_loss: 1.4598 - val_accuracy: 0.4764\n",
            "Epoch 6/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 1.1320 - accuracy: 0.5849 - val_loss: 1.4035 - val_accuracy: 0.5212\n",
            "Epoch 7/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.9711 - accuracy: 0.6543 - val_loss: 1.4505 - val_accuracy: 0.5127\n",
            "Epoch 8/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.8385 - accuracy: 0.7004 - val_loss: 1.4385 - val_accuracy: 0.5252\n",
            "Epoch 9/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.6903 - accuracy: 0.7590 - val_loss: 1.6224 - val_accuracy: 0.5067\n",
            "Epoch 10/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.5702 - accuracy: 0.7958 - val_loss: 1.6552 - val_accuracy: 0.5173\n",
            "Epoch 11/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.4535 - accuracy: 0.8379 - val_loss: 1.8939 - val_accuracy: 0.5082\n",
            "Epoch 12/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.3585 - accuracy: 0.8751 - val_loss: 1.9502 - val_accuracy: 0.5212\n",
            "Epoch 13/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.3039 - accuracy: 0.8928 - val_loss: 2.0747 - val_accuracy: 0.5088\n",
            "Epoch 14/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.2862 - accuracy: 0.8985 - val_loss: 2.3594 - val_accuracy: 0.5252\n",
            "Epoch 15/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.2263 - accuracy: 0.9233 - val_loss: 2.6942 - val_accuracy: 0.5015\n",
            "Epoch 16/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.2536 - accuracy: 0.9128 - val_loss: 2.4022 - val_accuracy: 0.4994\n",
            "Epoch 17/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1632 - accuracy: 0.9442 - val_loss: 2.8853 - val_accuracy: 0.5133\n",
            "Epoch 18/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.1151 - accuracy: 0.9591 - val_loss: 2.8417 - val_accuracy: 0.4976\n",
            "Epoch 19/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1370 - accuracy: 0.9572 - val_loss: 2.6943 - val_accuracy: 0.5188\n",
            "Epoch 20/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1256 - accuracy: 0.9555 - val_loss: 2.8626 - val_accuracy: 0.4955\n",
            "Epoch 21/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.1524 - accuracy: 0.9484 - val_loss: 2.8841 - val_accuracy: 0.4939\n",
            "Epoch 22/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.1305 - accuracy: 0.9569 - val_loss: 3.1718 - val_accuracy: 0.4976\n",
            "Epoch 23/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.1395 - accuracy: 0.9528 - val_loss: 2.7710 - val_accuracy: 0.5061\n",
            "Epoch 24/25\n",
            "53/53 [==============================] - 1s 23ms/step - loss: 0.0948 - accuracy: 0.9685 - val_loss: 3.0779 - val_accuracy: 0.5085\n",
            "Epoch 25/25\n",
            "53/53 [==============================] - 1s 25ms/step - loss: 0.0740 - accuracy: 0.9751 - val_loss: 3.4569 - val_accuracy: 0.5115\n",
            "Model: \"conf-vector-attack_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 10)                120       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 10)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131\n",
            "Trainable params: 131\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Preparing shadow batch of size 6600\n",
            "Done!\n",
            "Epoch 1/50\n",
            "73/73 [==============================] - 1s 7ms/step - loss: 0.6980 - accuracy: 0.5131 - val_loss: 0.6953 - val_accuracy: 0.5331\n",
            "Epoch 2/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.5489 - val_loss: 0.6942 - val_accuracy: 0.5235\n",
            "Epoch 3/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6911 - accuracy: 0.5465 - val_loss: 0.6925 - val_accuracy: 0.5295\n",
            "Epoch 4/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5490 - val_loss: 0.6927 - val_accuracy: 0.5086\n",
            "Epoch 5/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.5356 - val_loss: 0.6899 - val_accuracy: 0.5629\n",
            "Epoch 6/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6879 - accuracy: 0.5652 - val_loss: 0.6905 - val_accuracy: 0.5301\n",
            "Epoch 7/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6871 - accuracy: 0.5523 - val_loss: 0.6904 - val_accuracy: 0.5232\n",
            "Epoch 8/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.5557 - val_loss: 0.6872 - val_accuracy: 0.5573\n",
            "Epoch 9/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.5564 - val_loss: 0.6881 - val_accuracy: 0.5240\n",
            "Epoch 10/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5663 - val_loss: 0.6867 - val_accuracy: 0.5500\n",
            "Epoch 11/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6834 - accuracy: 0.5707 - val_loss: 0.6868 - val_accuracy: 0.5379\n",
            "Epoch 12/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6825 - accuracy: 0.5618 - val_loss: 0.6838 - val_accuracy: 0.5576\n",
            "Epoch 13/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.5677 - val_loss: 0.6851 - val_accuracy: 0.5326\n",
            "Epoch 14/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6803 - accuracy: 0.5511 - val_loss: 0.6831 - val_accuracy: 0.5414\n",
            "Epoch 15/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5505 - val_loss: 0.6813 - val_accuracy: 0.5424\n",
            "Epoch 16/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6778 - accuracy: 0.5478 - val_loss: 0.6811 - val_accuracy: 0.5346\n",
            "Epoch 17/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5430 - val_loss: 0.6800 - val_accuracy: 0.5348\n",
            "Epoch 18/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6752 - accuracy: 0.5521 - val_loss: 0.6771 - val_accuracy: 0.5157\n",
            "Epoch 19/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.5443 - val_loss: 0.6770 - val_accuracy: 0.5394\n",
            "Epoch 20/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6723 - accuracy: 0.5417 - val_loss: 0.6749 - val_accuracy: 0.5361\n",
            "Epoch 21/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.5476 - val_loss: 0.6750 - val_accuracy: 0.5636\n",
            "Epoch 22/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6688 - accuracy: 0.5580 - val_loss: 0.6720 - val_accuracy: 0.5725\n",
            "Epoch 23/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6673 - accuracy: 0.5718 - val_loss: 0.6709 - val_accuracy: 0.5707\n",
            "Epoch 24/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6654 - accuracy: 0.5687 - val_loss: 0.6677 - val_accuracy: 0.5465\n",
            "Epoch 25/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.5713 - val_loss: 0.6668 - val_accuracy: 0.5710\n",
            "Epoch 26/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6618 - accuracy: 0.5867 - val_loss: 0.6642 - val_accuracy: 0.5879\n",
            "Epoch 27/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6595 - accuracy: 0.5960 - val_loss: 0.6622 - val_accuracy: 0.5942\n",
            "Epoch 28/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6572 - accuracy: 0.6097 - val_loss: 0.6595 - val_accuracy: 0.5795\n",
            "Epoch 29/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.6029 - val_loss: 0.6589 - val_accuracy: 0.6020\n",
            "Epoch 30/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6524 - accuracy: 0.6268 - val_loss: 0.6553 - val_accuracy: 0.5972\n",
            "Epoch 31/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6496 - accuracy: 0.6182 - val_loss: 0.6510 - val_accuracy: 0.6232\n",
            "Epoch 32/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6464 - accuracy: 0.6269 - val_loss: 0.6502 - val_accuracy: 0.6354\n",
            "Epoch 33/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.6247 - val_loss: 0.6462 - val_accuracy: 0.6121\n",
            "Epoch 34/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6399 - accuracy: 0.6450 - val_loss: 0.6442 - val_accuracy: 0.6556\n",
            "Epoch 35/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6367 - accuracy: 0.6509 - val_loss: 0.6390 - val_accuracy: 0.6649\n",
            "Epoch 36/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6332 - accuracy: 0.6793 - val_loss: 0.6347 - val_accuracy: 0.6710\n",
            "Epoch 37/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.6823 - val_loss: 0.6305 - val_accuracy: 0.6783\n",
            "Epoch 38/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6256 - accuracy: 0.7037 - val_loss: 0.6281 - val_accuracy: 0.6992\n",
            "Epoch 39/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6224 - accuracy: 0.7216 - val_loss: 0.6238 - val_accuracy: 0.7045\n",
            "Epoch 40/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.7200 - val_loss: 0.6197 - val_accuracy: 0.7061\n",
            "Epoch 41/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6155 - accuracy: 0.7233 - val_loss: 0.6176 - val_accuracy: 0.7035\n",
            "Epoch 42/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.7229 - val_loss: 0.6139 - val_accuracy: 0.7073\n",
            "Epoch 43/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.7253 - val_loss: 0.6121 - val_accuracy: 0.7035\n",
            "Epoch 44/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.6068 - accuracy: 0.7242 - val_loss: 0.6083 - val_accuracy: 0.7134\n",
            "Epoch 45/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6039 - accuracy: 0.7276 - val_loss: 0.6061 - val_accuracy: 0.7109\n",
            "Epoch 46/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.7264 - val_loss: 0.6036 - val_accuracy: 0.7126\n",
            "Epoch 47/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.7285 - val_loss: 0.6012 - val_accuracy: 0.7121\n",
            "Epoch 48/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.5966 - accuracy: 0.7305 - val_loss: 0.5993 - val_accuracy: 0.7096\n",
            "Epoch 49/50\n",
            "73/73 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.7297 - val_loss: 0.5963 - val_accuracy: 0.7167\n",
            "Epoch 50/50\n",
            "73/73 [==============================] - 0s 5ms/step - loss: 0.5921 - accuracy: 0.7314 - val_loss: 0.5954 - val_accuracy: 0.7121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = attack.evaluate_attack()"
      ],
      "metadata": {
        "id": "q3ziH9LP3CY5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "7821ac50-da9e-4c85-b2c1-ed3286a603d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class-1 acc: 0.5918238759040833\n",
            "class-2 acc: 0.6036922931671143\n",
            "class-3 acc: 0.585995078086853\n",
            "class-4 acc: 0.5930305123329163\n",
            "class-5 acc: 0.5741565823554993\n",
            "class-6 acc: 0.6369550824165344\n",
            "class-7 acc: 0.5998743772506714\n",
            "class-8 acc: 0.628134548664093\n",
            "class-9 acc: 0.5794681310653687\n",
            "class-10 acc: 0.610763430595398\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Out       0.60      0.61      0.60      8000\n",
            "          In       0.60      0.59      0.60      8000\n",
            "\n",
            "    accuracy                           0.60     16000\n",
            "   macro avg       0.60      0.60      0.60     16000\n",
            "weighted avg       0.60      0.60      0.60     16000\n",
            "\n",
            "AUC: 0.630649140625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack.target_model = target_model_def\n",
        "res = attack.evaluate_attack()"
      ],
      "metadata": {
        "id": "7bdgsVbiFk3B",
        "outputId": "ed680a09-968c-4520-c420-e57a1d58411f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class-1 acc: 0.49685534834861755\n",
            "class-2 acc: 0.508307695388794\n",
            "class-3 acc: 0.4944717586040497\n",
            "class-4 acc: 0.4984443187713623\n",
            "class-5 acc: 0.48758751153945923\n",
            "class-6 acc: 0.5003253221511841\n",
            "class-7 acc: 0.5050251483917236\n",
            "class-8 acc: 0.48685014247894287\n",
            "class-9 acc: 0.5102040767669678\n",
            "class-10 acc: 0.49436795711517334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Out       0.50      0.80      0.61      8000\n",
            "          In       0.50      0.20      0.28      8000\n",
            "\n",
            "    accuracy                           0.50     16000\n",
            "   macro avg       0.50      0.50      0.45     16000\n",
            "weighted avg       0.50      0.50      0.45     16000\n",
            "\n",
            "AUC: 0.49902071875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a5ZmAGqFgPFP"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}